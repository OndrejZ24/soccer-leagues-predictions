{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c23974f",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Classifier - Soccer O/U 2.5 Goals Prediction\n",
    "\n",
    "**Objective**: Build and evaluate a baseline XGBoost classifier using core soccer match features to predict Over/Under 2.5 goals.\n",
    "\n",
    "**Tasks**:\n",
    "- Load baseline preprocessed data\n",
    "- Build baseline XGBoost classifier  \n",
    "- Train and validate model\n",
    "- Hyperparameter tuning\n",
    "- Feature importance analysis\n",
    "- Learning curves\n",
    "- Performance comparison (tuned vs untuned)\n",
    "- XGBoost vs Random Forest comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c451ea57",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d75c0",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b19a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=Warning) # Suppress convergence warnings from Gaussian Process\n",
    "\n",
    "\n",
    "#learning curve for baseline model\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, learning_curve, ShuffleSplit\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, classification_report, confusion_matrix,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Bayesian Optimization\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86b85f",
   "metadata": {},
   "source": [
    "### 1.2 Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4814da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate comprehensive metrics\n",
    "def evaluate_model(y_true, y_pred, y_pred_proba, model_name=\"Model\"):\n",
    "    \"\"\"Calculate comprehensive classification metrics\"\"\"\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìà {model_name} Performance Metrics:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-Score:  {metrics['f1']:.4f}\")\n",
    "    print(f\"ROC-AUC:   {metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9a706",
   "metadata": {},
   "source": [
    "### 1.3 Load Baseline Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the baseline preprocessed data\n",
    "\n",
    "with open('processed/baseline_preprocessed.pkl', 'rb') as f:\n",
    "    baseline_data = pickle.load(f)\n",
    "\n",
    "# Extract all datasets including validation\n",
    "X_train_baseline = baseline_data['X_train']\n",
    "X_val_baseline = baseline_data['X_val']\n",
    "X_test_baseline = baseline_data['X_test'] \n",
    "y_train = baseline_data['y_train']\n",
    "y_val = baseline_data['y_val']\n",
    "y_test = baseline_data['y_test']\n",
    "\n",
    "print(f\"\\nüìä Dataset Shapes:\")\n",
    "print(f\"Training set: {X_train_baseline.shape}\")\n",
    "print(f\"Validation set: {X_val_baseline.shape}\")\n",
    "print(f\"Test set: {X_test_baseline.shape}\")\n",
    "print(f\"Features: {X_train_baseline.shape[1]}\")\n",
    "\n",
    "print(f\"\\nüéØ Target Distribution:\")\n",
    "print(f\"Training - Over 2.5: {y_train.mean():.2%}\")\n",
    "print(f\"Validation - Over 2.5: {y_val.mean():.2%}\")\n",
    "print(f\"Test - Over 2.5: {y_test.mean():.2%}\")\n",
    "\n",
    "\n",
    "# Display data split summary\n",
    "total_samples = len(y_train) + len(y_val) + len(y_test)\n",
    "print(f\"\\nüìà Data Split Summary:\")\n",
    "print(f\"Total samples: {total_samples:,}\")\n",
    "print(f\"Training: {len(y_train):,} ({len(y_train)/total_samples:.1%})\")\n",
    "print(f\"Validation: {len(y_val):,} ({len(y_val)/total_samples:.1%})\")\n",
    "print(f\"Test: {len(y_test):,} ({len(y_test)/total_samples:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95349cd",
   "metadata": {},
   "source": [
    "## 2 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add6bae",
   "metadata": {},
   "source": [
    "### 2.1 Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dadad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline XGBoost classifier with default parameters\n",
    "\n",
    "# Initialize XGBoost with basic parameters\n",
    "xgb_baseline = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0  # Suppress training output\n",
    ")\n",
    "\n",
    "\n",
    "# Train the baseline XGBoost model\n",
    "xgb_baseline.fit(X_train_baseline, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_val_pred_baseline = xgb_baseline.predict(X_val_baseline)\n",
    "y_val_pred_proba_baseline = xgb_baseline.predict_proba(X_val_baseline)[:, 1]\n",
    "\n",
    "\n",
    "# Evaluate baseline model\n",
    "baseline_metrics = evaluate_model(\n",
    "    y_val, y_val_pred_baseline, y_val_pred_proba_baseline, \n",
    "    \"Baseline XGBoost (Validation)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6902898",
   "metadata": {},
   "source": [
    "## 2.2 Hyperparameter Optimization with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a2d8e",
   "metadata": {},
   "source": [
    "#### 2.2.1 Definition of optimized parameters and training training-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362da5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna hyperparameter optimization\n",
    "    Returns: ROC-AUC score to maximize\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': 0,\n",
    "        \n",
    "        # Tree structure parameters - adjusted for high dimensions (344+ features)\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 30),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 3, 20),\n",
    "        \n",
    "        # Sampling parameters - crucial for high dimensions\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 0.95),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.8),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 0.9),\n",
    "        \n",
    "        # Boosting parameters\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 4000, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.8, log=True),\n",
    "        \n",
    "        # Regularization parameters - stronger for high dimensions\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 20.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 50.0),\n",
    "        \n",
    "        # Advanced parameters\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 10.0),\n",
    "    }\n",
    "    \n",
    "    # Create and train model\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train_baseline, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_proba = model.predict_proba(X_val_baseline)[:, 1]\n",
    "    \n",
    "    # Return ROC-AUC score (higher is better)\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    return roc_auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12344b",
   "metadata": {},
   "source": [
    "#### 2.2.2 Running optuna optimization with 150 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.3 Run Hyperparameter Optimization\n",
    "\n",
    "# Create study with TPE sampler for efficient search\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # We want to maximize ROC-AUC\n",
    "    sampler=TPESampler(seed=RANDOM_STATE),\n",
    "    study_name='xgboost_soccer_prediction'\n",
    ")\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Run optimization with more trials for high-dimensional space\n",
    "N_TRIALS = 150  # More trials needed for complex parameter space with 344+ features\n",
    "print(f\"üöÄ Running {N_TRIALS} trials for high-dimensional optimization...\")\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "# Calculate optimization time\n",
    "optimization_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Optimization completed in {optimization_time:.1f} seconds\")\n",
    "print(f\"üìä Best ROC-AUC: {study.best_value:.6f}\")\n",
    "print(f\"üèÜ Best trial: #{study.best_trial.number}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc16c7c",
   "metadata": {},
   "source": [
    "#### 2.2.3 Best parameters according to optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeb0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã Best hyperparameters:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"   {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fee21",
   "metadata": {},
   "source": [
    "## 2.2 Hyperparameter Optimization with manual Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Define objective function (same as Optuna)\n",
    "# --------------------------------------------\n",
    "def evaluate_xgb_manual(params):\n",
    "    \"\"\"Train XGBoost and evaluate ROC-AUC on validation - matches Optuna objective.\"\"\"\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        # Parameters in same order as bounds array\n",
    "        max_depth=int(params[0]),\n",
    "        min_child_weight=int(params[1]),\n",
    "        subsample=params[2],\n",
    "        colsample_bytree=params[3],\n",
    "        colsample_bylevel=params[4],\n",
    "        n_estimators=int(params[5]),\n",
    "        learning_rate=params[6],\n",
    "        reg_alpha=params[7],\n",
    "        reg_lambda=params[8],\n",
    "        gamma=params[9]\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_baseline, y_train)\n",
    "    y_pred_val = model.predict_proba(X_val_baseline)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred_val)\n",
    "    # We minimize 1 - AUC (same as maximizing AUC)\n",
    "    return 1 - auc\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Define search space bounds (matching Optuna exactly)\n",
    "# --------------------------------------------\n",
    "param_bounds = np.array([\n",
    "    [4, 30],         # max_depth: 4-30\n",
    "    [3, 20],         # min_child_weight: 3-20\n",
    "    [0.7, 0.95],     # subsample: 0.7-0.95\n",
    "    [0.1, 0.8],      # colsample_bytree: 0.1-0.8\n",
    "    [0.1, 0.9],      # colsample_bylevel: 0.1-0.9\n",
    "    [100, 4000],     # n_estimators: 100-4000\n",
    "    [0.005, 0.8],    # learning_rate: 0.005-0.8\n",
    "    [0.1, 20.0],     # reg_alpha: 0.1-20.0\n",
    "    [1.0, 50.0],     # reg_lambda: 1.0-50.0\n",
    "    [0.1, 10.0],     # gamma: 0.1-10.0\n",
    "])\n",
    "\n",
    "n_params = param_bounds.shape[0]\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Initialize samples (random warm-up)\n",
    "# --------------------------------------------\n",
    "np.random.seed(RANDOM_STATE)\n",
    "N_INIT = 15  # More initial samples for 10-dimensional space\n",
    "\n",
    "\n",
    "X_samples = np.random.uniform(param_bounds[:, 0], param_bounds[:, 1], size=(N_INIT, n_params))\n",
    "Y_samples = np.array([evaluate_xgb_manual(x) for x in X_samples])\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Fit Gaussian Process surrogate\n",
    "# --------------------------------------------\n",
    "kernel = Matern(length_scale=1.0, nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, normalize_y=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Scaler helps GP fit parameters of different magnitudes \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_samples)\n",
    "gp.fit(X_scaled, Y_samples)\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Acquisition function (Upper Confidence Bound)\n",
    "# --------------------------------------------\n",
    "def acquisition_ucb(X, model, kappa=2.0):\n",
    "    \"\"\"Upper Confidence Bound acquisition function\"\"\"\n",
    "    mu, sigma = model.predict(X, return_std=True)\n",
    "    return mu - kappa * sigma  # minimizing (1 - AUC)\n",
    "\n",
    "def propose_next(model, bounds, n_candidates=3000):\n",
    "    \"\"\"Propose next point to evaluate\"\"\"\n",
    "    candidates = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_candidates, bounds.shape[0]))\n",
    "    candidates_scaled = scaler.transform(candidates)\n",
    "    acq_vals = acquisition_ucb(candidates_scaled, model)\n",
    "    best_idx = np.argmin(acq_vals)\n",
    "    return candidates[best_idx].reshape(1, -1), np.min(acq_vals)\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Iterative Bayesian Optimization loop\n",
    "# --------------------------------------------\n",
    "N_ITER = 150  # More iterations to match Optuna's exploration capacity\n",
    "history_best = [np.min(Y_samples)]\n",
    "\n",
    "print(f\"\\nüöÄ Starting Bayesian Optimization with {N_ITER} iterations...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(N_ITER):\n",
    "    # Propose next point\n",
    "    x_next, acq_val = propose_next(gp, param_bounds)\n",
    "    y_next = evaluate_xgb_manual(x_next[0])\n",
    "    \n",
    "    # Update datasets\n",
    "    X_samples = np.vstack([X_samples, x_next])\n",
    "    Y_samples = np.hstack([Y_samples, y_next])\n",
    "\n",
    "    # Refit Gaussian Process\n",
    "    X_scaled = scaler.fit_transform(X_samples)\n",
    "    gp.fit(X_scaled, Y_samples)\n",
    "\n",
    "    # Track progress\n",
    "    history_best.append(np.min(Y_samples))\n",
    "    current_best_auc = 1 - np.min(Y_samples)\n",
    "    \n",
    "    if (i + 1) % 10 == 0 or i < 5:  # Print progress every 10 iterations\n",
    "        print(f\"Iteration {i+1:02d}: Best AUC = {current_best_auc:.5f}\")\n",
    "\n",
    "optimization_time = time.time() - start_time\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Final results and comparison\n",
    "# --------------------------------------------\n",
    "best_idx = np.argmin(Y_samples)\n",
    "best_params_array = X_samples[best_idx]\n",
    "best_auc = 1 - Y_samples[best_idx]\n",
    "\n",
    "\n",
    "\n",
    "# Create parameter dictionary in same format as Optuna\n",
    "param_names = [\"max_depth\", \"min_child_weight\", \"subsample\", \"colsample_bytree\",\n",
    "               \"colsample_bylevel\", \"n_estimators\", \"learning_rate\", \"reg_alpha\",\n",
    "               \"reg_lambda\", \"gamma\"]\n",
    "\n",
    "# Convert to dictionary format matching Optuna output\n",
    "manual_bo_params = {}\n",
    "for i, name in enumerate(param_names):\n",
    "    if name in [\"max_depth\", \"min_child_weight\", \"n_estimators\"]:\n",
    "        manual_bo_params[name] = int(best_params_array[i])\n",
    "    else:\n",
    "        manual_bo_params[name] = float(best_params_array[i])\n",
    "\n",
    "print(f\"\\nüìã Best hyperparameters found:\")\n",
    "for name, val in manual_bo_params.items():\n",
    "    if isinstance(val, int):\n",
    "        print(f\"  {name:18}: {val}\")\n",
    "    else:\n",
    "        print(f\"  {name:18}: {val:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nüèÜ Manual Bayesian Optimization Results:\")\n",
    "print(f\"‚è±Ô∏è  Optimization time: {optimization_time:.1f} seconds\")\n",
    "print(f\"üéØ Best validation AUC: {best_auc:.6f}\")\n",
    "print(f\"üìä Total evaluations: {len(Y_samples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60591f6a",
   "metadata": {},
   "source": [
    "## 2.3 Comparison of optuna vs manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e1608",
   "metadata": {},
   "source": [
    "#### 2.3.1 Best parameters according to both approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract best parameters from Optuna study\n",
    "optuna_params = study.best_params\n",
    "optuna_auc = study.best_value\n",
    "\n",
    "print(f\"\\nüìä Comparison of Best Hyperparameters:\")\n",
    "print(f\"{'Parameter':<18} {'Optuna':<15}        {'Manual BO':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for param in param_names:\n",
    "    optuna_val = optuna_params.get(param, 'N/A')\n",
    "    manual_val = manual_bo_params.get(param, 'N/A')\n",
    "    \n",
    "    if isinstance(manual_val, int):\n",
    "        print(f\"{param:<18} {optuna_val:<15}              {manual_val:<15}\")\n",
    "    else:\n",
    "        \n",
    "        print(f\"{param:<18} {optuna_val:<15}         {manual_val:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ Best AUC Comparison:\")\n",
    "print(f\"Optuna AUC:    {optuna_auc:.6f}\")\n",
    "print(f\"Manual BO AUC: {best_auc:.6f}\")\n",
    "print(f\"Difference:    {abs(optuna_auc - best_auc):.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404937b0",
   "metadata": {},
   "source": [
    "## 2.4 Training Models with optimized parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac46ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Model trained with Optuna best parameters\n",
    "xgb_optuna = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    "    **optuna_params\n",
    ")\n",
    "\n",
    "xgb_optuna.fit(X_train_baseline, y_train)\n",
    "y_pred_val_optuna = xgb_optuna.predict_proba(X_val_baseline)[:, 1]\n",
    "auc_optuna = roc_auc_score(y_val, y_pred_val_optuna)\n",
    "print(f\"‚úÖ Optuna model AUC: {auc_optuna:.6f}\")\n",
    "\n",
    "# Model trained with Manual Bayesian Optimization best parameters  \n",
    "xgb_manual = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    "    **manual_bo_params\n",
    ")\n",
    "\n",
    "xgb_manual.fit(X_train_baseline, y_train)\n",
    "y_pred_val_manual = xgb_manual.predict_proba(X_val_baseline)[:, 1]\n",
    "auc_manual = roc_auc_score(y_val, y_pred_val_manual)\n",
    "print(f\"‚úÖ Manual BO model AUC: {auc_manual:.6f}\")\n",
    "\n",
    "print(f\"\\nüìä Final Validation Results:\")\n",
    "print(f\"Baseline XGBoost:     {baseline_metrics['roc_auc']:.6f}\")\n",
    "print(f\"Optuna Optimized:     {auc_optuna:.6f}\")\n",
    "print(f\"Manual BO Optimized:  {auc_manual:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd37943",
   "metadata": {},
   "source": [
    "# 3 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a749c95",
   "metadata": {},
   "source": [
    "## 3.1 Feature importance in all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot feature importance for baseline model\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_importance(xgb_baseline, max_num_features=10)\n",
    "plt.title(\"Baseline XGBoost Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot feature importance for optuna optimized model\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_importance(xgb_optuna, max_num_features=10)\n",
    "plt.title(\"Optuna BO XGBoost Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot feature importance for bayessian optimized model\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_importance(xgb_manual, max_num_features=10)\n",
    "plt.title(\"Manual BO XGBoost Feature Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a60ab3",
   "metadata": {},
   "source": [
    "## 3.2 learning curve for all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc08b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "train_sizes, train_scores, test_scores = learning_curve(xgb_baseline, X_train_baseline, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training AUC')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Validation AUC')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve for Baseline XGBoost')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#learning curve for optuna bo model\n",
    "train_sizes, train_scores, test_scores = learning_curve(xgb_optuna, X_train_baseline, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training AUC')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Validation AUC')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve for Optuna BO XGBoost')\n",
    "plt.show()\n",
    "\n",
    "#learning curve for manual bo model\n",
    "train_sizes, train_scores, test_scores = learning_curve(xgb_manual, X_train_baseline, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training AUC')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Validation AUC')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve for Manual BO XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb7a3b",
   "metadata": {},
   "source": [
    "## 3.3 test_set prediction for both optimized models and baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15dcc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Model trained with baseline parameters\n",
    "y_pred_test_baseline = xgb_baseline.predict_proba(X_test_baseline)[:, 1]\n",
    "auc_baseline_test = roc_auc_score(y_test, y_pred_test_baseline)\n",
    "print(f\"‚úÖ Baseline model TEST AUC: {auc_baseline_test:.6f}\")\n",
    "\n",
    "\n",
    "# Model trained with Optuna best parameters\n",
    "y_pred_test_optuna = xgb_optuna.predict_proba(X_test_baseline)[:, 1]\n",
    "auc_optuna_test = roc_auc_score(y_test, y_pred_test_optuna)\n",
    "print(f\"‚úÖ Optuna model TEST AUC: {auc_optuna_test:.6f}\")\n",
    "\n",
    "# Model trained with manual Bayesian Optimization best parameters\n",
    "y_pred_test_manual = xgb_manual.predict_proba(X_test_baseline)[:, 1]  \n",
    "auc_manual_test = roc_auc_score(y_test, y_pred_test_manual)  \n",
    "print(f\"‚úÖ Manual BO model TEST AUC: {auc_manual_test:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b72704",
   "metadata": {},
   "source": [
    "## 3.4 Comprehensive Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5127a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "y_pred_test_optuna_binary = (y_pred_test_optuna >= 0.5).astype(int)\n",
    "y_pred_test_manual_binary = (y_pred_test_manual >= 0.5).astype(int) \n",
    "y_pred_test_baseline_binary = (y_pred_test_baseline >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"üìä TEST SET PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüéØ OPTUNA OPTIMIZED MODEL:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_optuna_binary):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test_optuna_binary):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test_optuna_binary):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_test_optuna_binary):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_test_optuna):.4f}\")\n",
    "\n",
    "print(\"\\nüîß MANUAL BAYESIAN OPTIMIZED MODEL:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_manual_binary):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test_manual_binary):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test_manual_binary):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_test_manual_binary):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_test_manual):.4f}\")\n",
    "\n",
    "print(\"\\nüìä BASELINE MODEL:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_baseline_binary):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test_baseline_binary):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test_baseline_binary):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_test_baseline_binary):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_test_baseline):.4f}\")\n",
    "\n",
    "\n",
    "# Confusion Matrices\n",
    "print(\"\\nüî¢ CONFUSION MATRICES:\")\n",
    "print(\"\\nOptuna Model:\")\n",
    "print(confusion_matrix(y_test, y_pred_test_optuna_binary))\n",
    "print(\"\\nManual BO Model:\")\n",
    "print(confusion_matrix(y_test, y_pred_test_manual_binary))\n",
    "print(\"\\nBaseline Model:\")\n",
    "print(confusion_matrix(y_test, y_pred_test_baseline_binary))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280af082",
   "metadata": {},
   "source": [
    "## 3.5 Classification Report by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which countries we have based on division prefixes\n",
    "print(\"üåç CLASSIFICATION REPORT BY COUNTRY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extract country information from division columns\n",
    "div_columns = [col for col in X_test_baseline.columns if col.startswith('Div_')]\n",
    "print(f\"Found {len(div_columns)} division columns\")\n",
    "\n",
    "# Get the active divisions for each match (where value = 1)\n",
    "countries_data = []\n",
    "for idx in range(len(X_test_baseline)):\n",
    "    active_divs = [col.replace('Div_', '') for col in div_columns if X_test_baseline.iloc[idx][col] == 1]\n",
    "    if active_divs:\n",
    "        countries_data.append(active_divs[0])  # Take the first (should be only one)\n",
    "    else:\n",
    "        countries_data.append('Unknown')\n",
    "\n",
    "# Create a mapping of common division codes to countries\n",
    "country_mapping = {\n",
    "    'B1': 'Belgium', 'D1': 'Germany', 'D2': 'Germany',\n",
    "    'E0': 'England', 'E1': 'England', 'E2': 'England', 'E3': 'England', 'E4': 'England',\n",
    "    'F1': 'France', 'F2': 'France',\n",
    "    'G1': 'Greece', 'I1': 'Italy', 'I2': 'Italy',\n",
    "    'N1': 'Netherlands', 'P1': 'Portugal',\n",
    "    'SC0': 'Scotland', 'SC1': 'Scotland', 'SC2': 'Scotland', 'SC3': 'Scotland', 'SC4': 'Scotland',\n",
    "    'SP1': 'Spain', 'SP2': 'Spain', 'T1': 'Turkey'\n",
    "}\n",
    "\n",
    "# Map division codes to country names\n",
    "countries = [country_mapping.get(div, div) for div in countries_data]\n",
    "\n",
    "# Get unique countries and their counts\n",
    "country_counts = pd.Series(countries).value_counts()\n",
    "print(f\"\\nüìä Matches per Country:\")\n",
    "for country, count in country_counts.items():\n",
    "    print(f\"   {country}: {count:,} matches\")\n",
    "\n",
    "print(f\"\\nüéØ CLASSIFICATION REPORTS BY COUNTRY:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate classification report for each country with sufficient samples\n",
    "min_samples = 50  # Minimum samples needed for meaningful report\n",
    "significant_countries = country_counts[country_counts >= min_samples].index\n",
    "\n",
    "for country in significant_countries:\n",
    "    # Get indices for this country\n",
    "    country_mask = pd.Series(countries) == country\n",
    "    country_indices = country_mask[country_mask].index\n",
    "    \n",
    "    # Extract predictions and true values for this country\n",
    "    y_true_country = y_test.iloc[country_indices]\n",
    "    \n",
    "    # Use the Manual Bayesian Optimization model instead of Optuna\n",
    "    y_pred_country = y_pred_test_manual_binary[country_indices]\n",
    "    y_pred_proba_country = y_pred_test_manual[country_indices]\n",
    "    \n",
    "    print(f\"\\nüè¥ {country.upper()} ({len(country_indices)} matches)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true_country, y_pred_country)\n",
    "    precision = precision_score(y_true_country, y_pred_country, zero_division=0)\n",
    "    recall = recall_score(y_true_country, y_pred_country, zero_division=0)\n",
    "    f1 = f1_score(y_true_country, y_pred_country, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true_country, y_pred_proba_country)\n",
    "    \n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    \n",
    "    # Get classification report as dictionary to customize output\n",
    "    report_dict = classification_report(y_true_country, y_pred_country, \n",
    "                                      target_names=['Under 2.5', 'Over 2.5'], \n",
    "                                      zero_division=0, output_dict=True)\n",
    "    \n",
    "    # Print only the class-specific metrics (exclude summary rows)\n",
    "    print(f\"{'Class':<12} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<8}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for class_name in ['Under 2.5', 'Over 2.5']:\n",
    "        if class_name in report_dict:\n",
    "            metrics = report_dict[class_name]\n",
    "            print(f\"{class_name:<12} {metrics['precision']:<10.2f} {metrics['recall']:<10.2f} {metrics['f1-score']:<10.2f} {int(metrics['support']):<8}\")\n",
    "    \n",
    "    # Show actual vs predicted distribution\n",
    "    actual_over = y_true_country.mean()\n",
    "    predicted_over = pd.Series(y_pred_country).mean()\n",
    "    print(f\"Actual Over 2.5: {actual_over:.2%}\")\n",
    "    print(f\"Predicted Over 2.5: {predicted_over:.2%}\")\n",
    "\n",
    "# Summary comparison across countries\n",
    "print(f\"\\nüìà COUNTRY PERFORMANCE SUMMARY:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Country':<12} {'Samples':<8} {'Accuracy':<10} {'ROC-AUC':<10} {'Over 2.5%':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for country in significant_countries:\n",
    "    country_mask = pd.Series(countries) == country\n",
    "    country_indices = country_mask[country_mask].index\n",
    "    \n",
    "    y_true_country = y_test.iloc[country_indices]\n",
    "    y_pred_country = y_pred_test_manual_binary[country_indices]\n",
    "    y_pred_proba_country = y_pred_test_manual[country_indices]\n",
    "    \n",
    "    accuracy = accuracy_score(y_true_country, y_pred_country)\n",
    "    roc_auc = roc_auc_score(y_true_country, y_pred_proba_country)\n",
    "    actual_over = y_true_country.mean()\n",
    "    \n",
    "    print(f\"{country:<12} {len(country_indices):<8} {accuracy:<10.4f} {roc_auc:<10.4f} {actual_over:<10.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
