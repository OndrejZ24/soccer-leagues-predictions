{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extended XGBoost Classifier - Soccer O/U 2.5 Goals Prediction\n",
    "\n",
    "**Objective**: Build and evaluate an extended XGBoost classifier using extended soccer match features to predict Over/Under 2.5 goals.\n",
    "\n",
    "**Tasks**:\n",
    "- Load extended preprocessed data\n",
    "- Build extended XGBoost classifier  \n",
    "- Train and validate model\n",
    "- Hyperparameter tuning\n",
    "- Feature importance analysis\n",
    "- Learning curves\n",
    "- Performance comparison (tuned vs untuned)\n",
    "- XGBoost with extended features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=Warning) # Suppress convergence warnings from Gaussian Process\n",
    "\n",
    "\n",
    "#learning curve for baseline model\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, learning_curve, ShuffleSplit\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, classification_report, confusion_matrix,\n",
    "    roc_curve, precision_recall_curve, log_loss\n",
    ")\n",
    "\n",
    "# Bayesian Optimization\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 1.2 Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate comprehensive metrics\n",
    "def evaluate_model(y_true, y_pred, y_pred_proba, model_name=\"Model\"):\n",
    "    \"\"\"Calculate comprehensive classification metrics\"\"\"\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'log_loss': log_loss(y_true, y_pred_proba),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìà {model_name} Performance Metrics:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-Score:  {metrics['f1']:.4f}\")\n",
    "    print(f\"Log Loss:   {metrics['log_loss']:.4f}\")\n",
    "    print(f\"ROC-AUC:   {metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 1.3 Load Extended Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the extended preprocessed data\n",
    "\n",
    "with open('./outputs/processed/extended_preprocessed.pkl', 'rb') as f:\n",
    "    extended_data = pickle.load(f)\n",
    "\n",
    "# Extract all datasets including validation\n",
    "X_train_extended = extended_data['X_train']\n",
    "X_val_extended = extended_data['X_val']\n",
    "X_test_extended = extended_data['X_test'] \n",
    "y_train = extended_data['y_train']\n",
    "y_val = extended_data['y_val']\n",
    "y_test = extended_data['y_test']\n",
    "\n",
    "print(f\"\\nüìä Dataset Shapes:\")\n",
    "print(f\"Training set: {X_train_extended.shape}\")\n",
    "print(f\"Validation set: {X_val_extended.shape}\")\n",
    "print(f\"Test set: {X_test_extended.shape}\")\n",
    "print(f\"Features: {X_train_extended.shape[1]}\")\n",
    "\n",
    "print(f\"\\nüéØ Target Distribution:\")\n",
    "print(f\"Training - Over 2.5: {y_train.mean():.2%}\")\n",
    "print(f\"Validation - Over 2.5: {y_val.mean():.2%}\")\n",
    "print(f\"Test - Over 2.5: {y_test.mean():.2%}\")\n",
    "\n",
    "\n",
    "# Display data split summary\n",
    "total_samples = len(y_train) + len(y_val) + len(y_test)\n",
    "print(f\"\\nüìà Data Split Summary:\")\n",
    "print(f\"Total samples: {total_samples:,}\")\n",
    "print(f\"Training: {len(y_train):,} ({len(y_train)/total_samples:.1%})\")\n",
    "print(f\"Validation: {len(y_val):,} ({len(y_val)/total_samples:.1%})\")\n",
    "print(f\"Test: {len(y_test):,} ({len(y_test)/total_samples:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean feature names - remove characters that XGBoost doesn't allow: [, ], <, >\n",
    "def clean_feature_names(df):\n",
    "    \"\"\"Remove special characters from feature names that XGBoost doesn't allow\"\"\"\n",
    "    df.columns = df.columns.str.replace('[', '(', regex=False)\n",
    "    df.columns = df.columns.str.replace(']', ')', regex=False)\n",
    "    df.columns = df.columns.str.replace('<', 'less_than_', regex=False)\n",
    "    df.columns = df.columns.str.replace('>', 'greater_than_', regex=False)\n",
    "    return df\n",
    "\n",
    "# Clean all datasets\n",
    "X_train_extended = clean_feature_names(X_train_extended)\n",
    "X_val_extended = clean_feature_names(X_val_extended)\n",
    "X_test_extended = clean_feature_names(X_test_extended)\n",
    "\n",
    "print(\"\\n‚úÖ Feature names cleaned for XGBoost compatibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 2 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2.1 Extended model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extended XGBoost classifier with default parameters\n",
    "\n",
    "# Initialize XGBoost with basic parameters\n",
    "xgb_extended = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0  # Suppress training output\n",
    ")\n",
    "\n",
    "\n",
    "# Train the extended XGBoost model\n",
    "xgb_extended.fit(X_train_extended, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_val_pred_extended = xgb_extended.predict(X_val_extended)\n",
    "y_val_pred_proba_extended = xgb_extended.predict_proba(X_val_extended)[:, 1]\n",
    "\n",
    "\n",
    "# Evaluate extended model\n",
    "extended_metrics = evaluate_model(\n",
    "    y_val, y_val_pred_extended, y_val_pred_proba_extended, \n",
    "    \"Extended XGBoost (Validation)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 2.2 Hyperparameter Optimization with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### 2.2.1 Definition of optimized parameters and training training-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna hyperparameter optimization\n",
    "    Returns: log loss score to maximize\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': 0,\n",
    "        \n",
    "        # Tree structure parameters - adjusted for high dimensions (344+ features)\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 30),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 3, 20),\n",
    "        \n",
    "        # Sampling parameters - crucial for high dimensions\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 0.95),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.8),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 0.9),\n",
    "        \n",
    "        # Boosting parameters\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 4000, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.8, log=True),\n",
    "        \n",
    "        # Regularization parameters - stronger for high dimensions\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 20.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 50.0),\n",
    "        \n",
    "        # Advanced parameters\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 10.0),\n",
    "    }\n",
    "    \n",
    "    # Create and train model\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train_extended, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_proba = model.predict_proba(X_val_extended)[:, 1]  # Extract positive class probabilities\n",
    "    \n",
    "    # Return negative log loss (higher is better since we minimize log loss)\n",
    "    logloss = log_loss(y_val, y_pred_proba)\n",
    "    \n",
    "    return -logloss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### 2.2.2 Running optuna optimization with 250 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.3 Run Hyperparameter Optimization\n",
    "\n",
    "# Create study with TPE sampler for efficient search\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # We want to minimize log loss (maximize negative log loss)\n",
    "    sampler=TPESampler(seed=RANDOM_STATE),\n",
    "    study_name='xgboost_soccer_prediction'\n",
    ")\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Run optimization with more trials for high-dimensional space\n",
    "N_TRIALS = 250  # More trials needed for complex parameter space with 344+ features\n",
    "print(f\"üöÄ Running {N_TRIALS} trials for high-dimensional optimization...\")\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "# Calculate optimization time\n",
    "optimization_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Optimization completed in {optimization_time:.1f} seconds\")\n",
    "print(f\"üìä Best Log Loss: {-study.best_value:.6f}\")\n",
    "print(f\"üèÜ Best trial: #{study.best_trial.number}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### 2.2.3 Best parameters according to optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã Best hyperparameters:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"   {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 2.2 Hyperparameter Optimization with manual Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Define objective function (same as Optuna)\n",
    "# --------------------------------------------\n",
    "def evaluate_xgb_manual(params):\n",
    "    \"\"\"Train XGBoost and evaluate Log Loss on validation - matches Optuna objective.\"\"\"\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        # Parameters in same order as bounds array\n",
    "        max_depth=int(params[0]),\n",
    "        min_child_weight=int(params[1]),\n",
    "        subsample=params[2],\n",
    "        colsample_bytree=params[3],\n",
    "        colsample_bylevel=params[4],\n",
    "        n_estimators=int(params[5]),\n",
    "        learning_rate=params[6],\n",
    "        reg_alpha=params[7],\n",
    "        reg_lambda=params[8],\n",
    "        gamma=params[9]\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_extended, y_train)\n",
    "    y_pred_val = model.predict_proba(X_val_extended)[:, 1]  # Extract positive class probabilities\n",
    "    logloss = log_loss(y_val, y_pred_val)\n",
    "    # We minimize log loss directly\n",
    "    return logloss\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Define search space bounds (matching Optuna exactly)\n",
    "# --------------------------------------------\n",
    "param_bounds = np.array([\n",
    "    [4, 30],         # max_depth: 4-30\n",
    "    [3, 20],         # min_child_weight: 3-20\n",
    "    [0.7, 0.95],     # subsample: 0.7-0.95\n",
    "    [0.1, 0.8],      # colsample_bytree: 0.1-0.8\n",
    "    [0.1, 0.9],      # colsample_bylevel: 0.1-0.9\n",
    "    [100, 4000],     # n_estimators: 100-4000\n",
    "    [0.005, 0.8],    # learning_rate: 0.005-0.8\n",
    "    [0.1, 20.0],     # reg_alpha: 0.1-20.0\n",
    "    [1.0, 50.0],     # reg_lambda: 1.0-50.0\n",
    "    [0.1, 10.0],     # gamma: 0.1-10.0\n",
    "])\n",
    "\n",
    "n_params = param_bounds.shape[0]\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Initialize samples (random warm-up)\n",
    "# --------------------------------------------\n",
    "np.random.seed(RANDOM_STATE)\n",
    "N_INIT = 15  # More initial samples for 10-dimensional space\n",
    "\n",
    "\n",
    "X_samples = np.random.uniform(param_bounds[:, 0], param_bounds[:, 1], size=(N_INIT, n_params))\n",
    "Y_samples = np.array([evaluate_xgb_manual(x) for x in X_samples])\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Fit Gaussian Process surrogate\n",
    "# --------------------------------------------\n",
    "kernel = Matern(length_scale=1.0, nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, normalize_y=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Scaler helps GP fit parameters of different magnitudes \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_samples)\n",
    "gp.fit(X_scaled, Y_samples)\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Acquisition function (Upper Confidence Bound)\n",
    "# --------------------------------------------\n",
    "def acquisition_ucb(X, model, kappa=2.0):\n",
    "    \"\"\"Upper Confidence Bound acquisition function\"\"\"\n",
    "    mu, sigma = model.predict(X, return_std=True)\n",
    "    return mu - kappa * sigma  # minimizing log loss\n",
    "\n",
    "def propose_next(model, bounds, n_candidates=3000):\n",
    "    \"\"\"Propose next point to evaluate\"\"\"\n",
    "    candidates = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_candidates, bounds.shape[0]))\n",
    "    candidates_scaled = scaler.transform(candidates)\n",
    "    acq_vals = acquisition_ucb(candidates_scaled, model)\n",
    "    best_idx = np.argmin(acq_vals)\n",
    "    return candidates[best_idx].reshape(1, -1), np.min(acq_vals)\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Iterative Bayesian Optimization loop\n",
    "# --------------------------------------------\n",
    "N_ITER = 250  # More iterations to match Optuna's exploration capacity\n",
    "history_best = [np.min(Y_samples)]\n",
    "\n",
    "print(f\"\\nüöÄ Starting Bayesian Optimization with {N_ITER} iterations...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(N_ITER):\n",
    "    # Propose next point\n",
    "    x_next, acq_val = propose_next(gp, param_bounds)\n",
    "    y_next = evaluate_xgb_manual(x_next[0])\n",
    "    \n",
    "    # Update datasets\n",
    "    X_samples = np.vstack([X_samples, x_next])\n",
    "    Y_samples = np.hstack([Y_samples, y_next])\n",
    "\n",
    "    # Refit Gaussian Process\n",
    "    X_scaled = scaler.fit_transform(X_samples)\n",
    "    gp.fit(X_scaled, Y_samples)\n",
    "\n",
    "    # Track progress\n",
    "    history_best.append(np.min(Y_samples))\n",
    "    current_best_logloss = np.min(Y_samples)\n",
    "    \n",
    "    if (i + 1) % 10 == 0 or i < 5:  # Print progress every 10 iterations\n",
    "        print(f\"Iteration {i+1:02d}: Best Log Loss = {current_best_logloss:.5f}\")\n",
    "\n",
    "optimization_time = time.time() - start_time\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Final results and comparison\n",
    "# --------------------------------------------\n",
    "best_idx = np.argmin(Y_samples)\n",
    "best_params_array = X_samples[best_idx]\n",
    "best_logloss = Y_samples[best_idx]\n",
    "\n",
    "\n",
    "\n",
    "# Create parameter dictionary in same format as Optuna\n",
    "param_names = [\"max_depth\", \"min_child_weight\", \"subsample\", \"colsample_bytree\",\n",
    "               \"colsample_bylevel\", \"n_estimators\", \"learning_rate\", \"reg_alpha\",\n",
    "               \"reg_lambda\", \"gamma\"]\n",
    "\n",
    "# Convert to dictionary format matching Optuna output\n",
    "manual_bo_params = {}\n",
    "for i, name in enumerate(param_names):\n",
    "    if name in [\"max_depth\", \"min_child_weight\", \"n_estimators\"]:\n",
    "        manual_bo_params[name] = int(best_params_array[i])\n",
    "    else:\n",
    "        manual_bo_params[name] = float(best_params_array[i])\n",
    "\n",
    "print(f\"\\nüìã Best hyperparameters found:\")\n",
    "for name, val in manual_bo_params.items():\n",
    "    if isinstance(val, int):\n",
    "        print(f\"  {name:18}: {val}\")\n",
    "    else:\n",
    "        print(f\"  {name:18}: {val:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nüèÜ Manual Bayesian Optimization Results:\")\n",
    "print(f\"‚è±Ô∏è  Optimization time: {optimization_time:.1f} seconds\")\n",
    "print(f\"üéØ Best validation Log Loss: {best_logloss:.6f}\")\n",
    "print(f\"üìä Total evaluations: {len(Y_samples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 2.3 Comparison of optuna vs manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### 2.3.1 Best parameters according to both approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract best parameters from Optuna study\n",
    "optuna_params = study.best_params\n",
    "optuna_logloss = -study.best_value\n",
    "\n",
    "print(f\"\\nüìä Comparison of Best Hyperparameters:\")\n",
    "print(f\"{'Parameter':<18} {'Optuna':<15}        {'Manual BO':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for param in param_names:\n",
    "    optuna_val = optuna_params.get(param, 'N/A')\n",
    "    manual_val = manual_bo_params.get(param, 'N/A')\n",
    "    \n",
    "    if isinstance(manual_val, int):\n",
    "        print(f\"{param:<18} {optuna_val:<15}              {manual_val:<15}\")\n",
    "    else:\n",
    "        \n",
    "        print(f\"{param:<18} {optuna_val:<15}         {manual_val:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ Best Log Loss Comparison:\")\n",
    "print(f\"Optuna Log Loss:    {optuna_logloss:.6f}\")\n",
    "print(f\"Manual BO Log Loss: {best_logloss:.6f}\")\n",
    "print(f\"Difference:    {abs(optuna_logloss - best_logloss):.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 2.4 Training Models with optimized parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Model trained with Optuna best parameters\n",
    "xgb_optuna = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    "    **optuna_params\n",
    ")\n",
    "\n",
    "xgb_optuna.fit(X_train_extended, y_train)\n",
    "y_pred_val_optuna = xgb_optuna.predict_proba(X_val_extended)[:, 1]\n",
    "log_loss_optuna = log_loss(y_val, y_pred_val_optuna)\n",
    "print(f\"‚úÖ Optuna model Log Loss: {log_loss_optuna:.6f}\")\n",
    "\n",
    "# Model trained with Manual Bayesian Optimization best parameters  \n",
    "xgb_manual = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    "    **manual_bo_params\n",
    ")\n",
    "\n",
    "xgb_manual.fit(X_train_extended, y_train)\n",
    "y_pred_val_manual = xgb_manual.predict_proba(X_val_extended)[:, 1]  # Extract positive class probabilities\n",
    "log_loss_manual = log_loss(y_val, y_pred_val_manual)\n",
    "print(f\"‚úÖ Manual BO model Log Loss: {log_loss_manual:.6f}\")\n",
    "\n",
    "print(f\"\\nüìä Final Validation Results (Optimized for Log Loss):\")\n",
    "print(f\"Extended XGBoost:     Log Loss = {extended_metrics['log_loss']:.6f} | Accuracy = {extended_metrics['accuracy']:.6f}\")\n",
    "print(f\"Optuna Optimized:     Log Loss = {log_loss_optuna:.6f} | Accuracy = {accuracy_score(y_val, (y_pred_val_optuna >= 0.5).astype(int)):.6f}\")\n",
    "print(f\"Manual BO Optimized:  Log Loss = {log_loss_manual:.6f} | Accuracy = {accuracy_score(y_val, (y_pred_val_manual >= 0.5).astype(int)):.6f}\")\n",
    "print(f\"\\nüèÜ Best Log Loss: {min(extended_metrics['log_loss'], log_loss_optuna, log_loss_manual):.6f}\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 2.5 Final Model Training on Train + Validation Data\n",
    "\n",
    "**Important Methodological Note:**\n",
    "\n",
    "While hyperparameters were optimized using:\n",
    "- **Training data**: 2019-2023 seasons (for model fitting during optimization)\n",
    "- **Validation data**: 2023/2024 season (for hyperparameter selection)\n",
    "\n",
    "The **final models** for test evaluation are retrained on the **combined train+validation dataset** (2019-2024) to:\n",
    "1. ‚úÖ Use all available historical data before predicting 2024/2025\n",
    "2. ‚úÖ Provide maximum seasonal context (5 full seasons vs 4)\n",
    "3. ‚úÖ Maintain proper evaluation: test set (2024/2025) was never used in tuning or training\n",
    "\n",
    "This approach is standard practice in time-series ML: tune on historical splits, then retrain on all available data before final deployment/evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### 2.5.1 Combine Train and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and validation data for final model training\n",
    "# This gives us 2019-2024 seasons for training before predicting 2024/2025\n",
    "\n",
    "X_train_full = pd.concat([X_train_extended, X_val_extended], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "# Reset indices to ensure clean indexing\n",
    "X_train_full.reset_index(drop=True, inplace=True)\n",
    "y_train_full.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"üìä Combined Training Data (Train + Validation):\")\n",
    "print(f\"Features: {X_train_full.shape}\")\n",
    "print(f\"Samples: {len(y_train_full):,}\")\n",
    "print(f\"  - Original Train: {len(y_train):,} (2019-2023)\")\n",
    "print(f\"  - Original Val:   {len(y_val):,} (2023/2024)\")\n",
    "print(f\"  - Combined:       {len(y_train_full):,} (2019-2024)\")\n",
    "print(f\"\\nTarget Distribution (Combined): {y_train_full.mean():.2%} Over 2.5 goals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "#### 2.5.2 Retrain Final Models on Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1. Baseline Extended Model (retrained on full data) =====\n",
    "print(\"üîÑ Training Baseline Extended model on Train+Val data...\")\n",
    "\n",
    "xgb_extended_final = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_extended_final.fit(X_train_full, y_train_full)\n",
    "print(\"‚úÖ Baseline Extended model trained on combined data\")\n",
    "\n",
    "\n",
    "# ===== 2. Optuna-Optimized Model (retrained on full data) =====\n",
    "print(\"\\nüîÑ Training Optuna-optimized model on Train+Val data...\")\n",
    "\n",
    "xgb_optuna_final = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    "    **optuna_params  # Use best hyperparameters from Optuna\n",
    ")\n",
    "\n",
    "xgb_optuna_final.fit(X_train_full, y_train_full)\n",
    "print(\"‚úÖ Optuna-optimized model trained on combined data\")\n",
    "\n",
    "\n",
    "# ===== 3. Manual BO-Optimized Model (retrained on full data) =====\n",
    "print(\"\\nüîÑ Training Manual BO-optimized model on Train+Val data...\")\n",
    "\n",
    "xgb_manual_final = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    "    **manual_bo_params  # Use best hyperparameters from Manual BO\n",
    ")\n",
    "\n",
    "xgb_manual_final.fit(X_train_full, y_train_full)\n",
    "print(\"‚úÖ Manual BO-optimized model trained on combined data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ All final models ready for test set evaluation\")\n",
    "print(\"   Training data: 2019-2024 (Train + Validation)\")\n",
    "print(\"   Test data:     2024/2025 (Unseen)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# 3 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## 3.1 Feature Importance in All Three Final Models (Trained on Train+Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot feature importance for extended model (final version trained on train+val)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_importance(xgb_extended_final, max_num_features=10)\n",
    "plt.title(\"Extended XGBoost Feature Importance (Trained on 2019-2024)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot feature importance for optuna optimized model (final version)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_importance(xgb_optuna_final, max_num_features=10)\n",
    "plt.title(\"Optuna BO XGBoost Feature Importance (Trained on 2019-2024)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot feature importance for manual BO optimized model (final version)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_importance(xgb_manual_final, max_num_features=10)\n",
    "plt.title(\"Manual BO XGBoost Feature Importance (Trained on 2019-2024)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## 3.2 Learning Curves (From Hyperparameter Tuning Phase)\n",
    "\n",
    "**Note:** These learning curves show model behavior during the hyperparameter tuning phase (trained only on 2019-2023 data). They help diagnose overfitting/underfitting but are not from the final models used for test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "train_sizes, train_scores, test_scores = learning_curve(xgb_extended, X_train_extended, y_train, cv=cv, scoring='neg_log_loss', n_jobs=-1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, -np.mean(train_scores, axis=1), label='Training Log Loss')\n",
    "plt.plot(train_sizes, -np.mean(test_scores, axis=1), label='Validation Log Loss')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve for Extended XGBoost (Log Loss)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#learning curve for optuna bo model\n",
    "train_sizes, train_scores, test_scores = learning_curve(xgb_optuna, X_train_extended, y_train, cv=cv, scoring='neg_log_loss', n_jobs=-1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, -np.mean(train_scores, axis=1), label='Training Log Loss')\n",
    "plt.plot(train_sizes, -np.mean(test_scores, axis=1), label='Validation Log Loss')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve for Optuna BO XGBoost (Log Loss)')\n",
    "plt.show()\n",
    "\n",
    "#learning curve for manual bo model\n",
    "train_sizes, train_scores, test_scores = learning_curve(xgb_manual, X_train_extended, y_train, cv=cv, scoring='neg_log_loss', n_jobs=-1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, -np.mean(train_scores, axis=1), label='Training Log Loss')\n",
    "plt.plot(train_sizes, -np.mean(test_scores, axis=1), label='Validation Log Loss')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve for Manual BO XGBoost (Log Loss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## 3.3 Test Set Predictions (Final Models Trained on Train+Val)\n",
    "\n",
    "**Critical Note:** These predictions use models retrained on the **combined 2019-2024 data** (train+validation), not the models trained only on 2019-2023. This ensures maximum use of historical data before predicting 2024/2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ===== FINAL MODEL PREDICTIONS (Trained on Train+Val 2019-2024) =====\n",
    "\n",
    "# Baseline Extended model (trained on full data)\n",
    "y_pred_test_extended = xgb_extended_final.predict_proba(X_test_extended)[:, 1]\n",
    "log_loss_extended_test = log_loss(y_test, y_pred_test_extended)\n",
    "print(f\"‚úÖ Extended model (Train+Val) TEST Log Loss: {log_loss_extended_test:.6f}\")\n",
    "\n",
    "\n",
    "# Optuna-optimized model (trained on full data)\n",
    "y_pred_test_optuna = xgb_optuna_final.predict_proba(X_test_extended)[:, 1]\n",
    "log_loss_optuna_test = log_loss(y_test, y_pred_test_optuna)\n",
    "print(f\"‚úÖ Optuna model (Train+Val) TEST Log Loss: {log_loss_optuna_test:.6f}\")\n",
    "\n",
    "# Manual BO-optimized model (trained on full data)\n",
    "y_pred_test_manual = xgb_manual_final.predict_proba(X_test_extended)[:, 1]  \n",
    "log_loss_manual_test = log_loss(y_test, y_pred_test_manual)  \n",
    "print(f\"‚úÖ Manual BO model (Train+Val) TEST Log Loss: {log_loss_manual_test:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä All predictions made on 2024/2025 test set\")\n",
    "print(\"   Models were trained on: 2019-2024 (Train+Validation)\")\n",
    "print(\"   Test set was NEVER used in training or tuning\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## 3.4 Comprehensive Test Set Evaluation (Final Models - Train+Val)\n",
    "\n",
    "**These are the definitive results:** All models below were retrained on the combined 2019-2024 data before evaluation on the unseen 2024/2025 test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "y_pred_test_optuna_binary = (y_pred_test_optuna >= 0.5).astype(int)\n",
    "y_pred_test_manual_binary = (y_pred_test_manual >= 0.5).astype(int) \n",
    "y_pred_test_extended_binary = (y_pred_test_extended >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"üìä TEST SET PERFORMANCE COMPARISON (2024/2025 Season)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"All models trained on: 2019-2024 (Train + Validation)\")\n",
    "print(\"Evaluated on: 2024/2025 (Unseen Test Set)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüéØ OPTUNA OPTIMIZED MODEL (Train+Val):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_optuna_binary):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test_optuna_binary):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test_optuna_binary):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_test_optuna_binary):.4f}\")\n",
    "print(f\"Log Loss:   {log_loss(y_test, y_pred_test_optuna):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_test_optuna):.4f}\")\n",
    "\n",
    "print(\"\\nüîß MANUAL BAYESIAN OPTIMIZED MODEL (Train+Val):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_manual_binary):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test_manual_binary):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test_manual_binary):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_test_manual_binary):.4f}\")\n",
    "print(f\"Log Loss:   {log_loss(y_test, y_pred_test_manual):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_test_manual):.4f}\")\n",
    "\n",
    "print(\"\\nüìä BASELINE EXTENDED MODEL (Train+Val):\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_extended_binary):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test_extended_binary):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test_extended_binary):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_test_extended_binary):.4f}\")\n",
    "print(f\"Log Loss:   {log_loss(y_test, y_pred_test_extended):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_test_extended):.4f}\")\n",
    "\n",
    "\n",
    "# Confusion Matrices\n",
    "print(\"\\nüî¢ CONFUSION MATRICES:\")\n",
    "print(\"\\nOptuna Model (Train+Val):\")\n",
    "print(confusion_matrix(y_test, y_pred_test_optuna_binary))\n",
    "print(\"\\nManual BO Model (Train+Val):\")\n",
    "print(confusion_matrix(y_test, y_pred_test_manual_binary))\n",
    "print(\"\\nBaseline Extended Model (Train+Val):\")\n",
    "print(confusion_matrix(y_test, y_pred_test_extended_binary))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ These are the final, unbiased performance metrics\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## 3.5 Classification Report by Country (Using Final Manual BO Model)\n",
    "\n",
    "**Model Used:** Manual BO XGBoost trained on 2019-2024 data, evaluated on 2024/2025 test set per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which countries we have based on division prefixes\n",
    "print(\"üåç CLASSIFICATION REPORT BY COUNTRY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extract country information from division columns\n",
    "div_columns = [col for col in X_test_extended.columns if col.startswith('Div_')]\n",
    "print(f\"Found {len(div_columns)} division columns\")\n",
    "\n",
    "# Get the active divisions for each match (where value = 1)\n",
    "countries_data = []\n",
    "for idx in range(len(X_test_extended)):\n",
    "    active_divs = [col.replace('Div_', '') for col in div_columns if X_test_extended.iloc[idx][col] == 1]\n",
    "    if active_divs:\n",
    "        countries_data.append(active_divs[0])  # Take the first (should be only one)\n",
    "    else:\n",
    "        countries_data.append('Unknown')\n",
    "\n",
    "# Create a mapping of common division codes to countries\n",
    "country_mapping = {\n",
    "    'B1': 'Belgium', 'D1': 'Germany', 'D2': 'Germany',\n",
    "    'E0': 'England', 'E1': 'England', 'E2': 'England', 'E3': 'England', 'E4': 'England',\n",
    "    'F1': 'France', 'F2': 'France',\n",
    "    'G1': 'Greece', 'I1': 'Italy', 'I2': 'Italy',\n",
    "    'N1': 'Netherlands', 'P1': 'Portugal',\n",
    "    'SC0': 'Scotland', 'SC1': 'Scotland', 'SC2': 'Scotland', 'SC3': 'Scotland', 'SC4': 'Scotland',\n",
    "    'SP1': 'Spain', 'SP2': 'Spain', 'T1': 'Turkey'\n",
    "}\n",
    "\n",
    "# Map division codes to country names\n",
    "countries = [country_mapping.get(div, div) for div in countries_data]\n",
    "\n",
    "# Get unique countries and their counts\n",
    "country_counts = pd.Series(countries).value_counts()\n",
    "print(f\"\\nüìä Matches per Country:\")\n",
    "for country, count in country_counts.items():\n",
    "    print(f\"   {country}: {count:,} matches\")\n",
    "\n",
    "print(f\"\\nüéØ CLASSIFICATION REPORTS BY COUNTRY:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate classification report for each country with sufficient samples\n",
    "min_samples = 50  # Minimum samples needed for meaningful report\n",
    "significant_countries = country_counts[country_counts >= min_samples].index\n",
    "\n",
    "for country in significant_countries:\n",
    "    # Get indices for this country\n",
    "    country_mask = pd.Series(countries) == country\n",
    "    country_indices = country_mask[country_mask].index\n",
    "    \n",
    "    # Extract predictions and true values for this country\n",
    "    y_true_country = y_test.iloc[country_indices]\n",
    "    \n",
    "    # Use the Manual Bayesian Optimization model instead of Optuna\n",
    "    y_pred_country = y_pred_test_manual_binary[country_indices]\n",
    "    y_pred_proba_country = y_pred_test_manual[country_indices]\n",
    "    \n",
    "    print(f\"\\nüè¥ {country.upper()} ({len(country_indices)} matches)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true_country, y_pred_country)\n",
    "    precision = precision_score(y_true_country, y_pred_country, zero_division=0)\n",
    "    recall = recall_score(y_true_country, y_pred_country, zero_division=0)\n",
    "    f1 = f1_score(y_true_country, y_pred_country, zero_division=0)\n",
    "    log_loss_value = log_loss(y_true_country, y_pred_proba_country)\n",
    "    roc_auc = roc_auc_score(y_true_country, y_pred_proba_country)\n",
    "    \n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"Log Loss:   {log_loss_value:.4f}\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    \n",
    "    # Get classification report as dictionary to customize output\n",
    "    report_dict = classification_report(y_true_country, y_pred_country, \n",
    "                                      target_names=['Under 2.5', 'Over 2.5'], \n",
    "                                      zero_division=0, output_dict=True)\n",
    "    \n",
    "    # Print only the class-specific metrics (exclude summary rows)\n",
    "    print(f\"{'Class':<12} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<8}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for class_name in ['Under 2.5', 'Over 2.5']:\n",
    "        if class_name in report_dict:\n",
    "            metrics = report_dict[class_name]\n",
    "            print(f\"{class_name:<12} {metrics['precision']:<10.2f} {metrics['recall']:<10.2f} {metrics['f1-score']:<10.2f} {int(metrics['support']):<8}\")\n",
    "    \n",
    "    # Show actual vs predicted distribution\n",
    "    actual_over = y_true_country.mean()\n",
    "    predicted_over = pd.Series(y_pred_country).mean()\n",
    "    print(f\"Actual Over 2.5: {actual_over:.2%}\")\n",
    "    print(f\"Predicted Over 2.5: {predicted_over:.2%}\")\n",
    "\n",
    "# Summary comparison across countries\n",
    "print(f\"üìà COUNTRY PERFORMANCE SUMMARY:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Country':<12} {'Samples':<8} {'Accuracy':<10} {'Log Loss':<10} {'ROC-AUC':<10} {'Over 2.5%':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for country in significant_countries:\n",
    "    country_mask = pd.Series(countries) == country\n",
    "    country_indices = country_mask[country_mask].index\n",
    "    \n",
    "    y_true_country = y_test.iloc[country_indices]\n",
    "    y_pred_country = y_pred_test_manual_binary[country_indices]\n",
    "    y_pred_proba_country = y_pred_test_manual[country_indices]\n",
    "    \n",
    "    accuracy = accuracy_score(y_true_country, y_pred_country)\n",
    "    roc_auc = roc_auc_score(y_true_country, y_pred_proba_country)\n",
    "    log_loss_value = log_loss(y_true_country, y_pred_proba_country)\n",
    "    actual_over = y_true_country.mean()\n",
    "    \n",
    "    print(f\"{country:<12} {len(country_indices):<8} {accuracy:<10.4f} {log_loss_value:<10.4f} {roc_auc:<10.4f} {actual_over:<10.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python soccer-venv",
   "language": "python",
   "name": "soccer-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
