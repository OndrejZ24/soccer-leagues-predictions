{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML2 Semestral Project - Football O/U 2.5\n",
    "**Authors:** Phuong Nhi Tranová, Vít Maruniak, Šimon Slánský, Radim Šoukal, Ondřej Zetek, Martin Kareš, Jan Korčák, Jakub Maličkay, Jáchym Janouch  \n",
    "**Course:** FIS 4IT344 Machine Learning 2 (2025/2026)  \n",
    "**Goal:** Compare baseline (current features) vs extended (richer features) models for O/U 2.5 goals across markets; translate accuracy gains into optimal profit and **maximum data subscription price per country** *.  \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "***maximum data subscription price per country**\n",
    "- the most money our company should be willing to pay for that country's additional data\n",
    "- that's how much extra profit the improved model generates\n",
    "- baseline model → accuracy = A₀\n",
    "    - Generates profit Π*(A₀)\n",
    "- extended model → accuracy = A₁\n",
    "    - Generates profit Π*(A₁)\n",
    "- profit improvement = ΔΠ = Π(A₁) − Π(A₀)*\n",
    "    - basically how much more money the comany earns each year by using the better data\n",
    "- the maximum data subscription price per country = ΔΠ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports and paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore, chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Library parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "OUTPUT_DIR = f\"./outputs/processed\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_matches(data_dir: str) -> pd.DataFrame:\n",
    "    csv_files = glob.glob(os.path.join(data_dir, \"**\", \"*.csv\"), recursive=True)\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found under {data_dir}\")\n",
    "\n",
    "    frames = []\n",
    "    for fp in csv_files:\n",
    "        # extract path info\n",
    "        rel = os.path.relpath(fp, data_dir)\n",
    "        parts = Path(rel).parts\n",
    "        country = parts[0] if len(parts) >= 1 else None\n",
    "        league  = parts[1] if len(parts) >= 2 else None\n",
    "        season_file = parts[2] if len(parts) >= 3 else None\n",
    "        season_code = os.path.splitext(season_file)[0] if season_file else None\n",
    "\n",
    "        # read and rename\n",
    "        try:\n",
    "            df = pd.read_csv(fp, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {fp}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Format season as YYYY/YYYY format\n",
    "        if season_code and len(season_code) == 4 and season_code.isdigit():\n",
    "            # Handle formats like \"1920\" or \"2021\"\n",
    "            year1 = int(season_code[:2])\n",
    "            year2 = int(season_code[2:])\n",
    "\n",
    "            # Determine century based on year range\n",
    "            if year1 >= 19 and year1 <= 24:  # 19-24 maps to 2019-2024\n",
    "                year1_full = 2000 + year1\n",
    "            else:\n",
    "                year1_full = 1900 + year1\n",
    "\n",
    "            if year2 >= 19 and year2 <= 99:\n",
    "                if year2 < year1:  # Next year (e.g., 19->20, 23->24)\n",
    "                    year2_full = 2000 + year2\n",
    "                else:\n",
    "                    year2_full = 2000 + year2\n",
    "            else:\n",
    "                year2_full = 1900 + year2\n",
    "\n",
    "            season_formatted = f\"{year1_full}/{year2_full}\"\n",
    "        else:\n",
    "            season_formatted = season_code  # Fallback to original if format is unexpected\n",
    "\n",
    "        # Add Season column right after Div (if Div exists)\n",
    "        if 'Div' in df.columns:\n",
    "            div_idx = df.columns.get_loc('Div')\n",
    "            df.insert(div_idx + 1, 'Season', season_formatted)\n",
    "        else:\n",
    "            df['Season'] = season_formatted\n",
    "\n",
    "        frames.append(df)\n",
    "\n",
    "    all_df = pd.concat(frames, ignore_index=True, sort=False)\n",
    "    return all_df\n",
    "\n",
    "# run the loader\n",
    "all_matches = pd.DataFrame(load_all_matches(DATA_DIR))\n",
    "print(all_matches.columns.tolist())\n",
    "print(all_matches.shape)\n",
    "display(all_matches.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis\n",
    "\n",
    "Before proceeding with data cleaning, let's understand our data better through comprehensive exploratory data analysis. This will help us make informed decisions about preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Shape and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset shape: {all_matches.shape}\")\n",
    "print(f\"Number of seasons/countries covered:\")\n",
    "print(f\"Countries: {all_matches['Div'].str[:-1].nunique()}\")\n",
    "print(f\"Leagues: {all_matches['Div'].nunique()}\")\n",
    "print(f\"Date range: {all_matches['Date'].min()} to {all_matches['Date'].max()}\")\n",
    "\n",
    "# Check basic statistics\n",
    "print(f\"\\nBasic goal statistics:\")\n",
    "print(f\"Total goals per match stats:\")\n",
    "total_goals = all_matches['FTHG'] + all_matches['FTAG']\n",
    "print(total_goals.describe())\n",
    "\n",
    "print(f\"\\nOver/Under 2.5 goals distribution:\")\n",
    "over_2_5 = (total_goals > 2.5).astype(int)\n",
    "print(f\"Over 2.5: {over_2_5.sum()} ({over_2_5.mean():.2%})\")\n",
    "print(f\"Under 2.5: {(~over_2_5.astype(bool)).sum()} ({(1-over_2_5.mean()):.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our target variable (Over/Under 2.5 goals) is perfectly balanced with almost exactly 50/50 split, which is ideal for classification. Mainly because the model won't be biased toward either class and we can use standard accuracy but also because we won't have to do any kind of resampling or rebalancing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed missing values analysis\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'column': all_matches.columns,\n",
    "    'missing_count': all_matches.isnull().sum(),\n",
    "    'missing_percentage': (all_matches.isnull().sum() / len(all_matches)) * 100,\n",
    "    'dtype': all_matches.dtypes\n",
    "})\n",
    "\n",
    "# Filter to show only columns with missing values\n",
    "missing_analysis = missing_analysis[missing_analysis['missing_count'] > 0].sort_values('missing_percentage', ascending=False)\n",
    "\n",
    "print(f\"Columns with missing values: {len(missing_analysis)}\")\n",
    "print(f\"Total columns: {len(all_matches.columns)}\")\n",
    "print(f\"\\nTop 20 columns with highest missing percentage:\")\n",
    "display(missing_analysis.head(20))\n",
    "\n",
    "# Check missing patterns in key variables\n",
    "key_stats = ['HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "print(f\"\\nMissing data in key match statistics:\")\n",
    "for stat in key_stats:\n",
    "    if stat in all_matches.columns:\n",
    "        missing_pct = (all_matches[stat].isnull().sum() / len(all_matches)) * 100\n",
    "        print(f\"{stat}: {missing_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing data analysis reveals that:\n",
    "1. **Betting odds** have the highest missing percentages (80%+) - this is expected as not all bookmakers operate in all leagues/seasons\n",
    "2. **Key match statistics** (shots, corners, fouls, cards) have very low missing rates (<0.1%), which is excellent for our modeling\n",
    "3. Most missing data is in betting-related columns, which we can handle appropriately\n",
    "\n",
    "also we have found 4 unnamed columns that are 100% missing. they're most likely artifacts from csv exports so they're definitely safe to drop outright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets do a bit more of a in depth analysis, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = all_matches.copy()\n",
    "\n",
    "# missingness flag\n",
    "stats_cols = ['HS','AS','HST','AST','HF','AF','HC','AC','HY','AY','HR','AR']\n",
    "for c in stats_cols:\n",
    "    if c in raw.columns:\n",
    "        raw[f'isna_{c}'] = raw[c].isna().astype(int)\n",
    "\n",
    "# Row-level summary: how many of the 12 stats are missing in the same row?\n",
    "flag_cols = [f'isna_{c}' for c in stats_cols if f'isna_{c}' in raw.columns]\n",
    "raw['missing_count_stats'] = raw[flag_cols].sum(axis=1)\n",
    "\n",
    "# Quick overview\n",
    "print(raw['missing_count_stats'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the rows seem to have no missigness/ However, there are 41 rows that have are missing all 12 variables, which seems pretty clustered. Suggesting that the missing data likely stem from a specific data source or a batch issue rather than random omission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single-stat missing % (already computed as flags)\n",
    "single_rates = (raw[flag_cols].mean() * 100)\n",
    "single_rates.index = [c.replace('isna_', '') for c in single_rates.index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,4))\n",
    "ax.bar(single_rates.index, single_rates.values)\n",
    "ax.set_title('Missingness by variables (%)')\n",
    "ax.set_ylabel('% missing')\n",
    "ax.set_xlabel('stat')\n",
    "ax.set_xticklabels(single_rates.index, rotation=45, ha='right')\n",
    "for i, v in enumerate(single_rates.values):\n",
    "    ax.text(i, v, f'{v:.3f}%', ha='center', va='bottom', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "misigness seems uniformly low across all variables, there seems to be no issue with a variable specific collection issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "cmap = 'plasma'\n",
    "\n",
    "# Extract country from Div column (e.g., 'E1' -> 'E', 'SP2' -> 'SP')\n",
    "raw['country_code'] = raw['Div'].str[:-1]\n",
    "\n",
    "# 1️⃣ Country × Stat\n",
    "if 'country_code' in raw.columns:\n",
    "    M1 = raw.groupby('country_code')[flag_cols].mean().mul(100)\n",
    "    order = M1.mean(axis=1).sort_values(ascending=False).index\n",
    "    M1 = M1.loc[order]\n",
    "    M1.columns = [c.replace('isna_', '') for c in M1.columns]\n",
    "\n",
    "    im1 = axes[0].imshow(M1.values, aspect='auto', cmap=cmap)\n",
    "    axes[0].set_xticks(np.arange(M1.shape[1]))\n",
    "    axes[0].set_xticklabels(M1.columns, rotation=45, ha='right')\n",
    "    axes[0].set_yticks(np.arange(M1.shape[0]))\n",
    "    axes[0].set_yticklabels(M1.index)\n",
    "    axes[0].set_title('Country × Stat')\n",
    "    fig.colorbar(im1, ax=axes[0], label='% missing')\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, \"Missing 'Div' column\", ha='center', va='center')\n",
    "    axes[0].set_axis_off()\n",
    "\n",
    "# 2️⃣ Year × Stat (using Date column)\n",
    "if 'Date' in raw.columns:\n",
    "    raw['year'] = pd.to_datetime(raw['Date']).dt.year\n",
    "    M2 = raw.groupby('year')[flag_cols].mean().mul(100)\n",
    "    order = M2.mean(axis=1).sort_values(ascending=False).index\n",
    "    M2 = M2.loc[order]\n",
    "    M2.columns = [c.replace('isna_', '') for c in M2.columns]\n",
    "\n",
    "    im2 = axes[1].imshow(M2.values, aspect='auto', cmap=cmap)\n",
    "    axes[1].set_xticks(np.arange(M2.shape[1]))\n",
    "    axes[1].set_xticklabels(M2.columns, rotation=45, ha='right')\n",
    "    axes[1].set_yticks(np.arange(M2.shape[0]))\n",
    "    axes[1].set_yticklabels(M2.index.astype(int))\n",
    "    axes[1].set_title('Year × Stat')\n",
    "    fig.colorbar(im2, ax=axes[1], label='% missing')\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, \"Missing 'Date' column\", ha='center', va='center')\n",
    "    axes[1].set_axis_off()\n",
    "\n",
    "# 3️⃣ Year × Country\n",
    "needed = {'year', 'country_code'}\n",
    "if needed.issubset(raw.columns):\n",
    "    G = raw.groupby(['year','country_code'])[flag_cols].mean().mul(100)\n",
    "    G['avg_missing'] = G.mean(axis=1)\n",
    "    year_order  = G['avg_missing'].groupby(level=0).mean().sort_values(ascending=False).index\n",
    "    country_order = G['avg_missing'].groupby(level=1).mean().sort_values(ascending=False).index\n",
    "    P3 = (G['avg_missing'].unstack('country_code')\n",
    "          .reindex(index=year_order, columns=country_order)\n",
    "          .fillna(0))\n",
    "\n",
    "    im3 = axes[2].imshow(P3.values, aspect='auto', cmap=cmap)\n",
    "    axes[2].set_xticks(np.arange(P3.shape[1]))\n",
    "    axes[2].set_xticklabels(P3.columns, rotation=45, ha='right')\n",
    "    axes[2].set_yticks(np.arange(P3.shape[0]))\n",
    "    axes[2].set_yticklabels(P3.index.astype(int))\n",
    "    axes[2].set_title('Year × Country')\n",
    "    fig.colorbar(im3, ax=axes[2], label='% missing')\n",
    "else:\n",
    "    axes[2].text(0.5, 0.5, \"Missing required columns\", ha='center', va='center')\n",
    "    axes[2].set_axis_off()\n",
    "\n",
    "# 4️⃣ Country × League\n",
    "needed = {'country_code', 'Div'}\n",
    "if needed.issubset(raw.columns):\n",
    "    G = raw.groupby(['country_code', 'Div'])[flag_cols].mean().mul(100)\n",
    "    G['avg_missing'] = G.mean(axis=1)\n",
    "    P4 = (G['avg_missing'].unstack('Div').fillna(0))\n",
    "    country_order = P4.mean(axis=1).sort_values(ascending=False).index\n",
    "    league_order  = P4.mean(axis=0).sort_values(ascending=False).index\n",
    "    P4 = P4.loc[country_order, league_order]\n",
    "\n",
    "    im4 = axes[3].imshow(P4.values, aspect='auto', cmap=cmap)\n",
    "    axes[3].set_xticks(np.arange(P4.shape[1]))\n",
    "    axes[3].set_xticklabels(P4.columns, rotation=45, ha='right')\n",
    "    axes[3].set_yticks(np.arange(P4.shape[0]))\n",
    "    axes[3].set_yticklabels(P4.index)\n",
    "    axes[3].set_title('Country × League')\n",
    "    fig.colorbar(im4, ax=axes[3], label='% missing')\n",
    "else:\n",
    "    axes[3].text(0.5, 0.5, \"Missing required columns\", ha='center', va='center')\n",
    "    axes[3].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first heatmap shows missing data by country. Turkey has the most missing data by far, with over 1.4 percent missing on average. All other countries have very little missing data, less than 0.5 percent each.\n",
    "\n",
    "The second heatmap shows missing data by year. The years 2023 has more missing data than the other years.\n",
    "\n",
    "The third heatmap combines year and country together. It shows that Turkey has most missing values in 2023. In other years, the missingness is not so bad.\n",
    "\n",
    "The fourth heatmap shows missing data by country and league division. Again, Turkey's T1 division stands out with the highest missing data. Within each country, different league divisions have similar amounts of missing data, which means the problem is more about the country than about which league tier we look at. We've researched and found out that the cause was because of an earthquake.\n",
    "\n",
    "Overall, the missing data is not random. It is concentrated mainly in Turkey and in the year 2023 for the division T1, which is very odd and definitely a mistake because its turkeys top division, meaning missing data in this group is wrong. we'll need to drop that later.\n",
    "\n",
    "Now, we'll also check the missingness across different teams, differentiating home vs away teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_cols  = [f'isna_{c}' for c in stats_cols if f'isna_{c}' in raw.columns]\n",
    "top_n      = 15\n",
    "min_matches_ref = 50   # ignore refs with tiny sample sizes\n",
    "\n",
    "def group_missing_rate(df, key):\n",
    "    \"\"\"Return DataFrame with avg % missing across 12 stats, plus counts.\"\"\"\n",
    "    grp = df.groupby(key)[flag_cols]\n",
    "    rate = grp.mean().mul(100).mean(axis=1)\n",
    "    cnt  = df.groupby(key).size()\n",
    "    out  = pd.DataFrame({'rate': rate, 'n': cnt}).sort_values('rate', ascending=False)\n",
    "    return out\n",
    "\n",
    "home_df = group_missing_rate(raw, 'HomeTeam') if 'HomeTeam' in raw.columns else pd.DataFrame()\n",
    "away_df = group_missing_rate(raw, 'AwayTeam') if 'AwayTeam' in raw.columns else pd.DataFrame()\n",
    "ref_df  = group_missing_rate(raw, 'Referee')  if 'Referee'  in raw.columns else pd.DataFrame()\n",
    "if not ref_df.empty:\n",
    "    ref_df = ref_df[ref_df['n'] >= min_matches_ref].sort_values('rate', ascending=False)\n",
    "\n",
    "# merge for Home vs Away comparison (teams present in both)\n",
    "both = pd.DataFrame()\n",
    "if not home_df.empty and not away_df.empty:\n",
    "    both = (home_df[['rate']].rename(columns={'rate': 'home_rate'})\n",
    "            .merge(away_df[['rate']], left_index=True, right_index=True, how='inner')\n",
    "            .rename(columns={'rate': 'away_rate'}))\n",
    "    both['diff'] = both['home_rate'] - both['away_rate']\n",
    "    both = both.sort_values('home_rate', ascending=False).head(top_n)\n",
    "\n",
    "\n",
    "# checking missingness by home vs away team\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "if not home_df.empty:\n",
    "    htop = home_df.head(top_n)[::-1]\n",
    "    axes[0].barh(htop.index.astype(str), htop['rate'].values, color='#8c564b')\n",
    "    axes[0].set_title('Missingness by HomeTeam (avg % across stats)')\n",
    "    axes[0].set_xlabel('% missing')\n",
    "    for y, (r, n) in enumerate(zip(htop['rate'].values, htop['n'].values)):\n",
    "        axes[0].text(r, y, f'  {r:.2f}% (n={n})', va='center', ha='left', fontsize=9)\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, \"HomeTeam column not found\", ha='center', va='center')\n",
    "    axes[0].set_axis_off()\n",
    "\n",
    "if not away_df.empty:\n",
    "    atop = away_df.head(top_n)[::-1]\n",
    "    axes[1].barh(atop.index.astype(str), atop['rate'].values, color='#1f77b4')\n",
    "    axes[1].set_title('Missingness by AwayTeam (avg % across stats)')\n",
    "    axes[1].set_xlabel('% missing')\n",
    "    for y, (r, n) in enumerate(zip(atop['rate'].values, atop['n'].values)):\n",
    "        axes[1].text(r, y, f'  {r:.2f}% (n={n})', va='center', ha='left', fontsize=9)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, \"AwayTeam column not found\", ha='center', va='center')\n",
    "    axes[1].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization compares the average percentage of missing match statistics for each team when playing at home (brown dots) versus away (blue dots). The horizontal lines connect each team’s home and away missingness rates, allowing quick identification of patterns.\n",
    "\n",
    "Most teams show very little difference between home and away games, suggesting that data gaps are not related to the venue. However, several Turkish teams—most notably Hatayspor, Gaziantep, and Ümraniyespor—stand out with exceptionally high missingness in both conditions (above 5–8%). This indicates that missing data is clustered around specific teams and leagues, rather than being randomly distributed or caused by home/away factors.\n",
    "\n",
    "Overall, the visualization reinforces that the missingness originates from Turkey and its not random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missigness for referees\n",
    "if not ref_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    rtop = ref_df.head(top_n)[::-1]\n",
    "    ax.barh(rtop.index.astype(str), rtop['rate'].values, color='#9467bd')\n",
    "    ax.set_title(f'Missingness by Referee (avg % across stats, n≥{min_matches_ref})')\n",
    "    ax.set_xlabel('% missing')\n",
    "    for y, (r, n) in enumerate(zip(rtop['rate'].values, rtop['n'].values)):\n",
    "        ax.text(r, y, f'  {r:.2f}% (n={n})', va='center', ha='left', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No referees pass the sample-size filter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the most problematic referee seems to be D Williams at 0.56%, followed by C Napier at 0.53% and A Newlands and C Scott, the rest of the referees indicate no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Sanity Checks\n",
    "\n",
    "Before moving forward, we need to verify that our data makes logical sense. We will check if the relationships between different columns are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_issues = []\n",
    "\n",
    "# check 1: Full time goals should be >= half time goals\n",
    "print(\"\\nFull Time Goals >= Half Time Goals\")\n",
    "ht_ft_home_check = all_matches['FTHG'] >= all_matches['HTHG']\n",
    "ht_ft_away_check = all_matches['FTAG'] >= all_matches['HTAG']\n",
    "home_violations = (~ht_ft_home_check).sum()\n",
    "away_violations = (~ht_ft_away_check).sum()\n",
    "print(f\"Home goals violations: {home_violations}\")\n",
    "print(f\"Away goals violations: {away_violations}\")\n",
    "if home_violations > 0 or away_violations > 0:\n",
    "    sanity_issues.append(f\"FT goals < HT goals: {home_violations + away_violations} cases\")\n",
    "\n",
    "# check 2: Full time result should match actual goals\n",
    "print(\"\\nFull Time Result matches actual goals\")\n",
    "ftr_check = pd.Series(index=all_matches.index, dtype=bool)\n",
    "ftr_check = (\n",
    "    ((all_matches['FTR'] == 'H') & (all_matches['FTHG'] > all_matches['FTAG'])) |\n",
    "    ((all_matches['FTR'] == 'A') & (all_matches['FTAG'] > all_matches['FTHG'])) |\n",
    "    ((all_matches['FTR'] == 'D') & (all_matches['FTHG'] == all_matches['FTAG']))\n",
    ")\n",
    "ftr_violations = (~ftr_check).sum()\n",
    "print(f\"FTR mismatches: {ftr_violations}\")\n",
    "if ftr_violations > 0:\n",
    "    sanity_issues.append(f\"FTR doesn't match goals: {ftr_violations} cases\")\n",
    "\n",
    "# check 3: Half time result should match half time goals\n",
    "print(\"\\nChecking: Half Time Result matches half time goals\")\n",
    "htr_check = pd.Series(index=all_matches.index, dtype=bool)\n",
    "htr_check = (\n",
    "    ((all_matches['HTR'] == 'H') & (all_matches['HTHG'] > all_matches['HTAG'])) |\n",
    "    ((all_matches['HTR'] == 'A') & (all_matches['HTAG'] > all_matches['HTHG'])) |\n",
    "    ((all_matches['HTR'] == 'D') & (all_matches['HTHG'] == all_matches['HTAG']))\n",
    ")\n",
    "htr_violations = (~htr_check).sum()\n",
    "print(f\"HTR mismatches: {htr_violations}\")\n",
    "if htr_violations > 0:\n",
    "    sanity_issues.append(f\"HTR doesn't match HT goals: {htr_violations} cases\")\n",
    "\n",
    "# check 4: Shots on target should be <= total shots\n",
    "print(\"\\nShots on Target <= Total Shots\")\n",
    "home_shot_check = all_matches['HST'] <= all_matches['HS']\n",
    "away_shot_check = all_matches['AST'] <= all_matches['AS']\n",
    "home_shot_violations = (~home_shot_check).sum()\n",
    "away_shot_violations = (~away_shot_check).sum()\n",
    "print(f\"Home shots violations: {home_shot_violations}\")\n",
    "print(f\"Away shots violations: {away_shot_violations}\")\n",
    "if home_shot_violations > 0 or away_shot_violations > 0:\n",
    "    sanity_issues.append(f\"Shots on target > total shots: {home_shot_violations + away_shot_violations} cases\")\n",
    "\n",
    "# check 5: Goals should be <= shots on target (generally, but not always)\n",
    "print(\"\\nGoals <= Shots on Target (usually)\")\n",
    "home_goals_shots_check = all_matches['FTHG'] <= all_matches['HST']\n",
    "away_goals_shots_check = all_matches['FTAG'] <= all_matches['AST']\n",
    "home_goals_violations = (~home_goals_shots_check).sum()\n",
    "away_goals_violations = (~away_goals_shots_check).sum()\n",
    "print(f\"Home goals > shots on target: {home_goals_violations}\")\n",
    "print(f\"Away goals > shots on target: {away_goals_violations}\")\n",
    "print(f\"Note: Some violations are possible due to own goals or deflections\")\n",
    "if home_goals_violations > 10 or away_goals_violations > 10:\n",
    "    sanity_issues.append(f\"Goals > shots on target: {home_goals_violations + away_goals_violations} cases (check if excessive)\")\n",
    "\n",
    "# check 6: Red cards should be <= yellow cards + red cards\n",
    "print(\"\\nCard counts are reasonable\")\n",
    "home_red_check = all_matches['HR'] <= (all_matches['HY'] + all_matches['HR'])\n",
    "away_red_check = all_matches['AR'] <= (all_matches['AY'] + all_matches['AR'])\n",
    "print(f\"Home card logic violations: {(~home_red_check).sum()}\")\n",
    "print(f\"Away card logic violations: {(~away_red_check).sum()}\")\n",
    "\n",
    "# check 7: Negative values check\n",
    "print(\"\\nNo negative values in count columns\")\n",
    "count_columns = ['FTHG', 'FTAG', 'HTHG', 'HTAG', 'HS', 'AS', 'HST', 'AST',\n",
    "                'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "negative_found = False\n",
    "for col in count_columns:\n",
    "    if col in all_matches.columns:\n",
    "        negative_count = (all_matches[col] < 0).sum()\n",
    "        if negative_count > 0:\n",
    "            print(f\"{col}: {negative_count} negative values\")\n",
    "            negative_found = True\n",
    "            sanity_issues.append(f\"{col} has {negative_count} negative values\")\n",
    "if not negative_found:\n",
    "    print(f\"No negative values found\")\n",
    "\n",
    "# check 8: Extreme values check\n",
    "print(\"\\nExtreme values that might be data errors\")\n",
    "extreme_checks = {\n",
    "    'FTHG': 15,\n",
    "    'FTAG': 15,\n",
    "    'HS': 50,\n",
    "    'AS': 50,\n",
    "    'HC': 30,\n",
    "    'AC': 30,\n",
    "    'HY': 10,\n",
    "    'AY': 10,\n",
    "    'HR': 5,\n",
    "    'AR': 5\n",
    "}\n",
    "for col, threshold in extreme_checks.items():\n",
    "    if col in all_matches.columns:\n",
    "        extreme_count = (all_matches[col] > threshold).sum()\n",
    "        if extreme_count > 0:\n",
    "            max_value = all_matches[col].max()\n",
    "            print(f\"{col} > {threshold}: {extreme_count} cases (max: {max_value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sanity checks help us verify that the data is internally consistent. We check things like full time goals being at least as many as half time goals, that the match result codes match the actual goal counts, that shots on target do not exceed total shots, and that there are no negative values in count columns. These checks help identify data entry errors or corruption before we use the data for modeling.\n",
    "\n",
    "Our data passed most checks well. Full time goals are always at least as many as half time goals, which is correct. The full time result codes match the actual scores perfectly.\n",
    "\n",
    "We found 41 matches where the half time result code does not match the half time goals. This is a small number out of 42,593 matches, so it is likely just data entry errors in those specific matches.\n",
    "\n",
    "We found 6 matches where shots on target are higher than total shots. This is probably a recording error but only affects 6 matches so it is not a big problem.\n",
    "\n",
    "We found 234 matches where a team scored more goals than they had shots on target. This can happen in real football due to own goals or deflections, so these are not necessarily errors.\n",
    "\n",
    "We found one match where a team got 9 red cards. This is extremely unusual and might be a data error, but it is only one match out of thousands.\n",
    "\n",
    "Overall, the data quality is very good. The few issues we found affect less than 1 percent of matches and will not significantly impact our model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Matches and Goals Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# League distribution\n",
    "league_counts = all_matches['Div'].value_counts()\n",
    "print(\"League distribution:\")\n",
    "display(league_counts)\n",
    "\n",
    "# Country mapping for better understanding\n",
    "country_mapping = {\n",
    "    'E': 'England', 'SC': 'Scotland', 'SP': 'Spain', 'I': 'Italy',\n",
    "    'D': 'Germany', 'F': 'France', 'N': 'Netherlands', 'B': 'Belgium',\n",
    "    'P': 'Portugal', 'T': 'Turkey', 'G': 'Greece'\n",
    "}\n",
    "\n",
    "all_matches['Country'] = all_matches['Div'].str[:-1].map(country_mapping)\n",
    "country_counts = all_matches['Country'].value_counts()\n",
    "print(f\"\\nMatches per country:\")\n",
    "display(country_counts)\n",
    "\n",
    "# Visualize the distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Country distribution\n",
    "country_counts_sorted = country_counts.dropna().sort_values(ascending=False)\n",
    "bars = ax1.bar(country_counts_sorted.index, country_counts_sorted.values, color='skyblue')\n",
    "ax1.set_title('Matches per Country')\n",
    "ax1.set_xlabel('Country')\n",
    "ax1.set_ylabel('Number of Matches')\n",
    "ax1.tick_params(axis='x', rotation=30)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# data labels\n",
    "for rect in bars:\n",
    "    height = rect.get_height()\n",
    "    ax1.text(rect.get_x() + rect.get_width()/2, height, f\"{int(height):,}\",\n",
    "             ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Goals distribution\n",
    "total_goals = all_matches['FTHG'] + all_matches['FTAG']\n",
    "max_g = int(np.nanmax(total_goals))\n",
    "bins = np.arange(-0.5, max(10, max_g) + 1.5, 1)\n",
    "\n",
    "ax2.hist(total_goals, bins=bins, color='lightcoral', alpha=0.7)\n",
    "ax2.axvline(x=2.5, linestyle='--', linewidth=2, label='2.5 goals threshold')\n",
    "ax2.set_title('Distribution of Total Goals per Match')\n",
    "ax2.set_xlabel('Total Goals')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_xticks(range(0, max(10, max_g) + 1))\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, matches from England account for the majority of the data. This is due to England having 4 divisions compared to other countries that have 1 or 2.\n",
    "Also, the distribution of total goals per match is right-skewed, with a mode around 2–3 goals. The red dashed line at 2.5 goals marks the classification threshold for our target variable. Visually, the mass on either side of this threshold is roughly equal, which confirms the balanced 50/50 split observed in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Handling the missing values\n",
    "Let's begin with the most obvious one - some csv issues that immediately noticed in our EDA.\n",
    "\n",
    "It seems like the renaming and loading went smoothly! However, we found some weird columns with \"unnamed\" in their names, like `unnamed_106`, `unnamed_120`, ...  \n",
    "\n",
    "That sometimes happens when excel files have extra blank columns. We'll take a quick look to see if they have any data, and if they're totally empty (full of NaNs), we'll just get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnamed_cols = [c for c in all_matches.columns if c.lower().startswith(\"unnamed\")]\n",
    "all_matches[unnamed_cols].isna().mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're 100% full of NaNs so we can now safely drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = all_matches.drop(columns=unnamed_cols)\n",
    "\n",
    "print(f\"\\nMissing data in key match statistics:\")\n",
    "for stat in key_stats:\n",
    "    if stat in all_matches.columns:\n",
    "        missing_pct = (all_matches[stat].isnull().sum() / len(all_matches)) * 100\n",
    "        print(f\"{stat}: {missing_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets drop turkey's data in 2023, because it was the most problematic - the highest missignesness because of the earhquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SECTION NEEDS TO BE CORRECTED \n",
    "original_rows = len(raw)\n",
    "\n",
    "# Remove Turkey data for 2023 and division T1\n",
    "raw = raw[~((raw['country_code'] == 'T') & (raw['year'] == 2023))]  # Remove Turkey in 2023\n",
    "raw = raw[~((raw['country_code'] == 'T') & (raw['Div'] == 'T1'))]  # Remove Turkey's top division (T1)\n",
    "\n",
    "print(f\"Removed {original_rows - len(raw)} rows (Turkey in 2023 and T1 matches) ({(original_rows - len(raw))/original_rows*100:.1f}%)\")\n",
    "print(f\"Remaining: {len(raw)} rows\\n\")\n",
    "print(f\"Overall missing: {raw[flag_cols].mean().mean() * 100:.4f}%\\n\")\n",
    "\n",
    "# Generate heatmaps to check missingness after removal\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "cmap = 'plasma'\n",
    "\n",
    "# Country × Stat\n",
    "M1 = raw.groupby('country_code')[flag_cols].mean().mul(100)\n",
    "order = M1.mean(axis=1).sort_values(ascending=False).index\n",
    "M1 = M1.loc[order]\n",
    "M1.columns = [c.replace('isna_', '') for c in M1.columns]\n",
    "\n",
    "im1 = axes[0].imshow(M1.values, aspect='auto', cmap=cmap)\n",
    "axes[0].set_xticks(np.arange(M1.shape[1]))\n",
    "axes[0].set_xticklabels(M1.columns, rotation=45, ha='right')\n",
    "axes[0].set_yticks(np.arange(M1.shape[0]))\n",
    "axes[0].set_yticklabels(M1.index)\n",
    "axes[0].set_title('Country × Stat (after Turkey removal)')\n",
    "fig.colorbar(im1, ax=axes[0], label='% missing')\n",
    "\n",
    "# Year × Stat\n",
    "M2 = raw.groupby('year')[flag_cols].mean().mul(100)\n",
    "order = M2.mean(axis=1).sort_values(ascending=False).index\n",
    "M2 = M2.loc[order]\n",
    "M2.columns = [c.replace('isna_', '') for c in M2.columns]\n",
    "\n",
    "im2 = axes[1].imshow(M2.values, aspect='auto', cmap=cmap)\n",
    "axes[1].set_xticks(np.arange(M2.shape[1]))\n",
    "axes[1].set_xticklabels(M2.columns, rotation=45, ha='right')\n",
    "axes[1].set_yticks(np.arange(M2.shape[0]))\n",
    "axes[1].set_yticklabels(M2.index.astype(int))\n",
    "axes[1].set_title('Year × Stat (after Turkey removal)')\n",
    "fig.colorbar(im2, ax=axes[1], label='% missing')\n",
    "\n",
    "# Year × Country\n",
    "G = raw.groupby(['year', 'country_code'])[flag_cols].mean().mul(100)\n",
    "G['avg_missing'] = G.mean(axis=1)\n",
    "year_order = G['avg_missing'].groupby(level=0).mean().sort_values(ascending=False).index\n",
    "country_order = G['avg_missing'].groupby(level=1).mean().sort_values(ascending=False).index\n",
    "P3 = (G['avg_missing'].unstack('country_code')\n",
    "      .reindex(index=year_order, columns=country_order)\n",
    "      .fillna(0))\n",
    "\n",
    "im3 = axes[2].imshow(P3.values, aspect='auto', cmap=cmap)\n",
    "axes[2].set_xticks(np.arange(P3.shape[1]))\n",
    "axes[2].set_xticklabels(P3.columns, rotation=45, ha='right')\n",
    "axes[2].set_yticks(np.arange(P3.shape[0]))\n",
    "axes[2].set_yticklabels(P3.index.astype(int))\n",
    "axes[2].set_title('Year × Country (after Turkey removal)')\n",
    "fig.colorbar(im3, ax=axes[2], label='% missing')\n",
    "\n",
    "# Country × League\n",
    "G = raw.groupby(['country_code', 'Div'])[flag_cols].mean().mul(100)\n",
    "G['avg_missing'] = G.mean(axis=1)\n",
    "P4 = (G['avg_missing'].unstack('Div').fillna(0))\n",
    "country_order = P4.mean(axis=1).sort_values(ascending=False).index\n",
    "league_order = P4.mean(axis=0).sort_values(ascending=False).index\n",
    "P4 = P4.loc[country_order, league_order]\n",
    "\n",
    "im4 = axes[3].imshow(P4.values, aspect='auto', cmap=cmap)\n",
    "axes[3].set_xticks(np.arange(P4.shape[1]))\n",
    "axes[3].set_xticklabels(P4.columns, rotation=45, ha='right')\n",
    "axes[3].set_yticks(np.arange(P4.shape[0]))\n",
    "axes[3].set_yticklabels(P4.index)\n",
    "axes[3].set_title('Country × League (after Turkey removal)')\n",
    "fig.colorbar(im4, ax=axes[3], label='% missing')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing Turkey matches, the missing data problem is almost completely solved. The heatmaps now show very low missingness across all countries, years, and leagues. The overall missing percentage dropped significantly, confirming that Turkey was the main source of missing data. The remaining missing values are minimal, except for Belgium, and spread evenly across the dataset, which is acceptable for analysis. In Belgium's case, it's not worth dropping it because the % is low and we'd lose quite a lot of data by dropping it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Normalizing league codes\n",
    "Let's normalize the leagues, as English and Scottish leagues have the best leagues interpreted as E0, SC0, respectively. All other countries mark the best league as CountryCode1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = all_matches['Div'].str.startswith(('E', 'SC'))\n",
    "all_matches.loc[mask, 'Div'] = all_matches.loc[mask, 'Div'].apply(\n",
    "    lambda x: f\"{x[:-1]}{int(x[-1]) + 1}\"\n",
    ")\n",
    "\n",
    "print(all_matches['Div'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Handling English and Scottish yellow cards\n",
    "We need to take care of the first note in notex.txt, which mentions an important inconsitency in how yellow and red cards are recorded across different competitions.  \n",
    "\n",
    "In English and Scottish leagues, when a player receives a second yellow card that leads to a red card, the initial yellow card is not counted in the match statistics, only the red card is recorded. However, European and international competitions record both: the second yellow is counted as an additional yellow card plus a red card \n",
    "\n",
    "As a result, yellow card totals in English and Scottish matches can underestimate the true number of yellow cards compared to other leagues. To correct for this and ensure consistency across competitions, we applied a simple adjustment:\n",
    "- whenever a team has exactly one red card and one yellow card, we add one additional yellow card.\n",
    "- and if a team has 0 reds, 2 or more reds, or 1 red but no yellows, we make no adjustment.\n",
    "\n",
    "We acknowledge that this rule is an approximation, our adjustment may not always be the case and it may introduce some bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = all_matches['Div'].str.startswith(('E', 'SC'))\n",
    "red_mask = mask & ((all_matches['HR'] == 1) | (all_matches['AR'] == 1))\n",
    "\n",
    "print(\"Before adjustment (sample):\")\n",
    "print(all_matches.loc[red_mask, ['Div', 'HY', 'HR', 'AY', 'AR']].head())\n",
    "\n",
    "all_matches.loc[mask & (all_matches['HR'] == 1) & (all_matches['HY'] != 0), 'HY'] += 1\n",
    "all_matches.loc[mask & (all_matches['AR'] == 1) & (all_matches['AY'] != 0), 'AY'] += 1\n",
    "\n",
    "print(\"\\nAfter adjustment (sample):\")\n",
    "print(all_matches.loc[red_mask, ['Div', 'HY', 'HR', 'AY', 'AR']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Correcting data types\n",
    "Now, let's inspect the data types of our columns. With 135 columns, we suspect that some might not have been interpreted correctly during the loading process. Checking the data types is an important step before proceeding with any further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, dtype in all_matches.dtypes.items():\n",
    "    print(f\"{col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_columns = ['Date', 'Time']\n",
    "\n",
    "category_columns = ['Div', 'HomeTeam', 'AwayTeam', 'FTR', 'HTR', 'Referee', 'Country']\n",
    "\n",
    "int_columns = ['FTHG', 'FTAG', 'HTHG', 'HTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "\n",
    "float_columns = ['B365CH', 'BWCA', '1XBH']\n",
    "\n",
    "for col in time_columns:\n",
    "    if col == 'Date':\n",
    "        all_matches[col] = pd.to_datetime(all_matches[col])\n",
    "    else:\n",
    "        all_matches[col] = pd.to_datetime(all_matches[col], format='%H:%M').dt.time\n",
    "\n",
    "for col in category_columns:\n",
    "    if col in all_matches.columns:\n",
    "        all_matches[col] = all_matches[col].astype('category')\n",
    "\n",
    "for col in int_columns:\n",
    "    all_matches[col] = pd.to_numeric(all_matches[col], errors='coerce').astype('Int64')\n",
    "\n",
    "for col in float_columns:\n",
    "    all_matches[col] = pd.to_numeric(all_matches[col], errors='coerce').astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, dtype in all_matches.dtypes.items():\n",
    "    print(f\"{col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Outlier detection and handling\n",
    "\n",
    "Following the methodology from Week1 (house pricing), we'll use z-score analysis to detect outliers in match statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_stats_cols = ['HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "numerical_cols = ['FTHG', 'FTAG', 'HTHG', 'HTAG'] + match_stats_cols\n",
    "\n",
    "# calculating the z-scores for numerical columns\n",
    "print(\"Outlier analysis using z-score > 3:\")\n",
    "outlier_counts = {}\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col in all_matches.columns:\n",
    "        z_scores = np.abs(zscore(all_matches[col].dropna()))\n",
    "        outliers = (z_scores > 3).sum()\n",
    "        outlier_counts[col] = outliers\n",
    "        if outliers > 0:\n",
    "            print(f\"{col}: {outliers} outliers ({outliers/len(all_matches)*100:.2f}%)\")\n",
    "\n",
    "# looking at extreme cases\n",
    "print(f\"\\nExamples of potential outliers:\")\n",
    "print(f\"Highest total goals: {all_matches['FTHG'].max() + all_matches['FTAG'].max()}\")\n",
    "print(f\"Most shots in a match: {all_matches['HS'].max() + all_matches['AS'].max()}\")\n",
    "print(f\"Most cards in a match: {all_matches['HY'].max() + all_matches['AY'].max()}\")\n",
    "\n",
    "# visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "key_vars = ['FTHG', 'FTAG', 'HS', 'AS']\n",
    "\n",
    "for i, var in enumerate(key_vars):\n",
    "    row, col = i // 2, i % 2\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    # boxplot\n",
    "    all_matches[var].plot(kind='box', ax=ax)\n",
    "    ax.set_title(f'Box Plot of {var}')\n",
    "    ax.set_ylabel(var)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# For football data, we'll be more conservative with outlier removal\n",
    "# as extreme scores can be legitimate (unlike house prices)\n",
    "print(f\"\\nDecision: Keep outliers for football data as high scores/stats can be legitimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're retaining all outliers, high-scoring games are rare but comoletely valid so removing them could distort the true distribution football outcomes. They're meaningful observations that contribute to the model performance rather than noise and removing them would risk eliminating the rare but informative matches that influence the O/U probabilitites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature engineering\n",
    "\n",
    "Based on soccer domain knowledge and the course materials, we'll create meaningful features that could help predict Over/Under 2.5 goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Target variable construction\n",
    "We're creating the main target variable and checking how common each outcome is. We've also created an alternative targets, different goal lines to see their thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the main target variable: Over/Under 2.5 goals\n",
    "all_matches['total_goals'] = all_matches['FTHG'] + all_matches['FTAG']\n",
    "all_matches['over_2_5'] = (all_matches['total_goals'] > 2.5).astype(int)\n",
    "\n",
    "print(\"Target variable distribution:\")\n",
    "print(all_matches['over_2_5'].value_counts())\n",
    "print(f\"Over 2.5 rate: {all_matches['over_2_5'].mean():.2%}\")\n",
    "\n",
    "# also creating some alternative targets for analysis\n",
    "all_matches['over_1_5'] = (all_matches['total_goals'] > 1.5).astype(int)\n",
    "all_matches['over_3_5'] = (all_matches['total_goals'] > 3.5).astype(int)\n",
    "\n",
    "print(f\"\\nOther thresholds:\")\n",
    "print(f\"Over 1.5 rate: {all_matches['over_1_5'].mean():.2%}\")\n",
    "print(f\"Over 3.5 rate: {all_matches['over_3_5'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Basic feature engineering\n",
    "\n",
    "We're creating features that capture match dynamics and team performance patterns. The features are only created from match statisstics after the match - these features won't be allowed into training the prediction model or else we'd be creating data leakage. \n",
    "\n",
    "These newly created features will be then used to compute historical aggregates like moving averages, which represent what was known before the match - which is allowed. After computing the moving averages and seasonal trends, we will delete these features because they're just temporary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTANT: These are TEMPORARY INTERMEDIATE FEATURES\n",
    "# ============================================================================\n",
    "# These features are created from post-match statistics (HS, AS, HST, etc.)\n",
    "# that are only known AFTER a match is played. They are NOT used directly\n",
    "# in the final model.\n",
    "#\n",
    "# PURPOSE: These intermediate features are used to calculate:\n",
    "# 1. Moving averages (MA5) for extended dataset features\n",
    "# 2. Seasonal patterns and team statistics\n",
    "#\n",
    "# These raw features will be REMOVED in Section 4.6 before model training.\n",
    "# Only their aggregated historical versions (MA5, seasonal stats) will remain,\n",
    "# which ARE valid predictors as they represent past performance.\n",
    "# ============================================================================\n",
    "\n",
    "# Basic engineered features (TEMPORARY - for intermediate calculations only)\n",
    "all_matches['home_shot_accuracy'] = all_matches['HST'] / (all_matches['HS'] + 0.001)\n",
    "all_matches['away_shot_accuracy'] = all_matches['AST'] / (all_matches['AS'] + 0.001)\n",
    "all_matches['total_shots'] = all_matches['HS'] + all_matches['AS']\n",
    "all_matches['total_shots_on_target'] = all_matches['HST'] + all_matches['AST']\n",
    "\n",
    "# 2. Attacking vs Defensive balance (TEMPORARY)\n",
    "all_matches['shot_dominance'] = (all_matches['HS'] - all_matches['AS']) / (all_matches['HS'] + all_matches['AS'] + 0.001)\n",
    "all_matches['corner_dominance'] = (all_matches['HC'] - all_matches['AC']) / (all_matches['HC'] + all_matches['AC'] + 0.001)\n",
    "\n",
    "# 3. Game intensity features (TEMPORARY)\n",
    "all_matches['total_fouls'] = all_matches['HF'] + all_matches['AF']\n",
    "all_matches['total_cards'] = all_matches['HY'] + all_matches['AY'] + all_matches['HR'] + all_matches['AR']\n",
    "all_matches['card_intensity'] = all_matches['total_cards'] / (all_matches['total_fouls'] + 0.001)\n",
    "\n",
    "# 4. Half-time patterns (TEMPORARY)\n",
    "all_matches['ht_total_goals'] = all_matches['HTHG'] + all_matches['HTAG']\n",
    "all_matches['second_half_goals'] = all_matches['total_goals'] - all_matches['ht_total_goals']\n",
    "\n",
    "# 5. League tier (can be used directly - known before match)\n",
    "all_matches['league_tier'] = all_matches['Div'].str[-1].astype(int)\n",
    "\n",
    "# 6. Season timing features (can be used directly - known before match)\n",
    "all_matches['month'] = all_matches['Date'].dt.month\n",
    "all_matches['is_weekend'] = all_matches['Date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "\n",
    "print(\"Basic engineered features created (note: post-match stats are temporary).\")\n",
    "print(\"These will be used to calculate historical aggregates, then removed before modeling.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Baseline - feature engineering\n",
    "We'll begin by constructing the core feature set and adding essential engineered variables that serve as the foundation for all subsequent modeling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with core and basic engineered features\n",
    "df_basic = all_matches[['Div', 'Season', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR',\n",
    "                   'total_goals', 'league_tier', 'month', 'is_weekend', \"over_2_5\"]].copy()\n",
    "# by date for time-based features\n",
    "df_basic = df_basic.sort_values(['Div', 'Date']).reset_index(drop=True)\n",
    "print(f\"Columns: {df_basic.columns.tolist()}\")\n",
    "df_basic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Days since last match\n",
    "\n",
    "We want to calculate how many days have passed since last match team's previous match for both home and away teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days since last match for each team\n",
    "df_basic['home_days_since_last'] = np.nan\n",
    "df_basic['away_days_since_last'] = np.nan\n",
    "for team in df_basic['HomeTeam'].unique():\n",
    "    home_mask = df_basic['HomeTeam'] == team\n",
    "    away_mask = df_basic['AwayTeam'] == team\n",
    "    team_matches = df_basic[home_mask | away_mask].sort_values('Date')\n",
    "    #days between matches\n",
    "    team_matches['days_diff'] = team_matches['Date'].diff().dt.days\n",
    "    # to home/away columns\n",
    "    for idx, row in team_matches.iterrows():\n",
    "        if df_basic.loc[idx, 'HomeTeam'] == team:\n",
    "            df_basic.loc[idx, 'home_days_since_last'] = row['days_diff']\n",
    "        else:\n",
    "            df_basic.loc[idx, 'away_days_since_last'] = row['days_diff']\n",
    "# first matches filling with median\n",
    "df_basic['home_days_since_last'].fillna(df_basic['home_days_since_last'].median(), inplace=True)\n",
    "df_basic['away_days_since_last'].fillna(df_basic['away_days_since_last'].median(), inplace=True)\n",
    "\n",
    "print(f\"Home days since last - mean: {df_basic['home_days_since_last'].mean():.1f}, median: {df_basic['home_days_since_last'].median():.1f}\")\n",
    "print(f\"Away days since last - mean: {df_basic['away_days_since_last'].mean():.1f}, median: {df_basic['away_days_since_last'].median():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems ok, the usual pause is one week, which is expected, but they are visible pauses between individual seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Moving Averages \n",
    "\n",
    "We're creating form features - how many goals a team has been scoring and conceding recentlym based on yhe last 5 matches seperately for home and away teams. AKA we've calculated 5-match moving averages (MA5) for goals scored and conceded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic['home_goals_ma5'] = np.nan\n",
    "df_basic['home_conceded_ma5'] = np.nan\n",
    "df_basic['away_goals_ma5'] = np.nan\n",
    "df_basic['away_conceded_ma5'] = np.nan\n",
    "\n",
    "for team in df_basic['HomeTeam'].unique():\n",
    "\n",
    "    # Home matches\n",
    "    home_mask = df_basic['HomeTeam'] == team\n",
    "    home_dates = df_basic[home_mask].sort_values('Date').index\n",
    "    for i, idx in enumerate(home_dates):\n",
    "        if i >= 5:\n",
    "            last_5_home = df_basic.loc[home_dates[i-5:i]]\n",
    "            df_basic.loc[idx, 'home_goals_ma5'] = last_5_home['FTHG'].mean()\n",
    "            df_basic.loc[idx, 'home_conceded_ma5'] = last_5_home['FTAG'].mean()\n",
    "\n",
    "    # Away matches\n",
    "    away_mask = df_basic['AwayTeam'] == team\n",
    "    away_dates = df_basic[away_mask].sort_values('Date').index\n",
    "\n",
    "    for i, idx in enumerate(away_dates):\n",
    "        if i >= 5:\n",
    "            last_5_away = df_basic.loc[away_dates[i-5:i]]\n",
    "            df_basic.loc[idx, 'away_goals_ma5'] = last_5_away['FTAG'].mean()\n",
    "            df_basic.loc[idx, 'away_conceded_ma5'] = last_5_away['FTHG'].mean()\n",
    "\n",
    "# NaN values remain for teams' first 5 matches - will be handled by model\n",
    "# or imputed during train/test split using only training data\n",
    "print(f\"\\nMA5 Statistics (NaN preserved for early-season matches):\")\n",
    "print(f\"home_goals_ma5    - mean: {df_basic['home_goals_ma5'].mean():.2f}, missing: {df_basic['home_goals_ma5'].isna().sum()}\")\n",
    "print(f\"away_goals_ma5    - mean: {df_basic['away_goals_ma5'].mean():.2f}, missing: {df_basic['away_goals_ma5'].isna().sum()}\")\n",
    "print(f\"home_conceded_ma5 - mean: {df_basic['home_conceded_ma5'].mean():.2f}, missing: {df_basic['home_conceded_ma5'].isna().sum()}\")\n",
    "print(f\"away_conceded_ma5 - mean: {df_basic['away_conceded_ma5'].mean():.2f}, missing: {df_basic['away_conceded_ma5'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent the data leakage, the moving-average features: home_goals_ma5, home_conceded_ma5, away_goals_ma5, away_conceded_ma5 are designed to capture each team's recent form by averaging performance in their previous five home or away matches. For every match, we sorted each team's games chronologically and computed the MA5 stictly from the past results, which ennsured that the model only has access to information that would have beena vailable before the match kicked off.  \n",
    "\n",
    "On average, the teams score 1.47 goals at home and 1.2 goals away, which aligns with typical football scoring patterns where the home teams tend to perform better offensively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Promoted/Demoted flags\n",
    "\n",
    "Now we want to detect teams that changed leagues between seasons using the Season column (e.g., 2019/2020 → 2020/2021). We're going to do that by creating four flags that will tell the model if a team is newly promoted or demoted in that season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# promotion/demotion flags\n",
    "df_basic['home_promoted'] = 0\n",
    "df_basic['home_demoted'] = 0\n",
    "df_basic['away_promoted'] = 0\n",
    "df_basic['away_demoted'] = 0\n",
    "\n",
    "# For each team, check if they changed tier between seasons\n",
    "for team in df_basic['HomeTeam'].unique():\n",
    "    team_data = df_basic[(df_basic['HomeTeam'] == team) | (df_basic['AwayTeam'] == team)].sort_values('Date')\n",
    "\n",
    "    # Grouping by season and get the league tier for each season\n",
    "    season_tiers = team_data.groupby('Season')['league_tier'].first()\n",
    "\n",
    "    for i in range(1, len(season_tiers)):\n",
    "        season = season_tiers.index[i]\n",
    "        prev_tier = season_tiers.iloc[i-1]\n",
    "        curr_tier = season_tiers.iloc[i]\n",
    "\n",
    "        if curr_tier < prev_tier:  # Lower tier number = higher division\n",
    "            promoted = 1\n",
    "            demoted = 0\n",
    "        elif curr_tier > prev_tier:\n",
    "            promoted = 0\n",
    "            demoted = 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        season_mask = (df_basic['Season'] == season)\n",
    "        home_mask = season_mask & (df_basic['HomeTeam'] == team)\n",
    "        away_mask = season_mask & (df_basic['AwayTeam'] == team)\n",
    "\n",
    "        df_basic.loc[home_mask, 'home_promoted'] = promoted\n",
    "        df_basic.loc[home_mask, 'home_demoted'] = demoted\n",
    "        df_basic.loc[away_mask, 'away_promoted'] = promoted\n",
    "        df_basic.loc[away_mask, 'away_demoted'] = demoted\n",
    "\n",
    "print(f\"Home teams promoted: {df_basic['home_promoted'].sum()}\")\n",
    "print(f\"Home teams demoted: {df_basic['home_demoted'].sum()}\")\n",
    "print(f\"Away teams promoted: {df_basic['away_promoted'].sum()}\")\n",
    "print(f\"Away teams demoted: {df_basic['away_demoted'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promotion and demotion  are determined by tracking each team’s league tier from one season to the next, ensuring that changes in division are detected based on true seasonal transitions rather than simply comparing calendar years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 Historical Standings & Goal Patterns\n",
    "\n",
    "Now, we'll be calculating the team calculating team standings and goal-scoring patterns with round-based tracking and home/away splits.  \n",
    "\n",
    "For past seasons, we simply use the final end-of-season standings. For the current season, however, we reconstruct the table round by round, always using standings from the last fully completed round so the model never sees information from future matches. A round is considered complete only when all teams have played the same number of games, ensuring accurate pre-match snapshots.\n",
    "\n",
    "For every team, we track overall performance (points, goals for/against) as well as home-only and away-only statistics. We also compute goal-pattern features - how often a team scores, concedes, or participates in matches with 2+ or 3+ goals — captured both as counts and percentages. These percentages are expressed on a 0–100 scale to allow consistent comparison across leagues.\n",
    "\n",
    "The output will be a set of historical, round-accurate standings and goal-pattern features that reflect exactly what would have been known before each match, providing strong and leakage-free indicators of team strength and scoring tendencies,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate league standings: final for past seasons, round-by-round for current season\n",
    "def calculate_standings_with_rounds(df):\n",
    "    \"\"\"\n",
    "    Calculate standings with home/away splits:\n",
    "    - Position: Overall only\n",
    "    - Goal patterns: Overall + Home-specific + Away-specific (both counts and percentages)\n",
    "    \"\"\"\n",
    "    standings_list = []\n",
    "    match_to_round = {}\n",
    "\n",
    "    for (season, div), group in df.groupby(['Season', 'Div']):\n",
    "        group = group.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "        # Initialize tracking for overall, home, away\n",
    "        teams = set(group['HomeTeam'].unique()) | set(group['AwayTeam'].unique())\n",
    "        team_stats_overall = {team: {'points': 0, 'gf': 0, 'ga': 0, 'matches': 0} for team in teams}\n",
    "        team_stats_home = {team: {'gf': 0, 'ga': 0, 'matches': 0} for team in teams}\n",
    "        team_stats_away = {team: {'gf': 0, 'ga': 0, 'matches': 0} for team in teams}\n",
    "\n",
    "        # Goal patterns: overall, home-only, away-only\n",
    "        patterns_overall = {team: {f'{p}_{t}': 0 for p in ['sc', 'co', 'to'] for t in [2, 3]} for team in teams}\n",
    "        patterns_home = {team: {f'{p}_{t}': 0 for p in ['sc', 'co', 'to'] for t in [2, 3]} for team in teams}\n",
    "        patterns_away = {team: {f'{p}_{t}': 0 for p in ['sc', 'co', 'to'] for t in [2, 3]} for team in teams}\n",
    "\n",
    "        current_round = None\n",
    "\n",
    "        for _, match in group.iterrows():\n",
    "            ht, at = match['HomeTeam'], match['AwayTeam']\n",
    "            hg, ag = match['FTHG'], match['FTAG']\n",
    "            match_key = (season, div, match['Date'], ht, at)\n",
    "\n",
    "            # Store BEFORE match\n",
    "            if current_round is not None:\n",
    "                match_to_round[match_key] = current_round.copy()\n",
    "\n",
    "            # Update overall stats\n",
    "            team_stats_overall[ht]['gf'] += hg\n",
    "            team_stats_overall[ht]['ga'] += ag\n",
    "            team_stats_overall[ht]['matches'] += 1\n",
    "            team_stats_overall[at]['gf'] += ag\n",
    "            team_stats_overall[at]['ga'] += hg\n",
    "            team_stats_overall[at]['matches'] += 1\n",
    "\n",
    "            # Update home/away specific stats\n",
    "            team_stats_home[ht]['gf'] += hg\n",
    "            team_stats_home[ht]['ga'] += ag\n",
    "            team_stats_home[ht]['matches'] += 1\n",
    "            team_stats_away[at]['gf'] += ag\n",
    "            team_stats_away[at]['ga'] += hg\n",
    "            team_stats_away[at]['matches'] += 1\n",
    "\n",
    "            # Update goal patterns - OVERALL\n",
    "            for t in [2, 3]:\n",
    "                if hg >= t:\n",
    "                    patterns_overall[ht][f'sc_{t}'] += 1\n",
    "                    patterns_home[ht][f'sc_{t}'] += 1\n",
    "                if ag >= t:\n",
    "                    patterns_overall[ht][f'co_{t}'] += 1\n",
    "                    patterns_home[ht][f'co_{t}'] += 1\n",
    "                    patterns_overall[at][f'sc_{t}'] += 1\n",
    "                    patterns_away[at][f'sc_{t}'] += 1\n",
    "                if hg + ag >= t:\n",
    "                    patterns_overall[ht][f'to_{t}'] += 1\n",
    "                    patterns_overall[at][f'to_{t}'] += 1\n",
    "                    patterns_home[ht][f'to_{t}'] += 1\n",
    "                    patterns_away[at][f'to_{t}'] += 1\n",
    "                if hg >= t:\n",
    "                    patterns_overall[at][f'co_{t}'] += 1\n",
    "                    patterns_away[at][f'co_{t}'] += 1\n",
    "\n",
    "            # Points\n",
    "            if match['FTR'] == 'H': team_stats_overall[ht]['points'] += 3\n",
    "            elif match['FTR'] == 'A': team_stats_overall[at]['points'] += 3\n",
    "            else:\n",
    "                team_stats_overall[ht]['points'] += 1\n",
    "                team_stats_overall[at]['points'] += 1\n",
    "\n",
    "            # Check round completion\n",
    "            if len(set(s['matches'] for s in team_stats_overall.values())) == 1:\n",
    "                rows = []\n",
    "                for team in teams:\n",
    "                    s_o = team_stats_overall[team]\n",
    "                    s_h = team_stats_home[team]\n",
    "                    s_a = team_stats_away[team]\n",
    "\n",
    "                    row = {\n",
    "                        'Season': season, 'Div': div, 'Team': team,\n",
    "                        'Points': s_o['points'], 'Matches': s_o['matches'],\n",
    "                        'Goals_For': s_o['gf'], 'Goals_Against': s_o['ga']\n",
    "                    }\n",
    "\n",
    "                    # Overall goal patterns (count + pct)\n",
    "                    for t in [2, 3]:\n",
    "                        for p, full in [('sc', 'scored'), ('co', 'conceded'), ('to', 'total')]:\n",
    "                            cnt = patterns_overall[team][f'{p}_{t}']\n",
    "                            row[f'{full}_{t}plus_count'] = cnt\n",
    "                            row[f'{full}_{t}plus_pct'] = round(cnt / s_o['matches'] * 100, 1) if s_o['matches'] > 0 else 0\n",
    "\n",
    "                    # Home-specific goal patterns\n",
    "                    for t in [2, 3]:\n",
    "                        for p, full in [('sc', 'scored'), ('co', 'conceded'), ('to', 'total')]:\n",
    "                            cnt = patterns_home[team][f'{p}_{t}']\n",
    "                            row[f'home_{full}_{t}plus_count'] = cnt\n",
    "                            row[f'home_{full}_{t}plus_pct'] = round(cnt / s_h['matches'] * 100, 1) if s_h['matches'] > 0 else 0\n",
    "\n",
    "                    # Away-specific goal patterns\n",
    "                    for t in [2, 3]:\n",
    "                        for p, full in [('sc', 'scored'), ('co', 'conceded'), ('to', 'total')]:\n",
    "                            cnt = patterns_away[team][f'{p}_{t}']\n",
    "                            row[f'away_{full}_{t}plus_count'] = cnt\n",
    "                            row[f'away_{full}_{t}plus_pct'] = round(cnt / s_a['matches'] * 100, 1) if s_a['matches'] > 0 else 0\n",
    "\n",
    "                    rows.append(row)\n",
    "\n",
    "                current_round = pd.DataFrame(rows).sort_values('Points', ascending=False)\n",
    "                current_round['Position'] = range(1, len(current_round) + 1)\n",
    "\n",
    "        if current_round is not None:\n",
    "            standings_list.append(current_round)\n",
    "\n",
    "    final = pd.concat(standings_list, ignore_index=True) if standings_list else pd.DataFrame()\n",
    "    return final, match_to_round\n",
    "\n",
    "# Calculate standings\n",
    "df_season_standings, match_round_map = calculate_standings_with_rounds(df_basic)\n",
    "print(f\"Season standings: {len(df_season_standings)} team-season records\")\n",
    "print(f\"Round-based mappings: {len(match_round_map)} matches with historical standings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create historical position features with lookback logic\n",
    "season_list = sorted(df_basic['Season'].unique())\n",
    "season_to_order = {season: idx for idx, season in enumerate(season_list)}\n",
    "df_basic['season_order'] = df_basic['Season'].map(season_to_order)\n",
    "\n",
    "# Extract season years and create position lookup\n",
    "def extract_season_year(season_str):\n",
    "    return int(season_str.split('/')[0])\n",
    "\n",
    "df_season_standings['season_year'] = df_season_standings['Season'].apply(extract_season_year)\n",
    "unique_season_years = sorted(df_season_standings['season_year'].unique())\n",
    "\n",
    "# Add percentile rankings for cross-league comparability\n",
    "df_season_standings['league_size'] = df_season_standings.groupby(['Season', 'Div'])['Position'].transform('max')\n",
    "df_season_standings['Position_Percentile'] = (\n",
    "    (df_season_standings['league_size'] - df_season_standings['Position'] + 1) /\n",
    "    df_season_standings['league_size'] * 100\n",
    ").round(2)\n",
    "percentile_lookup = df_season_standings.set_index(['Season', 'Div', 'Team'])['Position_Percentile'].to_dict()\n",
    "\n",
    "# Create columns for percentile positions only (not raw positions)\n",
    "for year in unique_season_years:\n",
    "    df_basic[f'home_position_pct_{year}'] = np.nan\n",
    "    df_basic[f'away_position_pct_{year}'] = np.nan\n",
    "\n",
    "# Populate historical features\n",
    "for idx, row in df_basic.iterrows():\n",
    "    current_season_order = row['season_order']\n",
    "    current_season = row['Season']\n",
    "    match_key = (row['Season'], row['Div'], row['Date'], row['HomeTeam'], row['AwayTeam'])\n",
    "\n",
    "    for year in unique_season_years:\n",
    "        target_season = next((s for s in season_list if extract_season_year(s) == year), None)\n",
    "        if not target_season:\n",
    "            continue\n",
    "\n",
    "        target_season_order = season_to_order[target_season]\n",
    "\n",
    "        # For past seasons: use final standings\n",
    "        if target_season_order < current_season_order:\n",
    "            for team_type, team in [('home', row['HomeTeam']), ('away', row['AwayTeam'])]:\n",
    "                key = next(\n",
    "                    ((target_season, div, team) for div in df_season_standings['Div'].unique()\n",
    "                     if (target_season, div, team) in percentile_lookup),\n",
    "                    None\n",
    "                )\n",
    "                if key:\n",
    "                    df_basic.loc[idx, f'{team_type}_position_pct_{year}'] = percentile_lookup[key]\n",
    "\n",
    "        # For current season (same season as match): use round-based standings\n",
    "        elif target_season == current_season and match_key in match_round_map:\n",
    "            round_standings = match_round_map[match_key]\n",
    "            for team_type, team in [('home', row['HomeTeam']), ('away', row['AwayTeam'])]:\n",
    "                team_row = round_standings[round_standings['Team'] == team]\n",
    "                if not team_row.empty:\n",
    "                    position = team_row['Position'].iloc[0]\n",
    "                    league_size = len(round_standings)\n",
    "                    percentile = ((league_size - position + 1) / league_size * 100)\n",
    "                    df_basic.loc[idx, f'{team_type}_position_pct_{year}'] = round(percentile, 2)\n",
    "\n",
    "position_cols = [col for col in df_basic.columns if 'position_pct_' in col]\n",
    "print(f\"Historical position features: {len(position_cols)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add historical goal-scoring pattern features with home/away context\n",
    "# Create lookups from final standings\n",
    "goal_stat_lookups = {}\n",
    "for threshold in [2, 3]:\n",
    "    for prefix in ['scored', 'conceded', 'total']:\n",
    "        # Overall stats\n",
    "        for suffix in ['count', 'pct']:\n",
    "            col = f'{prefix}_{threshold}plus_{suffix}'\n",
    "            goal_stat_lookups[col] = df_season_standings.set_index(['Season', 'Div', 'Team'])[col].to_dict()\n",
    "        # Home-specific stats\n",
    "        for suffix in ['count', 'pct']:\n",
    "            col = f'home_{prefix}_{threshold}plus_{suffix}'\n",
    "            goal_stat_lookups[col] = df_season_standings.set_index(['Season', 'Div', 'Team'])[col].to_dict()\n",
    "        # Away-specific stats\n",
    "        for suffix in ['count', 'pct']:\n",
    "            col = f'away_{prefix}_{threshold}plus_{suffix}'\n",
    "            goal_stat_lookups[col] = df_season_standings.set_index(['Season', 'Div', 'Team'])[col].to_dict()\n",
    "\n",
    "# Create columns: home team gets overall + home-specific, away team gets overall + away-specific\n",
    "for year in unique_season_years:\n",
    "    for threshold in [2, 3]:\n",
    "        for prefix in ['scored', 'conceded', 'total']:\n",
    "            # Home team: overall + home-specific\n",
    "            df_basic[f'home_{prefix}_{threshold}plus_count_{year}'] = np.nan\n",
    "            df_basic[f'home_{prefix}_{threshold}plus_pct_{year}'] = np.nan\n",
    "            df_basic[f'home_home_{prefix}_{threshold}plus_count_{year}'] = np.nan\n",
    "            df_basic[f'home_home_{prefix}_{threshold}plus_pct_{year}'] = np.nan\n",
    "            # Away team: overall + away-specific\n",
    "            df_basic[f'away_{prefix}_{threshold}plus_count_{year}'] = np.nan\n",
    "            df_basic[f'away_{prefix}_{threshold}plus_pct_{year}'] = np.nan\n",
    "            df_basic[f'away_away_{prefix}_{threshold}plus_count_{year}'] = np.nan\n",
    "            df_basic[f'away_away_{prefix}_{threshold}plus_pct_{year}'] = np.nan\n",
    "\n",
    "# Populate goal statistics\n",
    "for idx, row in df_basic.iterrows():\n",
    "    current_season_order = row['season_order']\n",
    "    current_season = row['Season']\n",
    "    match_key = (row['Season'], row['Div'], row['Date'], row['HomeTeam'], row['AwayTeam'])\n",
    "\n",
    "    for year in unique_season_years:\n",
    "        target_season = next((s for s in season_list if extract_season_year(s) == year), None)\n",
    "        if not target_season:\n",
    "            continue\n",
    "\n",
    "        # For past seasons: use final standings\n",
    "        if season_to_order[target_season] < current_season_order:\n",
    "            # Home team\n",
    "            key_home = next(((target_season, div, row['HomeTeam']) for div in df_season_standings['Div'].unique()\n",
    "                             if (target_season, div, row['HomeTeam']) in percentile_lookup), None)\n",
    "            if key_home:\n",
    "                for threshold in [2, 3]:\n",
    "                    for prefix in ['scored', 'conceded', 'total']:\n",
    "                        # Overall stats\n",
    "                        for suffix in ['count', 'pct']:\n",
    "                            col = f'{prefix}_{threshold}plus_{suffix}'\n",
    "                            val = goal_stat_lookups[col].get(key_home)\n",
    "                            if val is not None:\n",
    "                                df_basic.loc[idx, f'home_{col}_{year}'] = val\n",
    "                        # Home-specific stats\n",
    "                        for suffix in ['count', 'pct']:\n",
    "                            col = f'home_{prefix}_{threshold}plus_{suffix}'\n",
    "                            val = goal_stat_lookups[col].get(key_home)\n",
    "                            if val is not None:\n",
    "                                df_basic.loc[idx, f'home_{col}_{year}'] = val\n",
    "\n",
    "            # Away team\n",
    "            key_away = next(((target_season, div, row['AwayTeam']) for div in df_season_standings['Div'].unique()\n",
    "                             if (target_season, div, row['AwayTeam']) in percentile_lookup), None)\n",
    "            if key_away:\n",
    "                for threshold in [2, 3]:\n",
    "                    for prefix in ['scored', 'conceded', 'total']:\n",
    "                        # Overall stats\n",
    "                        for suffix in ['count', 'pct']:\n",
    "                            col = f'{prefix}_{threshold}plus_{suffix}'\n",
    "                            val = goal_stat_lookups[col].get(key_away)\n",
    "                            if val is not None:\n",
    "                                df_basic.loc[idx, f'away_{col}_{year}'] = val\n",
    "                        # Away-specific stats\n",
    "                        for suffix in ['count', 'pct']:\n",
    "                            col = f'away_{prefix}_{threshold}plus_{suffix}'\n",
    "                            val = goal_stat_lookups[col].get(key_away)\n",
    "                            if val is not None:\n",
    "                                df_basic.loc[idx, f'away_{col}_{year}'] = val\n",
    "\n",
    "        # For current season: use round-based standings\n",
    "        elif target_season == current_season and match_key in match_round_map:\n",
    "            round_standings = match_round_map[match_key]\n",
    "\n",
    "            # Home team\n",
    "            home_row = round_standings[round_standings['Team'] == row['HomeTeam']]\n",
    "            if not home_row.empty:\n",
    "                for threshold in [2, 3]:\n",
    "                    for prefix in ['scored', 'conceded', 'total']:\n",
    "                        # Overall stats\n",
    "                        for suffix in ['count', 'pct']:\n",
    "                            col = f'{prefix}_{threshold}plus_{suffix}'\n",
    "                            if col in home_row.columns:\n",
    "                                df_basic.loc[idx, f'home_{col}_{year}'] = home_row[col].iloc[0]\n",
    "                        # Home-specific stats\n",
    "                        for suffix in ['count', 'pct']:\n",
    "                            col = f'home_{prefix}_{threshold}plus_{suffix}'\n",
    "                            if col in home_row.columns:\n",
    "                                df_basic.loc[idx, f'home_{col}_{year}'] = home_row[col].iloc[0]\n",
    "\n",
    "            # Away team\n",
    "            away_row = round_standings[round_standings['Team'] == row['AwayTeam']]\n",
    "            if not away_row.empty:\n",
    "                for threshold in [2, 3]:\n",
    "                    for prefix in ['scored', 'conceded', 'total']:\n",
    "                        # Overall stats\n",
    "                        for suffix in ['count', 'pct']:\n",
    "                            col = f'{prefix}_{threshold}plus_{suffix}'\n",
    "                            if col in away_row.columns:\n",
    "                                df_basic.loc[idx, f'away_{col}_{year}'] = away_row[col].iloc[0]\n",
    "                        # Away-specific stats\n",
    "                        for suffix in ['count', 'pct']:\n",
    "                            col = f'away_{prefix}_{threshold}plus_{suffix}'\n",
    "                            if col in away_row.columns:\n",
    "                                df_basic.loc[idx, f'away_{col}_{year}'] = away_row[col].iloc[0]\n",
    "\n",
    "goal_stat_cols = [col for col in df_basic.columns if any(f'{p}_{t}plus' in col for p in ['scored', 'conceded', 'total'] for t in [2, 3])]\n",
    "print(f\"Historical goal statistics: {len(goal_stat_cols)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of Section 4.3.4:**\n",
    "\n",
    "The purpose of this section was to ensure that no data-leakage will happen, while capturing each team's historical strengths and scoring tendencies. The core idea is that the model must only access information that would have been available before a match. To guarantee this, the code reconstructs league standings round-by-round. For all past seasons, final season standings are used. For the current season, however, we rely only on standings from the last fully completed round, meaning all teams have played the same number of matches. This ensures that league positions, points, and goal metrics always reflect true pre-match knowledge.\n",
    "\n",
    "Performance was then tracked in three contexts:\n",
    "- overall\n",
    "- home \n",
    "- away\n",
    "with ongoing updates to goals scored, goals conceded, points, and how often a team participates in matches with 2+ or 3+ goals. For each threshold, the model receives both counts and percentages, allowing it to understand not only a team’s tendencies but also the reliability of those tendencies (e.g., 80% over ten matches vs. 100% over one match). When a round is completed, a standings snapshot is saved containing points, position, goal tallies, and all goal-pattern metrics. This process produced 2,241 team-season records and 38,480 match-to-round mappings.  \n",
    "\n",
    "To make metrics comparable across leagues of different sizes, league positions are converted into percentiles (0–100), where higher percentiles indicate stronger teams. These percentiles are then inserted into the main dataset using strict chronological logic: final standings for past seasons and round-based standings for the current one. No future-season data is ever used. Finally, historical goal-pattern features are added with full home/away context—home teams receive overall + home-specific metrics, while away teams receive overall + away-specific metrics. In total, **301 new features were generated**: **13 position percentiles** and **288 goal-pattern statistics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5 Additional Contextual Derived Features\n",
    "\n",
    "We want to create additional higher-level features from existing data that might improve Over/Under 2.5 prediction. These features build on earlier computations and provide some insights into the team quality, momentum and match conditions.\n",
    "\n",
    "Team strength differentials capture the relative gap between the two teams. This includes the position percentile difference, which normalizes league position across leagues of varying sizes, and combined attacking/defensive strength indicators, which blend recent goal-scoring form with longer-term historical scoring patterns.\n",
    "\n",
    "Form-based features introduce a measure of momentum by comparing a team’s last five matches with the five preceding them, yielding a form trend that signals whether a team is improving or declining.\n",
    "\n",
    "Contextual features enhance the temporal and physical understanding of a match. These include season progress, which indicates whether a fixture occurs early, mid-season, or late in the campaign, and rest-days advantage, which measures the difference in preparation and recovery time between the teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Position difference features (most recent season available for both teams)\n",
    "df_basic['position_pct_diff'] = np.nan\n",
    "\n",
    "for idx, row in df_basic.iterrows():\n",
    "    # Find most recent season where both teams have position data\n",
    "    for year in reversed(unique_season_years):\n",
    "        home_pct_col = f'home_position_pct_{year}'\n",
    "        away_pct_col = f'away_position_pct_{year}'\n",
    "\n",
    "        if (pd.notna(df_basic.loc[idx, home_pct_col]) and\n",
    "            pd.notna(df_basic.loc[idx, away_pct_col])):\n",
    "            # Positive = home team has better position (higher percentile)\n",
    "            df_basic.loc[idx, 'position_pct_diff'] = df_basic.loc[idx, home_pct_col] - df_basic.loc[idx, away_pct_col]\n",
    "            break\n",
    "\n",
    "print(f\" Position percentile difference feature created\")\n",
    "print(f\"Coverage: {(df_basic['position_pct_diff'].notna().sum() / len(df_basic) * 100):.1f}%\")\n",
    "\n",
    "# 2. Combined attacking strength using context-aware stats\n",
    "# Home team uses home-specific stats, away team uses away-specific stats\n",
    "df_basic['combined_attack_strength'] = np.nan\n",
    "df_basic['combined_defense_weakness'] = np.nan\n",
    "\n",
    "for idx, row in df_basic.iterrows():\n",
    "    # Get most recent goal statistics (context-aware: home-specific for home team, away-specific for away)\n",
    "    for year in reversed(unique_season_years):\n",
    "        # Home team: use home-specific scoring\n",
    "        home_scored = df_basic.loc[idx, f'home_home_scored_3plus_pct_{year}']\n",
    "        home_conceded = df_basic.loc[idx, f'home_home_conceded_3plus_pct_{year}']\n",
    "        # Away team: use away-specific scoring\n",
    "        away_scored = df_basic.loc[idx, f'away_away_scored_3plus_pct_{year}']\n",
    "        away_conceded = df_basic.loc[idx, f'away_away_conceded_3plus_pct_{year}']\n",
    "\n",
    "        if pd.notna(home_scored) and pd.notna(away_scored):\n",
    "            # Combine recent MA with historical patterns\n",
    "            home_recent = df_basic.loc[idx, 'home_goals_ma5']\n",
    "            away_recent = df_basic.loc[idx, 'away_goals_ma5']\n",
    "\n",
    "            # Weighted average: 60% recent form, 40% historical context-specific pattern\n",
    "            df_basic.loc[idx, 'combined_attack_strength'] = (\n",
    "                0.6 * (home_recent + away_recent) +\n",
    "                0.4 * ((home_scored + away_scored) / 20)  # Normalize percentage to goals scale\n",
    "            )\n",
    "            df_basic.loc[idx, 'combined_defense_weakness'] = (\n",
    "                0.6 * (df_basic.loc[idx, 'home_conceded_ma5'] + df_basic.loc[idx, 'away_conceded_ma5']) +\n",
    "                0.4 * ((home_conceded + away_conceded) / 20)\n",
    "            )\n",
    "            break\n",
    "\n",
    "print(f\" Combined strength features created (using home/away context)\")\n",
    "print(f\"Coverage: {(df_basic['combined_attack_strength'].notna().sum() / len(df_basic) * 100):.1f}%\")\n",
    "\n",
    "# 3. Form trend (improving vs declining)\n",
    "df_basic['home_form_trend'] = np.nan\n",
    "df_basic['away_form_trend'] = np.nan\n",
    "\n",
    "for team in df_basic['HomeTeam'].unique():\n",
    "    # Home matches\n",
    "    home_mask = df_basic['HomeTeam'] == team\n",
    "    home_dates = df_basic[home_mask].sort_values('Date').index\n",
    "    for i, idx in enumerate(home_dates):\n",
    "        if i >= 10:  # Need at least 10 matches\n",
    "            last_5 = df_basic.loc[home_dates[i-5:i], 'FTHG'].mean()\n",
    "            prev_5 = df_basic.loc[home_dates[i-10:i-5], 'FTHG'].mean()\n",
    "            df_basic.loc[idx, 'home_form_trend'] = last_5 - prev_5  # Positive = improving\n",
    "\n",
    "    # Away matches\n",
    "    away_mask = df_basic['AwayTeam'] == team\n",
    "    away_dates = df_basic[away_mask].sort_values('Date').index\n",
    "    for i, idx in enumerate(away_dates):\n",
    "        if i >= 10:\n",
    "            last_5 = df_basic.loc[away_dates[i-5:i], 'FTAG'].mean()\n",
    "            prev_5 = df_basic.loc[away_dates[i-10:i-5], 'FTAG'].mean()\n",
    "            df_basic.loc[idx, 'away_form_trend'] = last_5 - prev_5\n",
    "\n",
    "# Fill NaN with 0 (no trend info = assume stable)\n",
    "df_basic['home_form_trend'].fillna(0, inplace=True)\n",
    "df_basic['away_form_trend'].fillna(0, inplace=True)\n",
    "\n",
    "print(f\" Form trend features created\")\n",
    "\n",
    "# 4. Rest days advantage\n",
    "df_basic['rest_days_advantage'] = df_basic['home_days_since_last'] - df_basic['away_days_since_last']\n",
    "\n",
    "print(f\" Rest days advantage created\")\n",
    "\n",
    "# 5. Season progress (match number / expected total matches based on league structure)\n",
    "# NO DATA LEAKAGE: Uses team count (known from first match) and round-robin format\n",
    "# Expected matches = N × (N-1) where N = number of teams in the league\n",
    "df_basic['season_progress'] = np.nan\n",
    "for season_div, group in df_basic.groupby(['Season', 'Div']):\n",
    "    # Count unique teams in this season/division (structural information)\n",
    "    teams_in_league = len(group['HomeTeam'].unique())\n",
    "    # Calculate expected total matches for round-robin (home & away)\n",
    "    expected_total_matches = teams_in_league * (teams_in_league - 1)\n",
    "\n",
    "    # Sort by date to get chronological order\n",
    "    sorted_indices = group.sort_values('Date').index\n",
    "\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        match_number = i + 1\n",
    "        df_basic.loc[idx, 'season_progress'] = match_number / expected_total_matches\n",
    "\n",
    "print(f\" Season progress feature created (using league structure)\")\n",
    "\n",
    "# Summary\n",
    "new_derived_features = ['position_pct_diff', 'combined_attack_strength',\n",
    "                        'combined_defense_weakness', 'home_form_trend', 'away_form_trend',\n",
    "                        'rest_days_advantage', 'season_progress']\n",
    "print(f\"Total new derived features: {len(new_derived_features)}\")\n",
    "print(f\"Features: {new_derived_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results confirm that all seven derived features seem to have very good coverage across dataset. The position percentile difference feature is available for about 97.3% of matches, meaning that in nearly all games we can quantify the recent quality gap between the two teams based on their league positions.   \n",
    "\n",
    "The combined attacking and defensive strength features cover 91.8% of matches, which is strong given that they depend on both recent form (MA5) and historical context-specific scoring patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify season_progress fix - check values are reasonable\n",
    "print(\"Season Progress Verification\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check range\n",
    "print(f\"\\nSeason progress range: {df_basic['season_progress'].min():.4f} to {df_basic['season_progress'].max():.4f}\")\n",
    "\n",
    "# Check a few examples from different league sizes\n",
    "for season_div in [('2024/2025', 'E0'), ('2024/2025', 'SP1'), ('2024/2025', 'SC0')]:\n",
    "    season, div = season_div\n",
    "    mask = (df_basic['Season'] == season) & (df_basic['Div'] == div)\n",
    "    group = df_basic[mask].copy()\n",
    "\n",
    "    if len(group) > 0:\n",
    "        teams = len(group['HomeTeam'].unique())\n",
    "        expected = teams * (teams - 1)\n",
    "        progress_values = group.sort_values('Date')['season_progress'].values\n",
    "\n",
    "        print(f\"\\n{season} {div}:\")\n",
    "        print(f\"Teams: {teams}, Expected matches: {expected}\")\n",
    "        print(f\"Matches so far: {len(group)}\")\n",
    "        print(f\"Progress range: {progress_values.min():.4f} to {progress_values.max():.4f}\")\n",
    "        print(f\"First 3 matches progress: {progress_values[:3]}\")\n",
    "\n",
    "print(\"Season progress values verified - using league structure (no data leakage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the season_progress feature is behaving as intended for standard league structures. For the 2024/2025 SP1 league, there are 20 teams, so the expected number of matches (20 × 19 = 380) matches the actual 380 games in the data. The season_progress values for SP1 go from about 0.0026 for the first match up to 1.0000 for the last match, which correctly maps the season from “just started” to “fully completed” on a 0–1 scale.  \n",
    "\n",
    "Globally, the overall range of 0.0018 to 2.0000 suggests that while most leagues follow the expected round-robin structure, some seasons or divisions have more matches than the simple N × (N-1) formula (e.g. extra rounds, playoffs, split leagues), leading to values slightly above 1. Still, the SP1 check confirms that for a standard 20-team league, the feature accurately tracks season progression based purely on league structure, without using any future-match information (so no data leakage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.6 Data Leakage Prevention Summary\n",
    "\n",
    "So, to fix the season progress, we had to investigate what was the problem, which was that our earlier implementation relied on `len(group)` , which unintentionally counted all matches from the entire season, even those that occured after the current match, which created the data leakage.  \n",
    "\n",
    "Our updated version insteadc alculates the expected number of matches using league structure `(teams × (teams − 1))`, which is fully safe because the number of teams and the round-robin format are known from the very start of the season. This uses only structural information (just as we know the Premier League has 38 rounds or the NBA has 82 games), not any future match results.\n",
    "\n",
    "Furthermore, to verify all feature groups:\n",
    " - MA5 features: Use `Date < date` or index slicing `[i-5:i]` to exclude current match  \n",
    " - Combined strength: Uses pre-calculated MA5 (which is safe)  \n",
    " - Form trend: Uses historical windows `[i-5:i]` and `[i-10:i-5]`  \n",
    " - Season progress: Now uses league structure (team count)  \n",
    " - Extended stats MA5: Uses `Date < date` filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.7 Feature Importance Testing\n",
    "\n",
    "In this stage we will test which engineered feature show meaningful relationships with the Over/Under 2.5 target using simple Pearson correlations. We test three main groups: time-based features (rest days, MA5 form, league tier, month), historical position features (percentile rankings across seasons), and historical goal-pattern features (scored/conceded/total 2+ and 3+ goal patterns in counts and percentages). Summary statistics help reveal which groups contain stronger linear signal, and we list the top 15 features by absolute correlation.  \n",
    "\n",
    "Because correlations only capture linear relationships, they provide a useful initial screening but not a full picture of feature importance. Many features that appear weak here can still be highly predictive in tree-based models, which capture non-linear effects, thresholds, and interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the Correlation Analysis to see a quick screeening of how strongly each features is linearly related to the O/U 2.5 target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.7.1 Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features to test\n",
    "num_features = ['home_days_since_last', 'away_days_since_last',\n",
    "                'home_goals_ma5', 'home_conceded_ma5', 'away_goals_ma5', 'away_conceded_ma5',\n",
    "                'league_tier', 'month']\n",
    "\n",
    "# Add historical position features (from section 4.3.4) - percentiles only\n",
    "position_features = [col for col in df_basic.columns if 'position_pct_' in col]\n",
    "\n",
    "# Add historical goal statistics features (from sections 4.3.4 and 4.3.5)\n",
    "# Includes: overall, home-specific, away-specific stats × counts and percentages\n",
    "goal_stat_features = [col for col in df_basic.columns if any(f'{p}_{t}plus' in col for p in ['scored', 'conceded', 'total'] for t in [2, 3])]\n",
    "\n",
    "all_num_features = num_features + position_features + goal_stat_features\n",
    "\n",
    "# Calculate correlations\n",
    "print(\"=\" * 60)\n",
    "print(\"CORRELATIONS WITH over_2_5 TARGET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. TIME-BASED FEATURES:\")\n",
    "time_corrs = []\n",
    "for feat in num_features:\n",
    "    corr = df_basic[feat].corr(df_basic['over_2_5'])\n",
    "    time_corrs.append((feat, corr))\n",
    "    print(f\"{feat:30s}: {corr:7.4f}\")\n",
    "\n",
    "print(f\"\\n2. HISTORICAL POSITION FEATURES ({len(position_features)} total):\")\n",
    "# Group by season year for cleaner display\n",
    "position_corrs = []\n",
    "for feat in position_features:\n",
    "    corr = df_basic[feat].corr(df_basic['over_2_5'])\n",
    "    position_corrs.append((feat, corr))\n",
    "    print(f\"{feat:30s}: {corr:7.4f}\")\n",
    "\n",
    "# Summary statistics for position features\n",
    "position_corr_values = [abs(c[1]) for c in position_corrs if not pd.isna(c[1])]\n",
    "if position_corr_values:\n",
    "    print(f\"Position features summary:\")\n",
    "    print(f\"Max |correlation|: {max(position_corr_values):.4f}\")\n",
    "    print(f\"Mean |correlation|: {np.mean(position_corr_values):.4f}\")\n",
    "    print(f\"Median |correlation|: {np.median(position_corr_values):.4f}\")\n",
    "\n",
    "print(f\"\\n3. HISTORICAL GOAL PATTERN FEATURES ({len(goal_stat_features)} total):\")\n",
    "goal_stat_corrs = []\n",
    "for feat in goal_stat_features:\n",
    "    corr = df_basic[feat].corr(df_basic['over_2_5'])\n",
    "    goal_stat_corrs.append((feat, corr))\n",
    "    print(f\"{feat:40s}: {corr:7.4f}\")\n",
    "\n",
    "# Summary statistics for goal stat features\n",
    "goal_stat_corr_values = [abs(c[1]) for c in goal_stat_corrs if not pd.isna(c[1])]\n",
    "if goal_stat_corr_values:\n",
    "    print(f\"Goal stat features summary:\")\n",
    "    print(f\"Max |correlation|: {max(goal_stat_corr_values):.4f}\")\n",
    "    print(f\"Mean |correlation|: {np.mean(goal_stat_corr_values):.4f}\")\n",
    "    print(f\"Median |correlation|: {np.median(goal_stat_corr_values):.4f}\")\n",
    "\n",
    "# Show top features by absolute correlation\n",
    "all_corrs = time_corrs + position_corrs + goal_stat_corrs\n",
    "all_corrs_sorted = sorted(all_corrs, key=lambda x: abs(x[1]) if not pd.isna(x[1]) else 0, reverse=True)\n",
    "\n",
    "print(f\"\\n4. TOP 15 FEATURES BY ABSOLUTE CORRELATION:\")\n",
    "for feat, corr in all_corrs_sorted[:15]:\n",
    "    print(f\"{feat:40s}: {corr:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlations show that no single feature has a strong linear relationship with the Over 2.5 target, which is expected given the complexity and randomness of football scoring. \n",
    "  \n",
    "  \n",
    "Recent attacking form (home_goals_ma5) and historical goal-scoring patterns (such as 2+ or 3+ goal metrics) have the highest correlations, but even these remain modest. Rest-day variables and league positions show very weak linear effects. Overall, while linear correlations are low across the board, many of these features may still be valuable in a non-linear model that captures interactions and threshold effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# 1. Time-based features\n",
    "time_corrs = [df_basic[f].corr(df_basic['over_2_5']) for f in num_features]\n",
    "axes[0].barh(num_features, time_corrs, color='steelblue')\n",
    "axes[0].axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "axes[0].set_xlabel('Correlation with Over 2.5', fontsize=11)\n",
    "axes[0].set_title('Time-Based Features', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Position features - show top 10 by absolute correlation\n",
    "position_corr_df = pd.DataFrame(position_corrs, columns=['feature', 'correlation'])\n",
    "position_corr_df['abs_corr'] = position_corr_df['correlation'].abs()\n",
    "top_position = position_corr_df.nlargest(10, 'abs_corr')\n",
    "axes[1].barh(range(len(top_position)), top_position['correlation'].values, color='coral')\n",
    "axes[1].set_yticks(range(len(top_position)))\n",
    "axes[1].set_yticklabels([f.replace('home_', 'H_').replace('away_', 'A_').replace('position_', 'pos_').replace('_pct', '%') for f in top_position['feature']], fontsize=8)\n",
    "axes[1].axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "axes[1].set_xlabel('Correlation with Over 2.5', fontsize=11)\n",
    "axes[1].set_title(f'Top 10 Position Features (of {len(position_features)})', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Goal stats - show top 10 by absolute correlation\n",
    "goal_corr_df = pd.DataFrame(goal_stat_corrs, columns=['feature', 'correlation'])\n",
    "goal_corr_df['abs_corr'] = goal_corr_df['correlation'].abs()\n",
    "top_goals = goal_corr_df.nlargest(10, 'abs_corr')\n",
    "axes[2].barh(range(len(top_goals)), top_goals['correlation'].values, color='mediumseagreen')\n",
    "axes[2].set_yticks(range(len(top_goals)))\n",
    "axes[2].set_yticklabels([f.replace('home_', 'H_').replace('away_', 'A_').replace('_pct_season_', '_S') for f in top_goals['feature']], fontsize=8)\n",
    "axes[2].axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "axes[2].set_xlabel('Correlation with Over 2.5', fontsize=11)\n",
    "axes[2].set_title(f'Top 10 Goal Pattern Features (of {len(goal_stat_features)})', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Overall weak correlations suggest non-linear relationships are important.\")\n",
    "print(f\"Tree-based models will likely perform better than linear models.\")\n",
    "print(f\"\\nStrongest absolute correlations:\")\n",
    "all_corrs = pd.concat([\n",
    "    pd.DataFrame({'feature': num_features, 'correlation': time_corrs}),\n",
    "    position_corr_df[['feature', 'correlation']],\n",
    "    goal_corr_df[['feature', 'correlation']]\n",
    "])\n",
    "all_corrs['abs_corr'] = all_corrs['correlation'].abs()\n",
    "top_overall = all_corrs.nlargest(5, 'abs_corr')\n",
    "for _, row in top_overall.iterrows():\n",
    "    print(f\"{row['feature']:50s}: {row['correlation']:7.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Analysis Interpretation of Numerical Features**\n",
    "\n",
    "The correlation analysis reveals that all engineered features exhibit **very weak linear relationships** with the Over/Under 2.5 target, with absolute correlation values staying below 0.10. This is expected in football analytics, where goal outcomes depend on complex, non-linear interactions rather than simple linear effects. Nevertheless, the analysis highlights several subtle patterns that help validate the usefulness of the engineered features.\n",
    "\n",
    "**Time-based features** show minimal linear impact. Both home and away rest days correlate at around −0.01, indicating that differences in recovery time do not linearly predict goal totals. Recent offensive form, measured by MA5 goals, exhibits the strongest signal in this group: `home_goals_ma5` correlates at roughly +0.08, and `away_goals_ma5` at +0.05, suggesting that teams scoring more in recent matches have a slightly increased probability of participating in Over 2.5 games. Defensive indicators such as MA5 conceded goals show weak negative correlations, consistent with the idea that more defensively solid teams tend toward lower-scoring outcomes. League tier shows a small negative correlation (about −0.04), hinting that lower-tier leagues may produce fewer high-scoring matches, though the effect is modest.\n",
    "\n",
    "**Historical position features** (13 percentile-based indicators) similarly demonstrate weak relationships, generally in the +0.02 to +0.06 range. Home team percentiles tend to correlate slightly stronger than away ones, which aligns with the notion that stronger home teams marginally increase the likelihood of higher goal totals. The overall magnitude remains small, implying that league position alone does not directly drive match goal outcomes but may interact with other variables, such as team style or recent promotion/relegation status.\n",
    "\n",
    "**The historical goal-pattern features**, a large group of 288 metrics capturing how often each team scores or concedes 2+ or 3+ goals,contain the strongest correlations in the analysis. Even so, the largest values fall in the 0.08–0.10 range. The top features primarily involve home-team high-scoring patterns from recent seasons. That suggests that teams with a history of producing multi-goal performances at home tend to continue that behavior, although the linear relationship remains modest.\n",
    "\n",
    "Overall, the weak correlations across all feature groups reinforce the conclusion that football match outcomes are driven by non-linear dynamics, thresholds, and interactions rather than simple linear effects. This means linear models such as logistic regression will struggle to extract meaningful predictive signal from these features. In contrast, *tree-based models—like Random Forests and XGBoost are far better suited* because they can model complex patterns such as conditional splits, diminishing returns, and interaction effects between team strength, recent form, historical tendencies, and contextual factors.\n",
    "\n",
    "In summary, although individual correlations are low, the feature set remains highly valuable. These features likely contribute predictive power when combined in non-linear models capable of capturing interactions and contextual dependencies. The correlation results therefore validate the engineered features while highlighting the importance of advanced modeling techniques for this prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.7.2. Boolean/categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean features - automatically include all that exist in df_basic\n",
    "# Define expected boolean features (add new ones here as you create them)\n",
    "expected_bool_features = ['is_weekend', 'home_promoted', 'home_demoted',\n",
    "                          'away_promoted', 'away_demoted']\n",
    "bool_features = [feat for feat in expected_bool_features if feat in df_basic.columns]\n",
    "\n",
    "print(f\"Analyzing {len(bool_features)} boolean/categorical features:\")\n",
    "print(f\"Features: {bool_features}\\n\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Over 2.5 rate by categorical feature:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for feat in bool_features:\n",
    "    grouped = df_basic.groupby(feat)['over_2_5'].agg(['mean', 'count'])\n",
    "    print(f\"\\n{feat}:\")\n",
    "    print(grouped)\n",
    "\n",
    "    # Chi-squared test\n",
    "    contingency = pd.crosstab(df_basic[feat], df_basic['over_2_5'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "    print(f\"Chi-squared p-value: {p:.4f}\")\n",
    "\n",
    "# Visualize - dynamically create subplots based on number of features\n",
    "n_features = min(len(bool_features), 5)  # Limit to 5 for readability\n",
    "fig, axes = plt.subplots(1, n_features, figsize=(5 * n_features, 4))\n",
    "if n_features == 1:\n",
    "    axes = [axes]  # Make it iterable\n",
    "\n",
    "# Configuration for feature visualization\n",
    "feature_configs = {\n",
    "    'is_weekend': {'labels': ['Weekday', 'Weekend'], 'title': 'Over 2.5 Rate: Weekend vs Weekday'},\n",
    "    'home_promoted': {'labels': ['Regular', 'Promoted'], 'title': 'Over 2.5 Rate: Home Team Promoted'},\n",
    "    'home_demoted': {'labels': ['Regular', 'Demoted'], 'title': 'Over 2.5 Rate: Home Team Demoted'},\n",
    "    'away_promoted': {'labels': ['Regular', 'Promoted'], 'title': 'Over 2.5 Rate: Away Team Promoted'},\n",
    "    'away_demoted': {'labels': ['Regular', 'Demoted'], 'title': 'Over 2.5 Rate: Away Team Demoted'}\n",
    "}\n",
    "\n",
    "for idx, feat in enumerate(bool_features[:n_features]):\n",
    "    rates = df_basic.groupby(feat)['over_2_5'].mean()\n",
    "    config = feature_configs.get(feat, {'labels': ['False', 'True'], 'title': f'Over 2.5 Rate: {feat}'})\n",
    "\n",
    "    axes[idx].bar(config['labels'], rates.values, color=['steelblue', 'coral'])\n",
    "    axes[idx].set_title(config['title'], fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Over 2.5 Rate')\n",
    "    axes[idx].set_ylim([0.45, 0.55])  # Zoom in on the relevant range\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(rates.values):\n",
    "        axes[idx].text(i, v + 0.002, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Boolean/Categorical Features:**\n",
    "\n",
    "The chi-squared analysis evaluates whether categorical match characteristics show statistically significant differences in Over 2.5 goal rates. Although effect sizes are small, a few features display meaningful deviations from the baseline:\n",
    "\n",
    "**Statistically Significant Predictors**  \n",
    "\n",
    "1. Weekend vs Weekday (p = 0.0012)  \n",
    "- Weekend fixtures have a noticeably higher Over 2.5 rate (50.5%) compared to weekday matches (48.7%).  \n",
    "- This is the strongest categorical signal in the analysis.  \n",
    "- A plausible explanation is that weekend matches often feature larger crowds and higher tempo games, more rested squads,more open tactical setups.  \n",
    "\n",
    "2. Away Team Demoted (p = 0.0121)\n",
    "- Demoted away teams record a significantly lower Over 2.5 rate (47.6%) than regular away teams (50.1%).\n",
    "- This suggests that relegated teams may adopt more defensive, risk-averse strategies, especially when playing away, potentially due to weaker overall squad quality at the higher level, focus on avoiding heavy defeats, psychological strain after demotion.\n",
    "\n",
    "3. Home Team Demoted (p = 0.0277)\n",
    "- A similar pattern appears at home: demoted teams produce fewer high-scoring matches (47.8% vs 50.1%).\n",
    "- The parallel home/away effects reinforce the conclusion that demotion status depresses goal totals regardless of venue.\n",
    "\n",
    "**Not Statistically Significant**\n",
    "\n",
    "4. Away Team Promoted (p = 0.0712)\n",
    "- Promoted away sides show a slightly higher Over 2.5 rate (51.8%), but the effect does not reach statistical significance.\n",
    "- It may reflect more adventurous playstyles or weaker defenses, but the evidence is inconclusive.\n",
    "\n",
    "5. Home Team Promoted (p = 0.4339)\n",
    "- No meaningful difference (50.8% vs 49.9%).\n",
    "- Promoted teams do not appear to influence scoring patterns at home in any systematic way.\n",
    "\n",
    "\n",
    "Overall, the weekend indicator emerges as the strongest categorical predictor, consistently showing a higher likelihood of matches ending Over 2.5 goals. Demotion status, both for home and away teams—forms the next most reliable signal, suggesting that relegated teams tend to engage in more conservative, lower-scoring matches. In contrast, promotion-related features exhibit mixed or statistically insignificant effects. Although the observed differences across all categories are relatively small, typically within a ±3 percentage point range, these variables can still provide useful predictive value when incorporated into non-linear models such as Random Forests or XGBoost, which are capable of capturing subtle interactions and context-dependent relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Extended - feature engineering\n",
    "We're creating extended dataframe with all available match data including detailed statistics and betting odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTENDED DATASET: All available match data including detailed statistics\n",
    "extended_core_features = [col for col in [\n",
    "    # Core match info\n",
    "    'Div', 'Season', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR',\n",
    "    # Match statistics\n",
    "    'Attendance', 'Referee', 'HS', 'AS', 'HST', 'AST', 'HHW', 'AHW', 'HC', 'AC',\n",
    "    'HF', 'AF', 'HFKC', 'AFKC', 'HO', 'AO', 'HY', 'AY', 'HR', 'AR', 'HBP', 'ABP'\n",
    "] if col in all_matches.columns]\n",
    "\n",
    "# All engineered features (using rich match statistics)\n",
    "# Note: Additional features (time-based + historical) will be merged from df_basic after creation\n",
    "extended_engineered_features = [col for col in [\n",
    "    'total_goals', 'ht_total_goals', 'second_half_goals',  # Goal-based\n",
    "    'home_shot_accuracy', 'away_shot_accuracy', 'total_shots', 'total_shots_on_target',  # Shot-based\n",
    "    'shot_dominance', 'corner_dominance', 'total_fouls', 'total_cards', 'card_intensity',  # Game dynamics\n",
    "    'league_tier', 'month', 'is_weekend',  # Date/league features\n",
    "    'over_2_5'  # Target variable\n",
    "] if col in all_matches.columns]\n",
    "\n",
    "# Extended features (betting odds - only high-quality columns after imputation)\n",
    "betting_features = []\n",
    "for col in all_matches.columns:\n",
    "    # Check if it's a betting column and has good data coverage (>10%)\n",
    "    if any(bookmaker in col for bookmaker in ['B365', 'BW', 'PS', 'IW', 'LB', 'WH', 'SJ', 'VC', 'BF', '1XB']):\n",
    "        data_coverage = (all_matches[col].notna().sum() / len(all_matches)) * 100\n",
    "        if data_coverage >= 10:  # Only include columns with at least 10% data coverage\n",
    "            betting_features.append(col)\n",
    "\n",
    "# Create extended dataframe\n",
    "all_extended_features = extended_core_features + extended_engineered_features + betting_features\n",
    "# Remove duplicates while preserving order\n",
    "all_extended_features = list(dict.fromkeys(all_extended_features))\n",
    "\n",
    "df_extended = all_matches[all_extended_features].copy()\n",
    "df_extended = df_extended.sort_values(['Div', 'Date']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Extended dataframe created\")\n",
    "print(f\"Shape: {df_extended.shape}\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"Core features: {len(extended_core_features)}\")\n",
    "print(f\"Engineered features: {len(extended_engineered_features)}\")\n",
    "print(f\"Betting features (>10% coverage): {len(betting_features)}\")\n",
    "print(f\"Total features: {len(all_extended_features)}\")\n",
    "print(f\"\\nColumns: {df_extended.columns.tolist()[:20]}...\")  # Show first 20\n",
    "df_extended.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extended dataframe was successfully created and contains 42,593 matches with 111 features in total. Of these, 25 are core match variables (league, season, date/time, teams, goals, result, referee, and basic stats such as shots, corners, fouls and cards), and 16 are engineered features capturing goal structure (total/HT/2nd-half goals), shot efficiency, dominance metrics, game intensity, and contextual information (league tier, month, weekend flag, Over 2.5 label). On top of that, the dataset includes 70 betting-related columns with at least 10% data coverage, spanning multiple bookmakers and markets (1X2, Asian handicap, and goal-line odds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Feature Integration from Baseline Dataset\n",
    "\n",
    "We integrate historical and time-based features from df_basic into df_extended through aligned row-by-row merging. This ensures that all engineered features—including MA5 indicators, historical position percentiles, goal-pattern statistics, and derived contextual measures—are available alongside the extended match statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_based_features = [\n",
    "    'home_days_since_last', 'away_days_since_last',\n",
    "    'home_goals_ma5', 'away_goals_ma5', 'home_conceded_ma5', 'away_conceded_ma5',\n",
    "    'home_promoted', 'away_promoted', 'home_demoted', 'away_demoted'\n",
    "]\n",
    "\n",
    "# Historical position features (overall only)\n",
    "historical_position_cols = [col for col in df_basic.columns if 'position_pct_' in col]\n",
    "\n",
    "# Historical goal pattern features (overall + home-specific + away-specific, counts + percentages)\n",
    "historical_goal_cols = [col for col in df_basic.columns if any(\n",
    "    f'{p}_{t}plus' in col for p in ['scored', 'conceded', 'total'] for t in [2, 3]\n",
    ")]\n",
    "\n",
    "# Derived features combining historical patterns\n",
    "derived_features = [col for col in df_basic.columns if any(\n",
    "    pattern in col for pattern in ['_strength_', '_combined_']\n",
    ")]\n",
    "\n",
    "features_to_merge = time_based_features + historical_position_cols + historical_goal_cols + derived_features\n",
    "\n",
    "print(f\"Features to merge from df_basic: {len(features_to_merge)}\")\n",
    "print(f\"Time-based features: {len(time_based_features)}\")\n",
    "print(f\"Position percentiles: {len(historical_position_cols)}\")\n",
    "print(f\"Goal patterns (overall + home/away, counts + pct): {len(historical_goal_cols)}\")\n",
    "print(f\"Derived features: {len(derived_features)}\")\n",
    "\n",
    "df_basic_sorted = df_basic.sort_values(['Div', 'Date']).reset_index(drop=True)\n",
    "df_extended_sorted = df_extended.sort_values(['Div', 'Date']).reset_index(drop=True)\n",
    "\n",
    "match_check = (\n",
    "    (df_basic_sorted['Div'] == df_extended_sorted['Div']) &\n",
    "    (df_basic_sorted['Date'] == df_extended_sorted['Date']) &\n",
    "    (df_basic_sorted['HomeTeam'] == df_extended_sorted['HomeTeam']) &\n",
    "    (df_basic_sorted['AwayTeam'] == df_extended_sorted['AwayTeam'])\n",
    ").all()\n",
    "\n",
    "if match_check:\n",
    "    print(f\"\\nRow alignment verified - safe to merge features\")\n",
    "\n",
    "    for col in features_to_merge:\n",
    "        df_extended[col] = df_basic_sorted[col].values\n",
    "\n",
    "    print(f\"{len(features_to_merge)} features added to df_extended\")\n",
    "    print(f\"- {len(time_based_features)} time-based features\")\n",
    "    print(f\"- {len(historical_position_cols)} position percentiles\")\n",
    "    print(f\"- {len(historical_goal_cols)} goal pattern features\")\n",
    "    print(f\"- {len(derived_features)} derived features\")\n",
    "    print(f\"\\nFinal df_extended shape: {df_extended.shape}\")\n",
    "else:\n",
    "    print(\"⚠ Row mismatch detected - cannot safely merge features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2. Extended Statistics - Moving Averages & Seasonal Patterns\n",
    "\n",
    "Furthermore, we've decided to calculate MA5 and historical patterns for match statistics (shots, corners, fouls, cards, etc.) following the same approach as goal-based features.\n",
    "\n",
    "Both features follow strict temporal logic: they only reference information available before each match, preventing data leakage while capturing meaningful team tendencies and recent form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate moving averages and seasonal history for extended match statistics.\n",
    "Following the same pattern as goal-based features in df_basic.\n",
    "\n",
    "MA5 Features: High + Medium Priority (Shots, Shots on Target, Corners, Fouls, Yellow Cards)\n",
    "Seasonal Patterns: High Priority Only (Shots, Shots on Target, Corners)\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 4.4.2: EXTENDED STATS MOVING AVERAGES & SEASONAL PATTERNS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: 5-Match Moving Averages (High + Medium Priority)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n1. CALCULATING 5-MATCH MOVING AVERAGES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define statistics to calculate MA5 for - High and Medium priority\n",
    "ma5_stats_config = {\n",
    "    # High Priority - Shooting\n",
    "    ('HS', 'shots'): 'home',\n",
    "    ('AS', 'shots'): 'away',\n",
    "    ('HST', 'shots_target'): 'home',\n",
    "    ('AST', 'shots_target'): 'away',\n",
    "    # High Priority - Attacking Pressure\n",
    "    ('HC', 'corners'): 'home',\n",
    "    ('AC', 'corners'): 'away',\n",
    "    # Medium Priority - Discipline\n",
    "    ('HF', 'fouls'): 'home',\n",
    "    ('AF', 'fouls'): 'away',\n",
    "    ('HY', 'yellows'): 'home',\n",
    "    ('AY', 'yellows'): 'away',\n",
    "}\n",
    "\n",
    "# Initialize MA5 columns\n",
    "print(f\"Initializing {len(ma5_stats_config)} MA5 columns...\")\n",
    "for (raw_col, stat_name), team_type in ma5_stats_config.items():\n",
    "    ma5_col = f'{team_type}_{stat_name}_ma5'\n",
    "    df_extended[ma5_col] = np.nan\n",
    "\n",
    "# Calculate moving averages - optimized by pre-sorting\n",
    "print(\"Calculating moving averages (optimized groupby approach)...\")\n",
    "df_extended_sorted = df_extended.sort_values(['Div', 'Date']).reset_index(drop=True)\n",
    "\n",
    "for (raw_col, stat_name), team_type in ma5_stats_config.items():\n",
    "    if raw_col not in df_extended.columns:\n",
    "        continue\n",
    "\n",
    "    ma5_col = f'{team_type}_{stat_name}_ma5'\n",
    "    team_col = 'HomeTeam' if team_type == 'home' else 'AwayTeam'\n",
    "\n",
    "    print(f\"Processing {ma5_col}...\")\n",
    "\n",
    "    # Group by division and team, then calculate MA5\n",
    "    for (div, team), group in df_extended_sorted.groupby(['Div', team_col]):\n",
    "        indices = group.index.tolist()\n",
    "        values = group[raw_col].values\n",
    "\n",
    "        # Calculate MA5 for each match in this group\n",
    "        for i, idx in enumerate(indices):\n",
    "            if i >= 5:  # Need at least 5 previous matches\n",
    "                ma5_value = np.nanmean(values[i-5:i])  # Exclude current match\n",
    "                if not np.isnan(ma5_value):\n",
    "                    df_extended.loc[idx, ma5_col] = ma5_value\n",
    "\n",
    "# NO DATA LEAKAGE: NaN values preserved for early-season matches\n",
    "print(\"\\nMA5 Summary:\")\n",
    "for (raw_col, stat_name), team_type in ma5_stats_config.items():\n",
    "    ma5_col = f'{team_type}_{stat_name}_ma5'\n",
    "    if ma5_col in df_extended.columns:\n",
    "        missing = df_extended[ma5_col].isna().sum()\n",
    "        missing_pct = (missing / len(df_extended)) * 100\n",
    "        mean_val = df_extended[ma5_col].mean()\n",
    "        print(f\"{ma5_col:25s}: missing={missing:5d} ({missing_pct:4.1f}%), mean={mean_val:6.2f}\")\n",
    "\n",
    "print(f\"Added {len(ma5_stats_config)} moving average features\")\n",
    "print(f\"(NaN values preserved for early-season matches - no data leakage)\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Seasonal Historical Patterns (High Priority Only)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n2. CALCULATING SEASONAL HISTORICAL PATTERNS\")\n",
    "print(\"-\" * 70)\n",
    "print(\"High priority features only: Shots, Shots on Target, Corners\")\n",
    "\n",
    "# Define thresholds for HIGH PRIORITY stats only\n",
    "stat_thresholds = {\n",
    "    'shots': [10, 15],           # 10+ shots, 15+ shots\n",
    "    'shots_target': [5, 8],      # 5+ on target, 8+ on target\n",
    "    'corners': [6, 10],          # 6+ corners, 10+ corners\n",
    "}\n",
    "\n",
    "# Season info\n",
    "unique_seasons = sorted(df_extended['Season'].unique())\n",
    "season_to_order = {s: i for i, s in enumerate(unique_seasons)}\n",
    "past_seasons = ['2019/2020', '2020/2021', '2021/2022', '2022/2023', '2023/2024', '2024/2025']\n",
    "season_years = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "# Map stat names to columns\n",
    "stat_to_home_col = {'shots': 'HS', 'shots_target': 'HST', 'corners': 'HC'}\n",
    "stat_to_away_col = {'shots': 'AS', 'shots_target': 'AST', 'corners': 'AC'}\n",
    "\n",
    "# Pre-calculate seasonal statistics for all teams (OPTIMIZATION)\n",
    "print(\"Pre-calculating team-season statistics...\")\n",
    "team_season_stats = {}\n",
    "\n",
    "for season in past_seasons:\n",
    "    for div in df_extended['Div'].unique():\n",
    "        season_div_mask = (df_extended['Season'] == season) & (df_extended['Div'] == div)\n",
    "        season_div_data = df_extended[season_div_mask]\n",
    "\n",
    "        if len(season_div_data) == 0:\n",
    "            continue\n",
    "\n",
    "        # Get all teams in this season/division\n",
    "        all_teams = set(season_div_data['HomeTeam'].unique()) | set(season_div_data['AwayTeam'].unique())\n",
    "\n",
    "        for team in all_teams:\n",
    "            # Overall stats (all matches)\n",
    "            overall_mask = (season_div_data['HomeTeam'] == team) | (season_div_data['AwayTeam'] == team)\n",
    "            overall_matches = season_div_data[overall_mask]\n",
    "\n",
    "            # Home-only stats\n",
    "            home_mask = season_div_data['HomeTeam'] == team\n",
    "            home_matches = season_div_data[home_mask]\n",
    "\n",
    "            # Away-only stats\n",
    "            away_mask = season_div_data['AwayTeam'] == team\n",
    "            away_matches = season_div_data[away_mask]\n",
    "\n",
    "            # Calculate stats for each threshold\n",
    "            stats = {}\n",
    "            for stat_name, thresholds in stat_thresholds.items():\n",
    "                h_col = stat_to_home_col[stat_name]\n",
    "                a_col = stat_to_away_col[stat_name]\n",
    "\n",
    "                for threshold in thresholds:\n",
    "                    # Overall stats\n",
    "                    count = 0\n",
    "                    for _, match in overall_matches.iterrows():\n",
    "                        col = h_col if match['HomeTeam'] == team else a_col\n",
    "                        if not pd.isna(match.get(col)) and match.get(col, 0) >= threshold:\n",
    "                            count += 1\n",
    "                    total = len(overall_matches)\n",
    "                    stats[f'{stat_name}_{threshold}plus_count'] = count\n",
    "                    stats[f'{stat_name}_{threshold}plus_pct'] = count / total if total > 0 else 0\n",
    "\n",
    "                    # Home-only stats\n",
    "                    if h_col in home_matches.columns:\n",
    "                        home_count = (home_matches[h_col] >= threshold).sum()\n",
    "                        home_total = len(home_matches)\n",
    "                        stats[f'home_{stat_name}_{threshold}plus_count'] = home_count\n",
    "                        stats[f'home_{stat_name}_{threshold}plus_pct'] = home_count / home_total if home_total > 0 else 0\n",
    "\n",
    "                    # Away-only stats\n",
    "                    if a_col in away_matches.columns:\n",
    "                        away_count = (away_matches[a_col] >= threshold).sum()\n",
    "                        away_total = len(away_matches)\n",
    "                        stats[f'away_{stat_name}_{threshold}plus_count'] = away_count\n",
    "                        stats[f'away_{stat_name}_{threshold}plus_pct'] = away_count / away_total if away_total > 0 else 0\n",
    "\n",
    "            team_season_stats[(season, div, team)] = stats\n",
    "\n",
    "print(f\"Pre-calculated stats for {len(team_season_stats)} team-season combinations\")\n",
    "\n",
    "# Initialize seasonal pattern columns\n",
    "print(\"Initializing seasonal pattern columns...\")\n",
    "total_columns = 0\n",
    "for stat_name in stat_thresholds.keys():\n",
    "    for threshold in stat_thresholds[stat_name]:\n",
    "        for year in season_years:\n",
    "            # Overall patterns\n",
    "            for prefix in ['home', 'away']:\n",
    "                df_extended[f'{prefix}_{stat_name}_{threshold}plus_count_{year}'] = 0\n",
    "                df_extended[f'{prefix}_{stat_name}_{threshold}plus_pct_{year}'] = np.nan\n",
    "                total_columns += 2\n",
    "            # Context-aware patterns\n",
    "            df_extended[f'home_home_{stat_name}_{threshold}plus_count_{year}'] = 0\n",
    "            df_extended[f'home_home_{stat_name}_{threshold}plus_pct_{year}'] = np.nan\n",
    "            df_extended[f'away_away_{stat_name}_{threshold}plus_count_{year}'] = 0\n",
    "            df_extended[f'away_away_{stat_name}_{threshold}plus_pct_{year}'] = np.nan\n",
    "            total_columns += 4\n",
    "\n",
    "print(f\"Created {total_columns} seasonal pattern columns\")\n",
    "\n",
    "# Populate features using pre-calculated statistics (FAST!)\n",
    "print(\"\\nPopulating seasonal pattern features (using lookups)...\")\n",
    "for idx, row in df_extended.iterrows():\n",
    "    current_season = row['Season']\n",
    "    current_season_order = season_to_order.get(current_season, 999)\n",
    "\n",
    "    for year_idx, year in enumerate(season_years):\n",
    "        if year_idx >= current_season_order:\n",
    "            continue\n",
    "\n",
    "        past_season = past_seasons[year_idx]\n",
    "\n",
    "        # Lookup home team stats\n",
    "        home_key = (past_season, row['Div'], row['HomeTeam'])\n",
    "        if home_key in team_season_stats:\n",
    "            home_stats = team_season_stats[home_key]\n",
    "            for stat_name in stat_thresholds.keys():\n",
    "                for threshold in stat_thresholds[stat_name]:\n",
    "                    # Overall\n",
    "                    df_extended.loc[idx, f'home_{stat_name}_{threshold}plus_count_{year}'] = home_stats.get(f'{stat_name}_{threshold}plus_count', 0)\n",
    "                    df_extended.loc[idx, f'home_{stat_name}_{threshold}plus_pct_{year}'] = home_stats.get(f'{stat_name}_{threshold}plus_pct', np.nan)\n",
    "                    # Home-specific\n",
    "                    df_extended.loc[idx, f'home_home_{stat_name}_{threshold}plus_count_{year}'] = home_stats.get(f'home_{stat_name}_{threshold}plus_count', 0)\n",
    "                    df_extended.loc[idx, f'home_home_{stat_name}_{threshold}plus_pct_{year}'] = home_stats.get(f'home_{stat_name}_{threshold}plus_pct', np.nan)\n",
    "\n",
    "        # Lookup away team stats\n",
    "        away_key = (past_season, row['Div'], row['AwayTeam'])\n",
    "        if away_key in team_season_stats:\n",
    "            away_stats = team_season_stats[away_key]\n",
    "            for stat_name in stat_thresholds.keys():\n",
    "                for threshold in stat_thresholds[stat_name]:\n",
    "                    # Overall\n",
    "                    df_extended.loc[idx, f'away_{stat_name}_{threshold}plus_count_{year}'] = away_stats.get(f'{stat_name}_{threshold}plus_count', 0)\n",
    "                    df_extended.loc[idx, f'away_{stat_name}_{threshold}plus_pct_{year}'] = away_stats.get(f'{stat_name}_{threshold}plus_pct', np.nan)\n",
    "                    # Away-specific\n",
    "                    df_extended.loc[idx, f'away_away_{stat_name}_{threshold}plus_count_{year}'] = away_stats.get(f'away_{stat_name}_{threshold}plus_count', 0)\n",
    "                    df_extended.loc[idx, f'away_away_{stat_name}_{threshold}plus_pct_{year}'] = away_stats.get(f'away_{stat_name}_{threshold}plus_pct', np.nan)\n",
    "\n",
    "    # Progress indicator\n",
    "    if (idx + 1) % 10000 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(df_extended)} matches...\")\n",
    "\n",
    "print(f\"Populated {total_columns} seasonal pattern features\")\n",
    "\n",
    "# ============================================================\n",
    "# Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY - SECTION 4.4.2 FEATURE ENGINEERING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Moving Average Features (MA5): {len(ma5_stats_config)}\")\n",
    "print(f\"- High Priority: Shots, Shots on Target, Corners\")\n",
    "print(f\"- Medium Priority: Fouls, Yellow Cards\")\n",
    "print(f\"\\nSeasonal Pattern Features: {total_columns}\")\n",
    "print(f\"- High Priority Only: Shots, Shots on Target, Corners\")\n",
    "print(f\"- Overall + Home/Away context for each stat\")\n",
    "print(f\"- {len(stat_thresholds)} stat types × 2 thresholds × 6 seasons\")\n",
    "print(f\"\\nTotal New Features: {len(ma5_stats_config) + total_columns}\")\n",
    "print(f\"Final df_extended shape: {df_extended.shape}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3. Betting odds\n",
    "Betting odds data from multiple bookmakers provides valuable market consensus on match outcomes. We consolidate this information into interpretable aggregate features that eliminate redundancy while preserving predictive signal.\n",
    "\n",
    "Goals:\n",
    "1. Merge BetVictor (BV) and VC Bet odds (same company, rebranded)\n",
    "2. Calculate minimum odds for each betting category\n",
    "3. Count number of bookmakers per betting category\n",
    "4. Remove individual bookmaker columns, keep only aggregates (Max/Avg/Min/Count)\n",
    "\n",
    "Betting Categories:\n",
    "- Match Odds (H/D/A): 1X2 pre-match\n",
    "- Match Odds Closing (CH/CD/CA): 1X2 closing\n",
    "- Over/Under (>2.5/<2.5): Total goals pre-match\n",
    "- Over/Under Closing (C>2.5/C<2.5): Total goals closing\n",
    "- Asian Handicap (AHH/AHA): Pre-match handicap\n",
    "- Asian Handicap Closing (CAHH/CAHA): Closing handicap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Add Max/Avg columns from all_matches if missing\n",
    "\n",
    "print(\"\\n1. ADDING MAX/AVG AGGREGATE COLUMNS FROM SOURCE DATA\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Add Max/Avg columns from all_matches if they're not already in df_extended\n",
    "max_avg_cols_to_add = [col for col in all_matches.columns\n",
    "                       if col.startswith(('Max', 'Avg'))\n",
    "                       and col not in df_extended.columns]\n",
    "\n",
    "if max_avg_cols_to_add:\n",
    "    print(f\"Adding {len(max_avg_cols_to_add)} Max/Avg columns:\")\n",
    "    for col in sorted(max_avg_cols_to_add):\n",
    "        df_extended[col] = all_matches[col]\n",
    "        print(f\"+ {col}\")\n",
    "else:\n",
    "    print(\"All Max/Avg columns already present\")\n",
    "\n",
    "# STEP 2: Merge BetVictor and VC Bet (Same Company)\n",
    "\n",
    "\n",
    "print(\"\\n2. MERGING BETVICTOR (BV) AND VC BET ODDS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# BetVictor columns for different betting categories\n",
    "bv_vc_pairs = {\n",
    "    'BVH': 'VCH', 'BVD': 'VCD', 'BVA': 'VCA',\n",
    "    'BVCH': 'VCCH', 'BVCD': 'VCCD', 'BVCA': 'VCCA',\n",
    "}\n",
    "\n",
    "merged_count = 0\n",
    "for bv_col, vc_col in bv_vc_pairs.items():\n",
    "    if bv_col in df_extended.columns and vc_col in df_extended.columns:\n",
    "        before_na = df_extended[bv_col].isna().sum()\n",
    "        df_extended[bv_col] = df_extended[bv_col].fillna(df_extended[vc_col])\n",
    "        after_na = df_extended[bv_col].isna().sum()\n",
    "        filled = before_na - after_na\n",
    "        if filled > 0:\n",
    "            print(f\"{bv_col}: filled {filled} values from {vc_col}\")\n",
    "            merged_count += 1\n",
    "\n",
    "if merged_count == 0:\n",
    "    print(f\"No VC columns found or already merged\")\n",
    "\n",
    "print(f\" BetVictor and VC Bet odds merged\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Define Bookmaker Columns by Category\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n3. IDENTIFYING BOOKMAKER COLUMNS BY CATEGORY\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define bookmaker prefixes (excluding aggregates like Max, Avg, Bb)\n",
    "bookmakers = ['1XB', 'B365', 'BF', 'BFD', 'BMGM', 'BV', 'BS', 'BW', 'CL',\n",
    "              'GB', 'IW', 'LB', 'PS', 'PSH', 'PSD', 'PSA', 'PH', 'PD', 'PA',\n",
    "              'SO', 'SB', 'SJ', 'SY', 'WH']\n",
    "\n",
    "# Define betting categories with their suffixes and column naming\n",
    "betting_categories = {\n",
    "    'match_odds_open': {\n",
    "        'suffixes': ['H', 'D', 'A'],\n",
    "        'count_col': 'NumBookmakers_MatchOdds',\n",
    "        'min_cols': ['MinH', 'MinD', 'MinA']\n",
    "    },\n",
    "    'match_odds_closing': {\n",
    "        'suffixes': ['CH', 'CD', 'CA'],\n",
    "        'count_col': 'NumBookmakers_MatchOddsClosing',\n",
    "        'min_cols': ['MinCH', 'MinCD', 'MinCA']\n",
    "    },\n",
    "    'over_under_open': {\n",
    "        'suffixes': ['>2.5', '<2.5'],\n",
    "        'count_col': 'NumBookmakers_OverUnder',\n",
    "        'min_cols': ['Min>2.5', 'Min<2.5']\n",
    "    },\n",
    "    'over_under_closing': {\n",
    "        'suffixes': ['C>2.5', 'C<2.5'],\n",
    "        'count_col': 'NumBookmakers_OverUnderClosing',\n",
    "        'min_cols': ['MinC>2.5', 'MinC<2.5']\n",
    "    },\n",
    "    'asian_handicap_open': {\n",
    "        'suffixes': ['AHH', 'AHA'],\n",
    "        'count_col': 'NumBookmakers_AsianHandicap',\n",
    "        'min_cols': ['MinAHH', 'MinAHA']\n",
    "    },\n",
    "    'asian_handicap_closing': {\n",
    "        'suffixes': ['CAHH', 'CAHA'],\n",
    "        'count_col': 'NumBookmakers_AsianHandicapClosing',\n",
    "        'min_cols': ['MinCAHH', 'MinCAHA']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Find bookmaker columns for each category\n",
    "bookmaker_cols_by_category = {}\n",
    "\n",
    "for category_name, category_info in betting_categories.items():\n",
    "    suffixes = category_info['suffixes']\n",
    "    bookmaker_cols_by_category[category_name] = {}\n",
    "\n",
    "    for suffix in suffixes:\n",
    "        cols = []\n",
    "        for bookmaker in bookmakers:\n",
    "            # Check for exact column match\n",
    "            col_name = f\"{bookmaker}{suffix}\"\n",
    "            if col_name in df_extended.columns:\n",
    "                cols.append(col_name)\n",
    "\n",
    "        bookmaker_cols_by_category[category_name][suffix] = cols\n",
    "        if cols:\n",
    "            print(f\"{category_name:30s} [{suffix:6s}]: {len(cols):2d} bookmakers\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: Calculate Min Odds and Bookmaker Counts per Category\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n4. CALCULATING MIN ODDS AND BOOKMAKER COUNTS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for category_name, category_info in betting_categories.items():\n",
    "    suffixes = category_info['suffixes']\n",
    "    count_col = category_info['count_col']\n",
    "    min_cols = category_info['min_cols']\n",
    "\n",
    "    # Track unique bookmakers for this category\n",
    "    unique_bookmakers_per_row = []\n",
    "\n",
    "    for i, suffix in enumerate(suffixes):\n",
    "        bookmaker_cols = bookmaker_cols_by_category[category_name][suffix]\n",
    "\n",
    "        if not bookmaker_cols:\n",
    "            continue\n",
    "\n",
    "        # Calculate minimum odds for this suffix\n",
    "        min_col = min_cols[i]\n",
    "        df_extended[min_col] = df_extended[bookmaker_cols].min(axis=1)\n",
    "\n",
    "        print(f\"Created {min_col:15s} from {len(bookmaker_cols)} bookmakers\")\n",
    "\n",
    "    # Calculate bookmaker count for this category\n",
    "    # Count how many bookmakers provided at least one odds type for this match\n",
    "    # For match odds: if a bookmaker has H, D, or A, count it once\n",
    "    all_bookmaker_cols_in_category = []\n",
    "    for suffix in suffixes:\n",
    "        all_bookmaker_cols_in_category.extend(bookmaker_cols_by_category[category_name][suffix])\n",
    "\n",
    "    if all_bookmaker_cols_in_category:\n",
    "        # Extract unique bookmaker prefixes from column names\n",
    "        def extract_bookmaker_prefix(col_name):\n",
    "            \"\"\"Extract bookmaker prefix from column name\"\"\"\n",
    "            for bm in bookmakers:\n",
    "                if col_name.startswith(bm):\n",
    "                    return bm\n",
    "            return None\n",
    "\n",
    "        # OPTIMIZED: Use vectorized pandas operations instead of nested loop\n",
    "        # For each row, count unique bookmakers that have at least one non-NaN value\n",
    "        def count_unique_bookmakers(row):\n",
    "            \"\"\"Count unique bookmakers with at least one non-NaN value for this row\"\"\"\n",
    "            unique_bm = set()\n",
    "            for col in all_bookmaker_cols_in_category:\n",
    "                if pd.notna(row[col]):\n",
    "                    bm_prefix = extract_bookmaker_prefix(col)\n",
    "                    if bm_prefix:\n",
    "                        unique_bm.add(bm_prefix)\n",
    "            return len(unique_bm)\n",
    "\n",
    "        # Apply function across rows - much faster than explicit loop\n",
    "        df_extended[count_col] = df_extended[all_bookmaker_cols_in_category].apply(count_unique_bookmakers, axis=1)\n",
    "        avg_count = df_extended[count_col].mean()\n",
    "        print(f\"Created {count_col:40s} (avg: {avg_count:.1f} bookmakers/match)\")\n",
    "\n",
    "print(f\"Created minimum odds and bookmaker counts for all categories\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5: Calculate Disagreement (Max - Min)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n5. CALCULATING BOOKMAKER DISAGREEMENT (MAX - MIN)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define disagreement calculations based on existing Max columns\n",
    "disagreement_mapping = {\n",
    "    'DisagreementH': ('MaxH', 'MinH'),\n",
    "    'DisagreementD': ('MaxD', 'MinD'),\n",
    "    'DisagreementA': ('MaxA', 'MinA'),\n",
    "    'DisagreementCH': ('MaxCH', 'MinCH'),\n",
    "    'DisagreementCD': ('MaxCD', 'MinCD'),\n",
    "    'DisagreementCA': ('MaxCA', 'MinCA'),\n",
    "    'Disagreement>2.5': ('Max>2.5', 'Min>2.5'),\n",
    "    'Disagreement<2.5': ('Max<2.5', 'Min<2.5'),\n",
    "    'DisagreementC>2.5': ('MaxC>2.5', 'MinC>2.5'),\n",
    "    'DisagreementC<2.5': ('MaxC<2.5', 'MinC<2.5'),\n",
    "    'DisagreementAHH': ('MaxAHH', 'MinAHH'),\n",
    "    'DisagreementAHA': ('MaxAHA', 'MinAHA'),\n",
    "    'DisagreementCAHH': ('MaxCAHH', 'MinCAHH'),\n",
    "    'DisagreementCAHA': ('MaxCAHA', 'MinCAHA'),\n",
    "}\n",
    "\n",
    "for disagreement_col, (max_col, min_col) in disagreement_mapping.items():\n",
    "    if max_col in df_extended.columns and min_col in df_extended.columns:\n",
    "        df_extended[disagreement_col] = df_extended[max_col] - df_extended[min_col]\n",
    "        avg_disagreement = df_extended[disagreement_col].mean()\n",
    "        print(f\"{disagreement_col:25s} = {max_col:12s} - {min_col:12s} (avg: {avg_disagreement:.3f})\")\n",
    "\n",
    "print(f\"Created disagreement features for available Max/Min pairs\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6: Remove Individual Bookmaker Columns\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n6. REMOVING INDIVIDUAL BOOKMAKER COLUMNS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Identify all individual bookmaker columns to remove\n",
    "individual_bookmaker_cols = []\n",
    "for col in df_extended.columns:\n",
    "    # Check if column starts with a bookmaker prefix\n",
    "    if any(col.startswith(bm) for bm in bookmakers):\n",
    "        # Exclude if it's an aggregate or new feature we created\n",
    "        if not col.startswith(('Num', 'Min', 'Disagreement')):\n",
    "            individual_bookmaker_cols.append(col)\n",
    "\n",
    "print(f\"Removing {len(individual_bookmaker_cols)} individual bookmaker columns...\")\n",
    "df_extended = df_extended.drop(columns=individual_bookmaker_cols)\n",
    "\n",
    "print(f\" Removed individual bookmaker columns\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 7: Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BETTING ODDS FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Count final betting features\n",
    "betting_features_remaining = [col for col in df_extended.columns if any(\n",
    "    pattern in col for pattern in ['Max', 'Min', 'Avg', 'Disagreement', 'NumBookmakers', 'Bb']\n",
    ")]\n",
    "\n",
    "print(f\"\\nFinal betting features: {len(betting_features_remaining)}\")\n",
    "print(f\"- Aggregate odds (Max/Avg/Min): {sum(1 for c in betting_features_remaining if c.startswith(('Max', 'Avg', 'Min')) and 'Disagreement' not in c and 'NumBookmakers' not in c)}\")\n",
    "print(f\"- Disagreement features: {sum(1 for c in betting_features_remaining if 'Disagreement' in c)}\")\n",
    "print(f\"- Bookmaker count features: {sum(1 for c in betting_features_remaining if 'NumBookmakers' in c)}\")\n",
    "print(f\"- BetBrain features: {sum(1 for c in betting_features_remaining if c.startswith('Bb'))}\")\n",
    "\n",
    "print(f\"\\nFinal df_extended shape: {df_extended.shape}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Final Feature Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1. Baseline Feature Summary\n",
    "\n",
    "Let's check out a quick health check + preview of df_basic right before we start dropping leakage columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of engineered features (BEFORE removing post-match columns)\n",
    "print(\"Final engineered dataframe (with all features):\")\n",
    "print(f\"Shape: {df_basic.shape}\")\n",
    "print(f\"\\nColumns:\")\n",
    "print(df_basic.columns.tolist())\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_basic.isnull().sum().sum())\n",
    "print(f\"\\nSample:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output shows that the baseline engineered dataset contains 42,593 matches and 332 features, combining core match info, time-based features, and a very large set of historical goal-pattern statistics. The high number of missing values (~44%) is expected, because early-season matches naturally lack historical data, and many rare-pattern features (like 3+ goals) don’t apply to all teams. The sample rows look correct: early matches have NaNs in MA5 features, weekend flags are accurate, and targets align with total goals. Overall, the summary confirms that the baseline dataset was built correctly before removing post-match leakage features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.1.1. Baseline - Added Features\n",
    "\n",
    "Starting from the original match records (Div, Season, Date, Time, HomeTeam, AwayTeam), the baseline dataset augments these identifiers with several groups of pre-match engineered features. After removing all direct post-match outcomes (FTHG, FTAG, FTR, total_goals), the final bseline feature matrix contains 328 columns, all available before kickoff. \n",
    "\n",
    "\n",
    "The added features for the baseline dataset can be grouped as:  \n",
    "**(a) Basic Structural and Calendar Features**  \n",
    "These features introduce simple but informative contextual variables:\n",
    "- `league_tier` – numerical league level extracted from each division code.\n",
    "- `month` – month of the match (1–12).\n",
    "- `is_weekend` – indicator for Saturday/Sunday fixtures.\n",
    "- `over_2_5` – binary target variable kept in the dataset but used only for modeling.\n",
    "  \n",
    "\n",
    "**(b) Rest and Short-Term Form (Time-Based Features)**  \n",
    "These features capture a team’s recent match rhythm and performance:  \n",
    "- Rest days - `home_days_since_last` and `away_days_since_last`\n",
    "- 5-match Moving Averages (MA5) - `home_goals_ma5`, `home_conceded_ma5` and `away_goals_ma5`, `away_conceded_ma5`  \n",
    "\n",
    "\n",
    "**(c) Promotion / Relegation Status and Season Ordering**  \n",
    "These features encode structural transitions and temporal progression:  \n",
    "- Promotion / Demotion Indicators - `home_promoted`, `away_promoted` and `home_demoted`, `away_demoted`\n",
    "- Season Index - `season_order` – ordinal indicator for the season (e.g., 2019 → 1, … 2024 → 6)\n",
    "\n",
    "\n",
    "**(d) Historical League Position Percentiles**\n",
    "These features approximate longrun team strength:  \n",
    "- For each season 2019–2024: home_position_pct_<year> and away_position_pct_<year>\n",
    "Each value represents a team’s final league standing normalised to a 0–1 range.\n",
    "\n",
    "\n",
    "**(e) Historical Goal Pattern Features (2+ and 3+ Goals)**  \n",
    "These features describe how frequently teams participate in high-scoring matches across seasons and contexts.  \n",
    "For each season (2019–2024), each pattern type (scored, conceded, total),\n",
    "and each threshold (2plus, 3plus), the dataset includes:\n",
    "- Overall Team Patterns - home_<pattern>_<threshold>_count_<year>, home_<pattern>_<threshold>_pct_<year>, away_<pattern>_<threshold>_count_<year>, away_<pattern>_<threshold>_pct_<year>\n",
    "- Home-Only and Away-Only Contexts - home_home_<pattern>_..., away_away_<pattern>_...\n",
    "\n",
    "These features provide deep historical context for team scoring behaviour.\n",
    "\n",
    "\n",
    "**(f) High-Level Derived Features**\n",
    "These features combine multiple signals into more interpretable summaries:  \n",
    "- position_pct_diff – relative strength difference based on league percentiles\n",
    "- combined_attack_strength – weighted blend of recent and historic attacking form\n",
    "- combined_defense_weakness – weighted blend of recent and historic defensive weakness\n",
    "- home_form_trend, away_form_trend – short-term performance trends\n",
    "- rest_days_advantage – difference between rest periods of both teams\n",
    "- season_progress – normalised stage of the season (0 = early, 1 = late)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.1.2.  Baseline - Main Observations\n",
    "\n",
    "The baseline dataset represents the first fully engineered version of the match data, containing 42,593 matches and 332 features prior to leakage removal. Despite the dataset containing a large number of missing values, this missingness is fully expected because early-season fixtures lack historical context, lower-tier or newly promoted teams have limited prior data, and high-threshold patterns (like 3+ goals) naturally occur infrequently. These missing values arise exclusively from the absence of past information, meaning they do not introduce any data leakage.    \n",
    "\n",
    "Correlation and statistical tests further confirm that no individual baseline feature strongly predicts Over/Under 2.5 goals on its own. All correlations are extremely weak, with absolute values below 0.02. Chi-square tests are similarly insignificant (p > 0.05), which indicats that none of the categorical predictors show meaningful standalone relationships with the target.    \n",
    "\n",
    "League tier exhibits the strongest correlation at only −0.012, hinting that lower leagues may feature slightly fewer high-scoring matches, but the effect is negligible. Recent attacking form displays a weak positive correlation (around 0.010), again far too small to matter independently. Features capturing promotion or relegation status do not produce consistent differences in goal frequency, and neither rest periods nor weekend scheduling show any measurable association with match goal totals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.1.3 Remove Post-Match Features to Prevent Data Leakage for Baseline\n",
    "\n",
    "With all historical and pre-match features fully constructed, the next step is to eliminate any columns that contain information generated after the match is played. These include full-time scores, half-time results, and any direct transformations of the final outcome (such as total_goals). Keeping such variables would allow the model to “peek into the future,” resulting in severe data leakage and unrealistically high performance.\n",
    "\n",
    "In the baseline dataset, we therefore identify and drop all post-match columns before modeling. The following code removes full-time goals, half-time statistics, final result indicators, and the total_goals variable, ensuring that only true pre-match information remains in df_basic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-match columns to remove from BASELINE dataset (df_basic)\n",
    "# These columns contain information only available AFTER the match is played\n",
    "post_match_basic = [\n",
    "    'FTHG', 'FTAG', 'FTR',  # Final match results\n",
    "    'total_goals',  # Direct derivative of the target (FTHG + FTAG)\n",
    "    'HTHG', 'HTAG', 'HTR',  # Half-time results (if present)\n",
    "]\n",
    "\n",
    "# Remove columns that exist in df_basic\n",
    "cols_to_drop_basic = [col for col in post_match_basic if col in df_basic.columns]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BASELINE DATASET (df_basic) - Removing Post-Match Features\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Shape before: {df_basic.shape}\")\n",
    "print(f\"Columns to remove: {cols_to_drop_basic}\")\n",
    "\n",
    "df_basic = df_basic.drop(columns=cols_to_drop_basic)\n",
    "\n",
    "print(f\"Shape after: {df_basic.shape}\")\n",
    "print(f\"\\nRemaining columns:\")\n",
    "print(df_basic.columns.tolist())\n",
    "print(f\"\\nBaseline dataset cleaned - only pre-match features remain\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2. Extended Feature Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2.1. Extended - Added Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2.2. Extended - Main Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2.3. Remove Post-Match Variables to Prevent Data Leakage for Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-match columns to remove from EXTENDED dataset (df_extended)\n",
    "# These include all match statistics and results that are only available after the match\n",
    "# NOTE: MA5 features are KEPT for training as they use historical data (previous 5 matches)\n",
    "post_match_extended = [\n",
    "    # Final match results\n",
    "    'FTHG', 'FTAG', 'FTR',\n",
    "    # Half-time results\n",
    "    'HTHG', 'HTAG', 'HTR',\n",
    "    # Shot statistics\n",
    "    'HS', 'AS', 'HST', 'AST',\n",
    "    # Corners\n",
    "    'HC', 'AC',\n",
    "    # Fouls\n",
    "    'HF', 'AF',\n",
    "    # Cards\n",
    "    'HY', 'AY', 'HR', 'AR',\n",
    "    # Other in-game statistics\n",
    "    'HHW', 'AHW', 'HFKC', 'AFKC', 'HO', 'AO', 'HBP', 'ABP',\n",
    "    # Derived features from post-match data\n",
    "    'total_goals', 'ht_total_goals', 'second_half_goals',\n",
    "    'home_shot_accuracy', 'away_shot_accuracy', 'total_shots', 'total_shots_on_target',\n",
    "    'shot_dominance', 'corner_dominance', 'total_fouls', 'total_cards', 'card_intensity',\n",
    "]\n",
    "\n",
    "# Remove columns that exist in df_extended\n",
    "cols_to_drop_extended = [col for col in post_match_extended if col in df_extended.columns]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXTENDED DATASET (df_extended) - Removing Post-Match Features\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Shape before: {df_extended.shape}\")\n",
    "print(f\"Columns to remove ({len(cols_to_drop_extended)}): {cols_to_drop_extended}\")\n",
    "\n",
    "df_extended = df_extended.drop(columns=cols_to_drop_extended)\n",
    "\n",
    "print(f\"Shape after: {df_extended.shape}\")\n",
    "print(f\"\\nRemaining columns:\")\n",
    "print(df_extended.columns.tolist())\n",
    "print(f\"\\nExtended dataset cleaned - only pre-match features remain\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Data Leakage Prevention\n",
    "\n",
    "**What was removed:**\n",
    "- **Match results:** FTHG, FTAG, FTR, HTHG, HTAG, HTR\n",
    "- **In-game statistics:** All shots, corners, fouls, cards\n",
    "- **Derived features:** total_goals, shot_accuracy, dominance metrics, card_intensity, etc.\n",
    "\n",
    "**What remains:**\n",
    "- **Pre-match identifiers:** Div, Season, Date, Time, HomeTeam, AwayTeam\n",
    "- **Pre-match context:** league_tier, month, is_weekend, Referee\n",
    "- **Historical features:** All MA5 features, position percentiles, goal patterns from PAST seasons\n",
    "- **Time-based features:** days_since_last, promoted/demoted indicators\n",
    "- **Betting odds:** Pre-match odds from bookmakers\n",
    "- **Target variable:** over_2_5 (kept for modeling)\n",
    "\n",
    "**Key principle:** All features in df_basic and df_extended are now calculated exclusively from:\n",
    "1. Information available BEFORE the match starts (dates, teams, league info)\n",
    "2. Historical data from PREVIOUS matches only (MA5, seasonal patterns, positions)\n",
    "3. Pre-match betting odds\n",
    "\n",
    "This ensures no information from the current match leaks into the predictive features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Train/Validation/Test Split by Season\n",
    "\n",
    "Create temporal splits to prevent data leakage. We'll use:\n",
    "- **Training:** 4 oldest seasons (2019/2020, 2020/2021, 2021/2022, 2022/2023)\n",
    "- **Validation:** 1 middle season (2023/2024)\n",
    "- **Testing:** 1 most recent seasons (2024/2025)\n",
    "\n",
    "This ensures the model is trained on past data and evaluated on future data, mimicking real-world deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define season splits\n",
    "train_seasons = ['2019/2020', '2020/2021', '2021/2022', '2022/2023']\n",
    "val_seasons = ['2023/2024']\n",
    "test_seasons = ['2024/2025']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAIN/VALIDATION/TEST SPLIT BY SEASON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Function to perform split for any dataframe\n",
    "def split_by_season(df, train_seasons, val_seasons, test_seasons, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Split dataframe by season with validation and ensure chronological sorting.\n",
    "\n",
    "    IMPORTANT: Data is sorted by Date to maintain temporal ordering, which is\n",
    "    critical for target encoding with shuffle=False in KFold cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check which seasons exist in the data\n",
    "    available_seasons = df['Season'].unique()\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    print(f\"Available seasons: {sorted(available_seasons)}\")\n",
    "\n",
    "    # Create splits\n",
    "    train_mask = df['Season'].isin(train_seasons)\n",
    "    val_mask = df['Season'].isin(val_seasons)\n",
    "    test_mask = df['Season'].isin(test_seasons)\n",
    "\n",
    "    # Sort by Date to ensure chronological order for target encoding\n",
    "    # Reset index to ensure sequential integer indexing (0, 1, 2, ...)\n",
    "    df_train = df[train_mask].copy().sort_values('Date').reset_index(drop=True)\n",
    "    df_val = df[val_mask].copy().sort_values('Date').reset_index(drop=True)\n",
    "    df_test = df[test_mask].copy().sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Report split sizes\n",
    "    print(f\"Training seasons: {train_seasons}\")\n",
    "    print(f\"Shape: {df_train.shape}\")\n",
    "    print(f\"Date range: {df_train['Date'].min()} to {df_train['Date'].max()}\")\n",
    "\n",
    "    print(f\"Validation seasons: {val_seasons}\")\n",
    "    print(f\"Shape: {df_val.shape}\")\n",
    "    print(f\"Date range: {df_val['Date'].min()} to {df_val['Date'].max()}\")\n",
    "\n",
    "    print(f\"Test seasons: {test_seasons}\")\n",
    "    print(f\"Shape: {df_test.shape}\")\n",
    "    print(f\"Date range: {df_test['Date'].min()} to {df_test['Date'].max()}\")\n",
    "\n",
    "    # Check for target distribution\n",
    "    if 'over_2_5' in df.columns:\n",
    "        train_rate = df_train['over_2_5'].mean()\n",
    "        val_rate = df_val['over_2_5'].mean()\n",
    "        test_rate = df_test['over_2_5'].mean()\n",
    "        print(f\"Over 2.5 rates: Train={train_rate:.3f}, Val={val_rate:.3f}, Test={test_rate:.3f}\")\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "# Split baseline dataset\n",
    "df_basic_train, df_basic_val, df_basic_test = split_by_season(\n",
    "    df_basic, train_seasons, val_seasons, test_seasons, \"BASELINE (df_basic)\"\n",
    ")\n",
    "\n",
    "# Split extended dataset\n",
    "df_extended_train, df_extended_val, df_extended_test = split_by_season(\n",
    "    df_extended, train_seasons, val_seasons, test_seasons, \"EXTENDED (df_extended)\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Temporal split completed successfully\")\n",
    "print(\"Data sorted chronologically and ready for target encoding\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Categorical Encoding\n",
    "\n",
    "## Overview\n",
    "\n",
    "We need to encode categorical variables before they can be used in machine learning models. We use different encoding strategies based on cardinality:\n",
    "\n",
    "### 1. Target Encoding (Chronological Expanding Window) - For High-Cardinality Variables\n",
    "**Variables:** HomeTeam, AwayTeam, Referee\n",
    "\n",
    "**Why Target Encoding?**\n",
    "- **High cardinality**: These variables have many unique values (hundreds of teams/referees)\n",
    "- **One-hot encoding** would create too many features (curse of dimensionality)\n",
    "- **Label encoding** would impose arbitrary ordering\n",
    "- **Target encoding** captures the relationship with the target variable\n",
    "\n",
    "**Chronological Expanding Window Approach:**\n",
    "1. Assumes all data is already sorted by Season/Date/Time\n",
    "2. Precomputes global target mean from training data only\n",
    "3. Maintains running sums and counts for each category\n",
    "4. For each row in chronological order:\n",
    "   - Calculate encoded value using statistics from **past matches only**\n",
    "   - Apply smoothing: `(count × mean + smoothing × global_mean) / (count + smoothing)`\n",
    "   - Update running statistics with current row's target\n",
    "5. For validation set: start with training statistics, encode chronologically\n",
    "6. For test set: start with training + validation statistics, encode chronologically\n",
    "\n",
    "**Why This Prevents Leakage:**\n",
    "- Each match is encoded using only information available **before** that match\n",
    "- Validation matches use only past training + validation matches\n",
    "- Test matches use only past training + validation + test matches\n",
    "- No future information leaks into past predictions\n",
    "\n",
    "**Smoothing Parameter:**\n",
    "- Prevents overfitting to rare categories\n",
    "- Higher smoothing = more regularization (closer to global mean)\n",
    "- We use `smoothing=10.0` as a reasonable default\n",
    "\n",
    "### 2. One-Hot Encoding - For Low-Cardinality Variable\n",
    "**Variable:** Div (League)\n",
    "\n",
    "**Why One-Hot Encoding?**\n",
    "- Low cardinality (~10 unique leagues)\n",
    "- Creates binary indicator columns for each league\n",
    "- No ordinality assumption\n",
    "- Standard approach for categorical variables with few categories\n",
    "\n",
    "### Variables NOT Encoded (Excluded from Features)\n",
    "- **Season**: Used for temporal train/test split - must exclude to prevent leakage\n",
    "- **Date/Time**: Temporal metadata (could extract cyclical features if needed)\n",
    "- **Original categorical columns**: HomeTeam, AwayTeam, Referee, Div (replaced by encoded versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_time_series(train_df, val_df, test_df, cat_column, target_column='over_2_5', prior_weight=10.0):\n",
    "    \"\"\"\n",
    "    Perform time-aware target encoding using chronological expanding window.\n",
    "    \n",
    "    This function prevents data leakage by ensuring each match is encoded using\n",
    "    only information from past matches. All inputs must be sorted by Season/Date/Time.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_df : DataFrame\n",
    "        Training data (must be sorted chronologically and include cat_column and target_column)\n",
    "    val_df : DataFrame\n",
    "        Validation data (must be sorted chronologically and include cat_column)\n",
    "    test_df : DataFrame\n",
    "        Test data (must be sorted chronologically and include cat_column)\n",
    "    cat_column : str\n",
    "        Name of the categorical column to encode\n",
    "    target_column : str\n",
    "        Name of the target column\n",
    "    prior_weight : float\n",
    "        Smoothing parameter (higher = more regularization toward global mean)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    train_encoded, val_encoded, test_encoded : numpy arrays\n",
    "        Encoded values aligned to input dataframes\n",
    "    \"\"\"\n",
    "    # Precompute global target mean from training data only\n",
    "    global_mean = train_df[target_column].mean()\n",
    "    \n",
    "    # Initialize running statistics using defaultdict\n",
    "    running_sum = defaultdict(float)\n",
    "    running_count = defaultdict(int)\n",
    "    \n",
    "    # --- Encode Training Set ---\n",
    "    train_encoded = np.zeros(len(train_df))\n",
    "    \n",
    "    for idx, row in train_df.iterrows():\n",
    "        category = row[cat_column]\n",
    "        target_value = row[target_column]\n",
    "        \n",
    "        # Get current running stats for this category\n",
    "        current_sum = running_sum[category]\n",
    "        current_count = running_count[category]\n",
    "        \n",
    "        # Calculate encoded value with smoothing (using past data only)\n",
    "        if current_count > 0:\n",
    "            encoded_value = (current_sum + prior_weight * global_mean) / (current_count + prior_weight)\n",
    "        else:\n",
    "            encoded_value = global_mean\n",
    "        \n",
    "        # Store encoded value\n",
    "        train_encoded[idx] = encoded_value\n",
    "        \n",
    "        # Update running statistics with current row\n",
    "        running_sum[category] += target_value\n",
    "        running_count[category] += 1\n",
    "    \n",
    "    # --- Encode Validation Set ---\n",
    "    # Copy training histories to start validation encoding\n",
    "    val_running_sum = running_sum.copy()\n",
    "    val_running_count = running_count.copy()\n",
    "    \n",
    "    val_encoded = np.zeros(len(val_df))\n",
    "    \n",
    "    for idx, row in val_df.iterrows():\n",
    "        category = row[cat_column]\n",
    "        target_value = row[target_column]\n",
    "        \n",
    "        # Get current running stats\n",
    "        current_sum = val_running_sum[category]\n",
    "        current_count = val_running_count[category]\n",
    "        \n",
    "        # Calculate encoded value with smoothing\n",
    "        if current_count > 0:\n",
    "            encoded_value = (current_sum + prior_weight * global_mean) / (current_count + prior_weight)\n",
    "        else:\n",
    "            encoded_value = global_mean\n",
    "        \n",
    "        # Store encoded value\n",
    "        val_encoded[idx] = encoded_value\n",
    "        \n",
    "        # Update running statistics with current row\n",
    "        val_running_sum[category] += target_value\n",
    "        val_running_count[category] += 1\n",
    "    \n",
    "    # --- Encode Test Set ---\n",
    "    # Start with train + validation histories\n",
    "    test_running_sum = val_running_sum.copy()\n",
    "    test_running_count = val_running_count.copy()\n",
    "    \n",
    "    test_encoded = np.zeros(len(test_df))\n",
    "    \n",
    "    for idx, row in test_df.iterrows():\n",
    "        category = row[cat_column]\n",
    "        target_value = row[target_column]\n",
    "        \n",
    "        # Get current running stats\n",
    "        current_sum = test_running_sum[category]\n",
    "        current_count = test_running_count[category]\n",
    "        \n",
    "        # Calculate encoded value with smoothing\n",
    "        if current_count > 0:\n",
    "            encoded_value = (current_sum + prior_weight * global_mean) / (current_count + prior_weight)\n",
    "        else:\n",
    "            encoded_value = global_mean\n",
    "        \n",
    "        # Store encoded value\n",
    "        test_encoded[idx] = encoded_value\n",
    "        \n",
    "        # Update running statistics with current row\n",
    "        test_running_sum[category] += target_value\n",
    "        test_running_count[category] += 1\n",
    "    \n",
    "    return train_encoded, val_encoded, test_encoded\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CATEGORICAL ENCODING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create copies to avoid modifying original data\n",
    "df_basic_train_encoded = df_basic_train.copy()\n",
    "df_basic_val_encoded = df_basic_val.copy()\n",
    "df_basic_test_encoded = df_basic_test.copy()\n",
    "\n",
    "df_extended_train_encoded = df_extended_train.copy()\n",
    "df_extended_val_encoded = df_extended_val.copy()\n",
    "df_extended_test_encoded = df_extended_test.copy()\n",
    "\n",
    "# Part 1: TARGET ENCODING for high-cardinality variables\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 1: TARGET ENCODING (CHRONOLOGICAL EXPANDING WINDOW)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "categorical_vars = ['HomeTeam', 'AwayTeam', 'Referee']\n",
    "\n",
    "# Encode each categorical variable for both datasets\n",
    "for cat_var in categorical_vars:\n",
    "    print(f\"\\n{cat_var}:\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # Check if variable exists in datasets\n",
    "    if cat_var not in df_basic_train.columns:\n",
    "        print(f\"{cat_var} not found in dataset, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # BASELINE dataset encoding\n",
    "    print(f\"BASELINE:\")\n",
    "    print(f\"Unique values in train: {df_basic_train[cat_var].nunique()}\")\n",
    "    print(f\"Unique values in val: {df_basic_val[cat_var].nunique()}\")\n",
    "    print(f\"Unique values in test: {df_basic_test[cat_var].nunique()}\")\n",
    "\n",
    "    train_enc, val_enc, test_enc = target_encode_time_series(\n",
    "        df_basic_train_encoded,\n",
    "        df_basic_val_encoded,\n",
    "        df_basic_test_encoded,\n",
    "        cat_var,\n",
    "        target_column='over_2_5',\n",
    "        prior_weight=10.0\n",
    "    )\n",
    "\n",
    "    # Add encoded columns\n",
    "    df_basic_train_encoded[f'{cat_var}_encoded'] = train_enc\n",
    "    df_basic_val_encoded[f'{cat_var}_encoded'] = val_enc\n",
    "    df_basic_test_encoded[f'{cat_var}_encoded'] = test_enc\n",
    "\n",
    "    print(f\"Encoded range: [{train_enc.min():.4f}, {train_enc.max():.4f}]\")\n",
    "    print(f\"Encoded mean: {train_enc.mean():.4f}\")\n",
    "\n",
    "    # EXTENDED dataset encoding\n",
    "    print(f\"EXTENDED:\")\n",
    "    print(f\"Unique values in train: {df_extended_train[cat_var].nunique()}\")\n",
    "    print(f\"Unique values in val: {df_extended_val[cat_var].nunique()}\")\n",
    "    print(f\"Unique values in test: {df_extended_test[cat_var].nunique()}\")\n",
    "\n",
    "    train_enc, val_enc, test_enc = target_encode_time_series(\n",
    "        df_extended_train_encoded,\n",
    "        df_extended_val_encoded,\n",
    "        df_extended_test_encoded,\n",
    "        cat_var,\n",
    "        target_column='over_2_5',\n",
    "        prior_weight=10.0\n",
    "    )\n",
    "\n",
    "    # Add encoded columns\n",
    "    df_extended_train_encoded[f'{cat_var}_encoded'] = train_enc\n",
    "    df_extended_val_encoded[f'{cat_var}_encoded'] = val_enc\n",
    "    df_extended_test_encoded[f'{cat_var}_encoded'] = test_enc\n",
    "\n",
    "    print(f\"Encoded range: [{train_enc.min():.4f}, {train_enc.max():.4f}]\")\n",
    "    print(f\"Encoded mean: {train_enc.mean():.4f}\")\n",
    "\n",
    "print(\"Target encoding completed\")\n",
    "\n",
    "\n",
    "# Part 2: ONE-HOT ENCODING for low-cardinality variable (Div)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 2: ONE-HOT ENCODING FOR DIV (LEAGUE)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check Div cardinality\n",
    "print(f\"\\nDiv (League) Analysis:\")\n",
    "print(f\"BASELINE - Unique leagues in train: {df_basic_train['Div'].nunique()}\")\n",
    "print(f\"BASELINE - Leagues: {sorted(df_basic_train['Div'].unique())}\")\n",
    "print(f\"\\nEXTENDED - Unique leagues in train: {df_extended_train['Div'].nunique()}\")\n",
    "print(f\"EXTENDED - Leagues: {sorted(df_extended_train['Div'].unique())}\")\n",
    "\n",
    "# One-hot encode Div for BASELINE dataset\n",
    "print(f\"\\nOne-hot encoding Div for BASELINE:\")\n",
    "div_train_baseline = pd.get_dummies(df_basic_train_encoded['Div'], prefix='Div', drop_first=False)\n",
    "div_val_baseline = pd.get_dummies(df_basic_val_encoded['Div'], prefix='Div', drop_first=False)\n",
    "div_test_baseline = pd.get_dummies(df_basic_test_encoded['Div'], prefix='Div', drop_first=False)\n",
    "\n",
    "# Align columns (in case val/test have missing categories)\n",
    "all_div_cols = sorted(set(div_train_baseline.columns) | set(div_val_baseline.columns) | set(div_test_baseline.columns))\n",
    "for col in all_div_cols:\n",
    "    if col not in div_train_baseline.columns:\n",
    "        div_train_baseline[col] = 0\n",
    "    if col not in div_val_baseline.columns:\n",
    "        div_val_baseline[col] = 0\n",
    "    if col not in div_test_baseline.columns:\n",
    "        div_test_baseline[col] = 0\n",
    "\n",
    "div_train_baseline = div_train_baseline[all_div_cols]\n",
    "div_val_baseline = div_val_baseline[all_div_cols]\n",
    "div_test_baseline = div_test_baseline[all_div_cols]\n",
    "\n",
    "# Add to dataframes\n",
    "df_basic_train_encoded = pd.concat([df_basic_train_encoded, div_train_baseline], axis=1)\n",
    "df_basic_val_encoded = pd.concat([df_basic_val_encoded, div_val_baseline], axis=1)\n",
    "df_basic_test_encoded = pd.concat([df_basic_test_encoded, div_test_baseline], axis=1)\n",
    "\n",
    "print(f\"Created {len(all_div_cols)} dummy columns: {all_div_cols}\")\n",
    "\n",
    "# One-hot encode Div for EXTENDED dataset\n",
    "print(f\"\\nOne-hot encoding Div for EXTENDED:\")\n",
    "div_train_extended = pd.get_dummies(df_extended_train_encoded['Div'], prefix='Div', drop_first=False)\n",
    "div_val_extended = pd.get_dummies(df_extended_val_encoded['Div'], prefix='Div', drop_first=False)\n",
    "div_test_extended = pd.get_dummies(df_extended_test_encoded['Div'], prefix='Div', drop_first=False)\n",
    "\n",
    "# Align columns\n",
    "all_div_cols_ext = sorted(set(div_train_extended.columns) | set(div_val_extended.columns) | set(div_test_extended.columns))\n",
    "for col in all_div_cols_ext:\n",
    "    if col not in div_train_extended.columns:\n",
    "        div_train_extended[col] = 0\n",
    "    if col not in div_val_extended.columns:\n",
    "        div_val_extended[col] = 0\n",
    "    if col not in div_test_extended.columns:\n",
    "        div_test_extended[col] = 0\n",
    "\n",
    "div_train_extended = div_train_extended[all_div_cols_ext]\n",
    "div_val_extended = div_val_extended[all_div_cols_ext]\n",
    "div_test_extended = div_test_extended[all_div_cols_ext]\n",
    "\n",
    "# Add to dataframes\n",
    "df_extended_train_encoded = pd.concat([df_extended_train_encoded, div_train_extended], axis=1)\n",
    "df_extended_val_encoded = pd.concat([df_extended_val_encoded, div_val_extended], axis=1)\n",
    "df_extended_test_encoded = pd.concat([df_extended_test_encoded, div_test_extended], axis=1)\n",
    "\n",
    "print(f\"Created {len(all_div_cols_ext)} dummy columns: {all_div_cols_ext}\")\n",
    "\n",
    "print(\"One-hot encoding completed\")\n",
    "\n",
    "\n",
    "# Part 3: DROP ORIGINAL CATEGORICAL COLUMNS\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 3: REMOVING ORIGINAL CATEGORICAL COLUMNS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Drop original categorical columns since we now have encoded versions\n",
    "cols_to_drop = ['HomeTeam', 'AwayTeam', 'Referee', 'Div']\n",
    "\n",
    "# BASELINE datasets\n",
    "for col in cols_to_drop:\n",
    "    if col in df_basic_train_encoded.columns:\n",
    "        df_basic_train_encoded = df_basic_train_encoded.drop(columns=[col])\n",
    "        df_basic_val_encoded = df_basic_val_encoded.drop(columns=[col])\n",
    "        df_basic_test_encoded = df_basic_test_encoded.drop(columns=[col])\n",
    "        print(f\"Dropped {col} from BASELINE datasets\")\n",
    "\n",
    "# EXTENDED datasets\n",
    "for col in cols_to_drop:\n",
    "    if col in df_extended_train_encoded.columns:\n",
    "        df_extended_train_encoded = df_extended_train_encoded.drop(columns=[col])\n",
    "        df_extended_val_encoded = df_extended_val_encoded.drop(columns=[col])\n",
    "        df_extended_test_encoded = df_extended_test_encoded.drop(columns=[col])\n",
    "        print(f\"Dropped {col} from EXTENDED datasets\")\n",
    "\n",
    "print(\"Original categorical columns removed\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CATEGORICAL ENCODING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"BASELINE datasets:\")\n",
    "print(f\"Train shape: {df_basic_train_encoded.shape}\")\n",
    "print(f\"Val shape: {df_basic_val_encoded.shape}\")\n",
    "print(f\"Test shape: {df_basic_test_encoded.shape}\")\n",
    "print(f\"\\nEXTENDED datasets:\")\n",
    "print(f\"Train shape: {df_extended_train_encoded.shape}\")\n",
    "print(f\"Val shape: {df_extended_val_encoded.shape}\")\n",
    "print(f\"Test shape: {df_extended_test_encoded.shape}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Create Feature Matrices with Encoded Variables\n",
    "\n",
    "Now prepare the final feature matrices including the encoded categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now update the feature preparation to include encoded variables\n",
    "print(\"=\" * 70)\n",
    "print(\"PREPARING FINAL FEATURE MATRICES WITH ENCODED VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Update the exclude columns list (original columns, not encoded versions)\n",
    "exclude_cols = ['Div', 'Season', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'Referee', 'over_2_5']\n",
    "\n",
    "# BASELINE dataset\n",
    "feature_cols_basic = [col for col in df_basic_train_encoded.columns if col not in exclude_cols]\n",
    "print(f\"\\nBASELINE:\")\n",
    "print(f\"Total features: {len(feature_cols_basic)}\")\n",
    "print(f\"Encoded features: {[col for col in feature_cols_basic if '_encoded' in col]}\")\n",
    "\n",
    "X_basic_train = df_basic_train_encoded[feature_cols_basic].copy()\n",
    "X_basic_val = df_basic_val_encoded[feature_cols_basic].copy()\n",
    "X_basic_test = df_basic_test_encoded[feature_cols_basic].copy()\n",
    "\n",
    "y_basic_train = df_basic_train_encoded['over_2_5'].copy()\n",
    "y_basic_val = df_basic_val_encoded['over_2_5'].copy()\n",
    "y_basic_test = df_basic_test_encoded['over_2_5'].copy()\n",
    "\n",
    "print(f\"X_train shape: {X_basic_train.shape}\")\n",
    "print(f\"X_val shape: {X_basic_val.shape}\")\n",
    "print(f\"X_test shape: {X_basic_test.shape}\")\n",
    "\n",
    "# EXTENDED dataset\n",
    "feature_cols_extended = [col for col in df_extended_train_encoded.columns if col not in exclude_cols]\n",
    "print(f\"\\nEXTENDED:\")\n",
    "print(f\"Total features: {len(feature_cols_extended)}\")\n",
    "print(f\"Encoded features: {[col for col in feature_cols_extended if '_encoded' in col]}\")\n",
    "\n",
    "X_extended_train = df_extended_train_encoded[feature_cols_extended].copy()\n",
    "X_extended_val = df_extended_val_encoded[feature_cols_extended].copy()\n",
    "X_extended_test = df_extended_test_encoded[feature_cols_extended].copy()\n",
    "\n",
    "y_extended_train = df_extended_train_encoded['over_2_5'].copy()\n",
    "y_extended_val = df_extended_val_encoded['over_2_5'].copy()\n",
    "y_extended_test = df_extended_test_encoded['over_2_5'].copy()\n",
    "\n",
    "print(f\"X_train shape: {X_extended_train.shape}\")\n",
    "print(f\"X_val shape: {X_extended_val.shape}\")\n",
    "print(f\"X_test shape: {X_extended_test.shape}\")\n",
    "\n",
    "# Verify no categorical columns remain\n",
    "print(f\"\\nVerification:\")\n",
    "categorical_basic = X_basic_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "categorical_extended = X_extended_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "if categorical_basic:\n",
    "    print(f\"WARNING: Categorical features remain in BASELINE: {categorical_basic}\")\n",
    "else:\n",
    "    print(f\"BASELINE: All features are numeric\")\n",
    "\n",
    "if categorical_extended:\n",
    "    print(f\"WARNING: Categorical features remain in EXTENDED: {categorical_extended}\")\n",
    "else:\n",
    "    print(f\"EXTENDED: All features are numeric\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Final feature matrices ready for modeling\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Save Preprocessed Data to Pickle Files\n",
    "\n",
    "Save the final preprocessed datasets (both baseline and extended) as pickle files for easy loading in the modeling notebook.\n",
    "\n",
    "**What's being saved:**\n",
    "- Feature matrices: `X_train`, `X_val`, `X_test`\n",
    "- Target vectors: `y_train`, `y_val`, `y_test`\n",
    "- Feature names: List of all feature column names\n",
    "- Metadata: Information about the preprocessing (dates, sizes, encoded features, etc.)\n",
    "\n",
    "**Output files:**\n",
    "- `processed/baseline_preprocessed.pkl` - Baseline feature set\n",
    "- `processed/extended_preprocessed.pkl` - Extended feature set with rolling statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save BASELINE dataset\n",
    "\n",
    "print(\"\\nSaving BASELINE dataset...\")\n",
    "\n",
    "baseline_data = {\n",
    "    'X_train': X_basic_train,\n",
    "    'X_val': X_basic_val,\n",
    "    'X_test': X_basic_test,\n",
    "    'y_train': y_basic_train,\n",
    "    'y_val': y_basic_val,\n",
    "    'y_test': y_basic_test,\n",
    "    'feature_names': feature_cols_basic,\n",
    "}\n",
    "\n",
    "baseline_filename = f'{OUTPUT_DIR}/baseline_preprocessed.pkl'\n",
    "with open(baseline_filename, 'wb') as f:\n",
    "    pickle.dump(baseline_data, f)\n",
    "\n",
    "print(f\"Saved to: {baseline_filename}\")\n",
    "print(f\"Train shape: {X_basic_train.shape}\")\n",
    "print(f\"Val shape: {X_basic_val.shape}\")\n",
    "print(f\"Test shape: {X_basic_test.shape}\")\n",
    "print(f\"Features: {len(feature_cols_basic)}\")\n",
    "\n",
    "\n",
    "# Save EXTENDED dataset\n",
    "\n",
    "print(\"\\nSaving EXTENDED dataset...\")\n",
    "\n",
    "extended_data = {\n",
    "    'X_train': X_extended_train,\n",
    "    'X_val': X_extended_val,\n",
    "    'X_test': X_extended_test,\n",
    "    'y_train': y_extended_train,\n",
    "    'y_val': y_extended_val,\n",
    "    'y_test': y_extended_test,\n",
    "    'feature_names': feature_cols_extended,\n",
    "}\n",
    "\n",
    "extended_filename = f'{OUTPUT_DIR}/extended_preprocessed.pkl'\n",
    "with open(extended_filename, 'wb') as f:\n",
    "    pickle.dump(extended_data, f)\n",
    "\n",
    "print(f\"Saved to: {extended_filename}\")\n",
    "print(f\"Train shape: {X_extended_train.shape}\")\n",
    "print(f\"Val shape: {X_extended_val.shape}\")\n",
    "print(f\"Test shape: {X_extended_test.shape}\")\n",
    "print(f\"Features: {len(feature_cols_extended)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NBksARdgdMkP",
    "Qx3gpH8TdToi",
    "O5SNQWIMhxZA",
    "NNyVnO2Bk4zo",
    "XMiRfCrVzDVd",
    "fwwBVM5ex2SA"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python soccer-venv",
   "language": "python",
   "name": "soccer-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
